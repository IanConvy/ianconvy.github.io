<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-09-01">

<title>Ian Convy’s Stuff - Dimensionality Reduction and Generative Modeling using Wavelets</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/bootstrap-icons-1.9.1/all.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Ian Convy’s Stuff</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../../projects/phd/phd.html" rel="" target="" aria-current="page">
 <span class="menu-text">PhD Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/tetris/tetris.html" rel="" target="">
 <span class="menu-text">Tetris</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/other/other.html" rel="" target="">
 <span class="menu-text">Other</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/IanConvy" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/ian-convy" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../projects/other/other.html">Other</a></li><li class="breadcrumb-item"><a href="../../../projects/other/wavelet/wavelet.html">Wavelet Reconstructor</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../projects/phd/phd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Research</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/phd/decomp/deomp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interaction Decomposition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/phd/bayesian/bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Error Correction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/phd/mi-scaling/mi-scaling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Correlation Scaling in Images</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../projects/tetris/tetris.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tetris</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/tetris/tetris-sql/tetris-sql.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PostgreTETRIS</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../projects/tetris/tetris-vba/tetris-vba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tetris in VBA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/tetris/tetris-vba/post-thoughts-tetris-vba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Post: Some Thoughts on VBA Tetris</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/tetris/tetris-spark/tetris-spark.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Solving Tetris with Spark</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/tetris/tetris-emulator/tetris-emulator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NES Emulator</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../projects/other/other.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Other</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/other/neoquest/neoquest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decoding NeoQuest II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/other/wavelet/wavelet.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Wavelet Reconstructor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/other/speedrunning/speedrunning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Speedrunning Report</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#a-brief-introduction-to-wavelets" id="toc-a-brief-introduction-to-wavelets" class="nav-link" data-scroll-target="#a-brief-introduction-to-wavelets">A Brief Introduction to Wavelets</a></li>
  <li><a href="#wavelet-reconstruction-using-neural-networks" id="toc-wavelet-reconstruction-using-neural-networks" class="nav-link" data-scroll-target="#wavelet-reconstruction-using-neural-networks">Wavelet reconstruction using neural networks</a></li>
  <li><a href="#generating-novel-images" id="toc-generating-novel-images" class="nav-link" data-scroll-target="#generating-novel-images">Generating novel images</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Dimensionality Reduction and Generative Modeling using Wavelets</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 1, 2021</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><i class="bi-github " style="" role="img" aria-hidden="true"></i> <a href="https://github.com/IanConvy/wavelet-reconstructor">GitHub Repository</a></p>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This project describes a neural network algorithm that uses wavelets to reconstruct images. The model operates by outputting reasonable estimates of the wavelet coefficients for a sample when given a set of corresponding scale coefficients as an input. The algorithm can be used for generative modeling, with the latent space being the space of scale coefficients at an appropriate level of coarse-graining. Since the wavelet decomposition will significantly lower the dimension of the original data, it is possible to use a simple distribution, such as a Gaussian, to sample from the latent space and generate complex reconstructed outputs.</p>
<p>The <code>walkthrough.ipynb</code> Jupyter notebook in the GitHub repository (linked above) contains a description of the neural network model and a tutorial on its use. The full source code is contained in the <code>wavelet.py</code> and <code>mnist_model.py</code> modules in the <code>src</code> folder. A suitable virtual environment can be set up using the <code>requirements.txt</code> file (<code>the requirements.in</code> file lists the direct dependencies).</p>
<p>A non-interactive version of the Jupyter notebook is reproduced below.</p>
</section>
<section id="a-brief-introduction-to-wavelets" class="level2">
<h2 class="anchored" data-anchor-id="a-brief-introduction-to-wavelets">A Brief Introduction to Wavelets</h2>
<p>A <em>wavelet</em> is a wave that has a finite extent, such that its amplitude is zero outside of a limited domain. This is a very general definition, and the wavelets of interest to mathematicians and engineers tend to have additional useful properties, such as certain orthogonality conditions. The utility of wavelets comes from their ability to act as a basis for virtually any signal, which allows us to decompose the signal into a linear combination of wavelets. This is similar to the Fourier series for periodic functions, except that wavelets can resolve signal properties in both the frequency and time domains simultaneously. This makes them an exceptionally powerful tool for signal analysis, especially on image and time-series data.</p>
<p>When working with wavelets, there are two key sets of functions: the <em>scaling functions</em> <span class="math inline">\(\phi_{j,k}\)</span> and the <em>wavelet functions</em> <span class="math inline">\(\psi_{j,k}\)</span>. Each set of functions is generated by a single <em>mother</em> function, which is scaled and translated by a fixed amount to generate the indexed functions:</p>
<p><span class="math display">\[\begin{equation}
\phi_{j,k}(x) = 2^{\frac{j}{2}} \phi(2^jx - k), \quad \quad \psi_{j,k}(x) = 2^{\frac{j}{2}} \psi(2^jx - k)
\end{equation}\]</span></p>
<p>For a given <span class="math inline">\(j\)</span>, the scaling functions span a vector space that can describe a signal up to a certain level of detail, with higher values of <span class="math inline">\(j\)</span> corresponding to greater resolution. The <span class="math inline">\(j\)</span>th wavelet function set spans the difference between the scaling spaces corresponding to <span class="math inline">\(j\)</span> and <span class="math inline">\(j+1\)</span>, and can be viewed as adding back the detail that is lost in the coarser space. In the following code, we plot examples of the scaling and wavelet mother functions for the “Daubechies 4” wavelet using the library PyWavelets:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pywt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> pywt.Wavelet(<span class="st">'db4'</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>(phi, psi, x) <span class="op">=</span> w.wavefun(level<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>(fig, [ax_1, ax_2]) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, sharey <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>ax_1.plot(x, phi)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>ax_2.plot(x, psi)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>ax_1.set_title(<span class="vs">r"Scaling function $\phi\ (x)$"</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>ax_2.set_title(<span class="vs">r"Wavelet function $\psi\ (x)$"</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../..\assets/projects/other/wavelet/mothers_funcs.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Scaling and wavelet mother functions.</figcaption>
</figure>
</div>
<p>Note that the functions have a highly irregular shape, and do not possess any closed-form solution. Instead, their shapes are generated on demand using a numerical algorithm.</p>
<p>In a <em>wavelet decomposition</em>, we project a signal into a specified scaling space depending on the level <span class="math inline">\(j\)</span> of detail desired, which generates a set of expansion coefficients for the <span class="math inline">\(j\)</span>th set of scale functions plus coefficients for the wavelet spaces corresponding to each coarse-graining step. The original signal can always be reconstructed from the coarse-grained signal by adding back the wavelet terms, although if these terms are unknown then the fine-grained structure of the signal will be lost. The following code block shows a custom Keras layer in TensorFlow that carries out a wavelet decomposition on the input signal:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Wavelet_Decon(tf.keras.layers.Layer):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, h, axis, <span class="op">**</span>kwargs):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The h_0 and h_1 attributes are the filter values for </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># computing the scale coefficients and wavelet coefficients</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># respectively.</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> tf.constant(h)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> tf.<span class="bu">range</span>(tf.size(h))</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_0 <span class="op">=</span> h[:, tf.newaxis, tf.newaxis]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_1 <span class="op">=</span> tf.reverse(tf.dynamic_stitch([indices[::<span class="dv">2</span>], indices[<span class="dv">1</span>::<span class="dv">2</span>]], [<span class="op">-</span>h[::<span class="dv">2</span>], h[<span class="dv">1</span>::<span class="dv">2</span>]]), [<span class="dv">0</span>])[:, tf.newaxis, tf.newaxis]</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.basis_indices <span class="op">=</span> tf.<span class="bu">range</span>(tf.size(h) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.axis <span class="op">=</span> axis</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The permute attribute simply specifies indices for a </span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># transposition that places the target axis at the end</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># of the tensor shape.</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        num_dims <span class="op">=</span> input_shape.rank</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.permute <span class="op">=</span> tf.dynamic_stitch([tf.<span class="bu">range</span>(num_dims), [<span class="va">self</span>.axis, num_dims<span class="op">-</span><span class="dv">1</span>]], [tf.<span class="bu">range</span>(num_dims), [num_dims<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.axis]])</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># To perform the decomposition, the input is first </span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># appended with a truncated copy of itself so that </span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># it is big enough to allow the filters to act on all</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># featutes. Then the scale and wavelet coefficients </span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># are computed by convolving the expanded input</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># with h_0 and h_1.</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> tf.transpose(inputs, <span class="va">self</span>.permute)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        cycle_indices <span class="op">=</span> <span class="va">self</span>.basis_indices <span class="op">%</span> tf.shape(inputs)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        periodic_coeff <span class="op">=</span> tf.concat([inputs, tf.gather(inputs, cycle_indices, axis <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>)], axis <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        h_0_conv <span class="op">=</span> tf.nn.conv1d(periodic_coeff[..., tf.newaxis], <span class="va">self</span>.h_0, stride <span class="op">=</span> <span class="dv">1</span>, padding <span class="op">=</span> <span class="st">"VALID"</span>)[..., <span class="dv">0</span>]</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        h_1_conv <span class="op">=</span> tf.nn.conv1d(periodic_coeff[..., tf.newaxis], <span class="va">self</span>.h_1, stride <span class="op">=</span> <span class="dv">1</span>, padding <span class="op">=</span> <span class="st">"VALID"</span>)[..., <span class="dv">0</span>]</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        scale_coeff <span class="op">=</span> tf.transpose(h_0_conv[..., ::<span class="dv">2</span>], <span class="va">self</span>.permute)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        wavelet_coeff <span class="op">=</span> tf.transpose(h_1_conv[..., ::<span class="dv">2</span>], <span class="va">self</span>.permute)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> tf.concat([scale_coeff, wavelet_coeff], <span class="va">self</span>.axis)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> outputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The core operations within this layer are the pair of convolutions that act on a specified axis of the input. The filters for these convolution are based on the specific choice of wavelet, and allow us to easily compute the scale coefficients for the coarse-grained output along with the associated wavelet coefficients. To compute the wavelet decomposition on higher-dimensional data, we can simply apply this layer on each of the feature axes. The following code shows how the wavelet decomposition acts on an image from the MNIST dataset:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src <span class="im">import</span> wavelet</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> tf.keras.datasets.mnist.load_data()[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> tf.cast(image, <span class="st">"float32"</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>padded_image <span class="op">=</span> wavelet.Pad_nD()(image)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>decon_layer <span class="op">=</span> wavelet.Wavelet_Decon_Layer(wavelet.haar)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>decon <span class="op">=</span> decon_layer(image[<span class="va">None</span>])</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>(fig, axes) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="bu">len</span>(decon), figsize <span class="op">=</span> (<span class="fl">9.3</span>, <span class="dv">7</span>))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (ax, coeff) <span class="kw">in</span> <span class="bu">zip</span>(axes, <span class="bu">reversed</span>(decon)):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    ax.imshow(coeff[<span class="dv">0</span>], cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../..\assets/projects/other/wavelet/image_decomp.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image coarse-graining from the wavelet decomposition.</figcaption>
</figure>
</div>
<p>In this sequence of plots, we can see the original image of a five on the left, followed by images of decreasing resolution which appear to be divided into four quadrants. The top left quadrant shows the coarse-grained image generated by the wavelet decomposition, while the other three quadrants show the fine-grained detail that was lost relative to the image before it. In the most extreme case, the wavelet decomposition reduces the image down to only a single pixel, but even this level of coarse-graining can be undone by recombining the other three quadrants via an <em>inverse wavelet decomposition</em>. Code for a Keras layer that carries out the inverse decomposition is given here:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Wavelet_Recon(tf.keras.layers.Layer):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, h, axis, <span class="op">**</span>kwargs):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The h_0 and h_1 attributes are the filter values for </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># reconstructing portions of the image from the scale</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coefficients and wavelet coefficients respectively.</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> tf.constant(h)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> tf.<span class="bu">range</span>(tf.size(h))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_0 <span class="op">=</span> h[::<span class="op">-</span><span class="dv">1</span>, tf.newaxis, tf.newaxis]</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_1 <span class="op">=</span> tf.reverse(tf.dynamic_stitch([indices[::<span class="dv">2</span>], indices[<span class="dv">1</span>::<span class="dv">2</span>]], [<span class="op">-</span>h[::<span class="dv">2</span>], h[<span class="dv">1</span>::<span class="dv">2</span>]]), [<span class="dv">0</span>])[::<span class="op">-</span><span class="dv">1</span>, tf.newaxis, tf.newaxis]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.basis_indices <span class="op">=</span> tf.<span class="bu">range</span>(<span class="op">-</span>(tf.size(h) <span class="op">-</span> <span class="dv">2</span>)<span class="op">//</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.axis <span class="op">=</span> axis</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The permute attribute simply specifies indices for a </span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># transposition that places the target axis at the end</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># of the tensor shape.</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        num_dims <span class="op">=</span> input_shape[<span class="dv">0</span>].rank</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.permute <span class="op">=</span> tf.dynamic_stitch([tf.<span class="bu">range</span>(num_dims), [<span class="va">self</span>.axis, num_dims<span class="op">-</span><span class="dv">1</span>]], [tf.<span class="bu">range</span>(num_dims), [num_dims<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.axis]])</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The layer takes as input a list of two tensors,</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># which hold the scale and wavelet coefficients</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># respectively. To recover the original data shape,</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zeroes are inserted into the data and then convolved</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># with the h_0 and h_ attributes to generate the </span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># reconstruction.</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> tf.stack([tf.transpose(inputs[<span class="dv">0</span>], <span class="va">self</span>.permute), tf.transpose(inputs[<span class="dv">1</span>], <span class="va">self</span>.permute)])</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        cycle_indices <span class="op">=</span> <span class="va">self</span>.basis_indices <span class="op">%</span> tf.shape(inputs)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        new_inputs <span class="op">=</span> tf.concat([tf.gather(inputs, cycle_indices, axis <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>), inputs], axis <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>)[..., <span class="dv">1</span>:]</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        batch_shape <span class="op">=</span> tf.shape(inputs)[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        up_shape <span class="op">=</span> tf.concat([batch_shape, <span class="dv">2</span><span class="op">*</span>tf.shape(new_inputs)[<span class="op">-</span><span class="dv">1</span>:]], <span class="dv">0</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        coeff_up <span class="op">=</span> tf.reshape(tf.stack([tf.zeros_like(new_inputs), new_inputs], <span class="op">-</span><span class="dv">1</span>), up_shape)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        coeff_up <span class="op">=</span> tf.concat([coeff_up, tf.zeros_like(coeff_up[..., <span class="dv">0</span>:<span class="dv">1</span>])], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        scale_coeff <span class="op">=</span> coeff_up[<span class="dv">0</span>]</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        wavelet_coeff <span class="op">=</span> coeff_up[<span class="dv">1</span>]</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        h_0_conv <span class="op">=</span> tf.nn.conv1d(scale_coeff[..., tf.newaxis], <span class="va">self</span>.h_0, stride <span class="op">=</span> <span class="dv">1</span>, padding <span class="op">=</span> <span class="st">"VALID"</span>)[..., <span class="dv">0</span>]</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        h_1_conv <span class="op">=</span> tf.nn.conv1d(wavelet_coeff[..., tf.newaxis], <span class="va">self</span>.h_1, stride <span class="op">=</span> <span class="dv">1</span>, padding <span class="op">=</span> <span class="st">"VALID"</span>)[..., <span class="dv">0</span>]</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> tf.transpose(h_0_conv <span class="op">+</span> h_1_conv, <span class="va">self</span>.permute)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> outputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This layer is similar to that of the wavelet decomposition, except that there are more manipulations of the input to get it into the correct configuration. The core operation though is still a pair of convolutions with filters that are determined by the type of wavelet used in the original decomposition.</p>
</section>
<section id="wavelet-reconstruction-using-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="wavelet-reconstruction-using-neural-networks">Wavelet reconstruction using neural networks</h2>
<p>Wavelet reconstruction (i.e.&nbsp;the inverse wavelet decomposition) can always be carried out exactly if we have access to the wavelet coefficients corresponding to each of the coarse-graining operations. However, what if all we had were the scale coefficients? Would it still be possible to reconstruct the signal? For a random signal the answer is clearly no, since a virtually infinite number of higher-resolution signals can correspond to a given coarse-grained signal. That said, if we restrict ourselves to a narrow class of inputs, then it may be possible to infer the missing wavelet coefficients based on the values of the scale coefficients.</p>
<p>This task can be understood as a problem in generative modeling, and it should be possible to carry out using a well-trained neural network. Given a full-resolution training sample, we can perform a sequence of wavelet decomposition down to a specified level of coarse-graining, with each decomposition yielding a set of scale coefficients and a set of wavelet coefficients. These sets of coefficients serve as our inputs and target outputs respectively, and we can use them to train a model at each coarse-graining level. Once these models have been trained, we can take a sample from the coarse-grained signal space and upscale it back to the original resolution. The following code shows a composite Keras model that can carry out wavelet reconstruction on MNIST images:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Wavelet_MNIST():</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, h):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create layers that will carry out the wavelet decomposition</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and reconstruction. </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pad_layer <span class="op">=</span> wavelet.Pad_nD()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decon_layer <span class="op">=</span> wavelet.Wavelet_Decon_Layer(h, coarse_only <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.recon_layer <span class="op">=</span> wavelet.Wavelet_nD_Recon(h)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>):</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Each of the model cores correspond to a different</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coarse-grained input size. The 1x1 and 2x2 models</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># are dense networks, while the remaining models</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># are convolutional. </span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models <span class="op">=</span> []</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores <span class="op">=</span> []</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        model_1_core <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Flatten(),</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">128</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">128</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">32</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">3</span>),</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Reshape([<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>])</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        model_1 <span class="op">=</span> <span class="va">self</span>.assemble_model(model_1_core, <span class="dv">1</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores.append(model_1_core)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models.append(model_1)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        model_2_core <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Flatten(),</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">128</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">128</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">32</span>, <span class="st">"relu"</span>),</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">12</span>),</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Reshape([<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        model_2 <span class="op">=</span> <span class="va">self</span>.assemble_model(model_2_core, <span class="dv">2</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores.append(model_2_core)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models.append(model_2)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        model_4_core <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Lambda(<span class="kw">lambda</span> x: tf.expand_dims(x, <span class="op">-</span><span class="dv">1</span>)),</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">3</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        model_4 <span class="op">=</span> <span class="va">self</span>.assemble_model(model_4_core, <span class="dv">4</span>)</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores.append(model_4_core)</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models.append(model_4)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        model_8_core <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Lambda(<span class="kw">lambda</span> x: tf.expand_dims(x, <span class="op">-</span><span class="dv">1</span>)),</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">3</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>)</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        model_8 <span class="op">=</span> <span class="va">self</span>.assemble_model(model_8_core, <span class="dv">8</span>)</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores.append(model_8_core)</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models.append(model_8)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        model_16_core <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Lambda(<span class="kw">lambda</span> x: tf.expand_dims(x, <span class="op">-</span><span class="dv">1</span>)),</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Conv2D(<span class="dv">3</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>)</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        model_16 <span class="op">=</span> <span class="va">self</span>.assemble_model(model_16_core, <span class="dv">16</span>)</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cores.append(model_16_core)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models.append(model_16)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_all(<span class="va">self</span>, train_images, test_images, epochs, batch_size, save <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.models)):</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>            length <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>i</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Training model_</span><span class="sc">{</span>length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.train(length, train_images, test_images, epochs, batch_size, save)</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, length, train_images, test_images, epochs, batch_size, save <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Each model is trained using the exact decomposition coefficients, rather than the</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># reconstructed output from the previous layers. The "length" argument sets which</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coarse-graining level should be used for training.</span></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>        train_data <span class="op">=</span> <span class="va">self</span>.wavelet_transform(train_images.shuffle(<span class="dv">60000</span>).batch(batch_size), length)</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>        test_data <span class="op">=</span> <span class="va">self</span>.wavelet_transform(test_images.batch(batch_size), length)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>        index <span class="op">=</span> <span class="bu">int</span>(math.log2(length))</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> <span class="va">self</span>.models[index]</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">compile</span>(</span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="st">"mae"</span>,</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>            optimizer <span class="op">=</span> tf.keras.optimizers.RMSprop(<span class="fl">0.0005</span>))</span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>        model.fit(</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a>            train_data,</span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a>            epochs <span class="op">=</span> epochs, </span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>            validation_data <span class="op">=</span> test_data,</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a>            callbacks <span class="op">=</span> [tf.keras.callbacks.EarlyStopping(monitor <span class="op">=</span> <span class="st">"val_loss"</span>, patience <span class="op">=</span> <span class="dv">10</span>, restore_best_weights <span class="op">=</span> <span class="va">True</span>)])</span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> save:</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a>            core <span class="op">=</span> <span class="va">self</span>.cores[index]</span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>            core.save(<span class="ss">f"mnist_models/wavelet/core_</span><span class="sc">{</span>length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> assemble_model(<span class="va">self</span>, core, length):</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This function adds the wavelet reconstruction layer</span></span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a>        <span class="co"># to the model core.</span></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a>        first <span class="op">=</span> tf.keras.layers.Input([length, length])</span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>        fine <span class="op">=</span> core(first)</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> tf.keras.layers.Lambda(</span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a>            <span class="kw">lambda</span> x: tf.concat([</span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a>                tf.concat([x[<span class="dv">0</span>], x[<span class="dv">1</span>][..., <span class="dv">0</span>]], axis <span class="op">=</span> <span class="dv">2</span>),</span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a>                tf.concat([x[<span class="dv">1</span>][..., <span class="dv">1</span>], x[<span class="dv">1</span>][..., <span class="dv">2</span>]], axis <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a>            ], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a>        )([first, fine])</span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a>        recon <span class="op">=</span> <span class="va">self</span>.recon_layer(combined)</span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [first], outputs <span class="op">=</span> [recon])</span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model</span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> wavelet_transform(<span class="va">self</span>, dataset, length, keep_orig <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This function carries out a wavelet decomposition on the</span></span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a>        <span class="co"># inputs using the decon_layer.</span></span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a>        index <span class="op">=</span> <span class="bu">int</span>(math.log2(length))</span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a>        padded <span class="op">=</span> dataset.<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="va">self</span>.pad_layer(x))</span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> keep_orig:</span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a>            coeff <span class="op">=</span> padded.<span class="bu">map</span>(<span class="kw">lambda</span> y: (<span class="va">self</span>.decon_layer(y)[index], y))</span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb5-143"><a href="#cb5-143" aria-hidden="true" tabindex="-1"></a>            coeff <span class="op">=</span> padded.<span class="bu">map</span>(<span class="kw">lambda</span> y: (<span class="va">self</span>.decon_layer(y)[index], <span class="va">self</span>.decon_layer(y)[index <span class="op">+</span> <span class="dv">1</span>]))</span>
<span id="cb5-144"><a href="#cb5-144" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> coeff</span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reconstruct(<span class="va">self</span>, inputs, length <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This function uses the model to appoximately reconstructs </span></span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the original input based on its coarse-grained scale </span></span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coefficients.</span></span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> length <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a>            length <span class="op">=</span> tf.shape(inputs)[<span class="dv">1</span>]</span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a>        start_index <span class="op">=</span> <span class="bu">int</span>(math.log2(length))</span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a>        next_input <span class="op">=</span> inputs</span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(start_index, <span class="dv">5</span>):</span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> <span class="va">self</span>.models[i]</span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a>            next_input <span class="op">=</span> model(next_input)</span>
<span id="cb5-159"><a href="#cb5-159" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> next_input</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that there is a model core for each resolution, from the original (padded) 32 x 32 images to the maximally coarse-grained 1 x 1 pixel “image”. To evaluate the performance of the model, we can perform a sequence of wavelet decomposition on an image and then use the model to reconstruct the image starting from each of the possible coarse-graining levels. We should expect to get a nearly perfect reconstruction after only a single coarse-graining step, since little information has been lost. After several coarse-graining steps, however, perfect reconstruction is likely to be impossible due to the large amount of image detail that has been discarded. The code below shows the deconstruction and reconstruction of an image at different coase-graining levels:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src <span class="im">import</span> wavelet, mnist_model</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>test_image <span class="op">=</span> tf.keras.datasets.mnist.load_data()[<span class="dv">1</span>][<span class="dv">0</span>][<span class="dv">4</span>]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>test_image <span class="op">=</span> tf.cast(test_image, <span class="st">"float32"</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> tf.data.Dataset.from_tensors(test_image[<span class="va">None</span>])</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> mnist_model.Wavelet_MNIST(wavelet.d_4)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>model.load()</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>(fig, axes) <span class="op">=</span> plt.subplots(<span class="dv">5</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (length, (ax_1, ax_2, ax_3)) <span class="kw">in</span> <span class="bu">zip</span>([<span class="dv">16</span>, <span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>], axes):</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    decon <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(model.wavelet_transform(dataset, length)))[<span class="dv">0</span>]</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    raw_recon <span class="op">=</span> model.reconstruct(decon)[<span class="dv">0</span>]</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    final_recon <span class="op">=</span> mnist_model.clip_pixels(raw_recon)[<span class="dv">2</span>:<span class="dv">30</span>, <span class="dv">2</span>:<span class="dv">30</span>]</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    ax_1.imshow(test_image, cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    ax_2.imshow(decon[<span class="dv">0</span>], cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    ax_3.imshow(final_recon, cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">0</span>].set_title(<span class="st">"Original"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">1</span>].set_title(<span class="st">"Coarse-grained"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">2</span>].set_title(<span class="st">"Reconstructed"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../..\assets/projects/other/wavelet/reconstruct.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Digit reconstructed using different latent space dimensions.</figcaption>
</figure>
</div>
<p>In each row, the original image of the digit “4” is given on the left, and the reconstruction generated by the model is shown on the right. In the middle column, we show the coarse-grained image, which is seen to lose resolution by a factor of two along each dimension as we go down the rows. As the size of the coarse-grained image space decreases, we can easily see the expected degradation of the reconstruction quality, though the output still shows impressive fidelity.</p>
<p>When working with reconstructions from the lower-resolution decompositions, we can observe an increase in noise or “static” from the reconstruction, which clearly does not fit into the normal appearance of the MNIST images. These reconstructions would look much more convincing if we could remove the obvious noise artifacts, so we will train a secondary model to perform this clean-up. The following code creates the cleaner model using a method on the Wavelet_MNIST class:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_cleaner(<span class="va">self</span>, length, train_images, test_images, epochs, batch_size):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.cleaner <span class="op">=</span> tf.keras.models.Sequential([ <span class="co"># The cleaner is deliberately shallow.</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Lambda(<span class="kw">lambda</span> x: tf.expand_dims(x, <span class="op">-</span><span class="dv">1</span>)),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>),</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">1</span>, <span class="dv">3</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span>, padding <span class="op">=</span> <span class="st">"same"</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Reshape([<span class="dv">32</span>, <span class="dv">32</span>])</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    first <span class="op">=</span> tf.keras.layers.Input([length, length])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    recon <span class="op">=</span> <span class="va">self</span>.reconstruct(first, length)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    cleaned <span class="op">=</span> <span class="va">self</span>.cleaner(recon)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [first], outputs <span class="op">=</span> [cleaned])</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> core <span class="kw">in</span> <span class="va">self</span>.cores:</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        core.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="st">"mae"</span>,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> tf.keras.optimizers.RMSprop(<span class="fl">0.0005</span>))</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> <span class="va">self</span>.wavelet_transform(train_images.shuffle(<span class="dv">60000</span>).batch(batch_size), length, <span class="va">True</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> <span class="va">self</span>.wavelet_transform(test_images.batch(batch_size), length, <span class="va">True</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    model.fit(</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        train_data,</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        epochs <span class="op">=</span> epochs, </span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        validation_data <span class="op">=</span> test_data,</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        callbacks <span class="op">=</span> [tf.keras.callbacks.EarlyStopping(monitor <span class="op">=</span> <span class="st">"val_loss"</span>, patience <span class="op">=</span> <span class="dv">10</span>, restore_best_weights <span class="op">=</span> <span class="va">True</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With this cleaning model, the reconstruction can be made to more closely resemble images from the MNIST dataset, even if its overall appearance still differs somewhat from the original image that was decomposed. The following code shows some examples of model reconstruction using the cleaner:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src <span class="im">import</span> wavelet, mnist_model</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>test_images <span class="op">=</span> tf.keras.datasets.mnist.load_data()[<span class="dv">1</span>][<span class="dv">0</span>]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>test_images <span class="op">=</span> tf.cast(test_images, <span class="st">"float32"</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> tf.data.Dataset.from_tensors(test_images[:<span class="dv">10</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> mnist_model.Wavelet_MNIST(wavelet.d_4)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>model.load()</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>decon <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(model.wavelet_transform(dataset, <span class="dv">4</span>)))[<span class="dv">0</span>]</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>recon <span class="op">=</span> model.reconstruct(decon)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>clipped <span class="op">=</span> mnist_model.clip_pixels(recon)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>cleaned <span class="op">=</span> model.clean(recon)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>(fig, axes) <span class="op">=</span> plt.subplots(<span class="dv">10</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">12</span> ,<span class="dv">16</span>))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (orig_image, recon_image, clean_recon_image, (ax_1, ax_2, ax_3)) <span class="kw">in</span> <span class="bu">zip</span>(test_images, clipped, cleaned, axes):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    ax_1.imshow(orig_image, cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    ax_2.imshow(recon_image, cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    ax_3.imshow(clean_recon_image, cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">0</span>].set_title(<span class="st">"Original"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">1</span>].set_title(<span class="st">"Reconstructed from 4x4"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>][<span class="dv">2</span>].set_title(<span class="st">"Cleaned"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../..\assets/projects/other/wavelet/cleaned.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Digits reconstructed using the cleaning algorithm.</figcaption>
</figure>
</div>
<p>Comparing the second and third columns, we can see that the cleaner is able to fix most irregularities in the brightness and location of the image pixels, although broader discrepancies in shape will not be addressed.</p>
</section>
<section id="generating-novel-images" class="level2">
<h2 class="anchored" data-anchor-id="generating-novel-images">Generating novel images</h2>
<p>So far we have focused on reconstructing existing images that were coarse-grained via wavelet decomposition, but it is also possible to view the low-resolution image space as a latent space for an image-generating model. At the smallest resolution sizes, such as 2x2, it is possible to use a Gaussian distribution to generate the initial probability density on the latent space. The Gaussian distributions can be fit to a set of coarse-grained images generated from the wavelet decomposition of a training set. The following method for the Wavelet_MNIST class generates novel images using this Gaussian approach:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_gaussian(<span class="va">self</span>, dataset, length, num_samples):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    decon <span class="op">=</span> <span class="va">self</span>.wavelet_transform(dataset.batch(<span class="dv">60000</span>), length)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> tf.reshape(<span class="bu">next</span>(<span class="bu">iter</span>(decon))[<span class="dv">0</span>], [<span class="dv">60000</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    cov <span class="op">=</span> tfp.stats.covariance(data)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> tf.reduce_mean(data, <span class="dv">0</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> tfp.distributions.MultivariateNormalFullCovariance(mean, cov).sample([num_samples])</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    recon <span class="op">=</span> <span class="va">self</span>.reconstruct(tf.reshape(samples, [num_samples, length, length]))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    cleaned <span class="op">=</span> <span class="va">self</span>.cleaner(recon)[:, <span class="dv">2</span>:<span class="dv">30</span>, <span class="dv">2</span>:<span class="dv">30</span>]</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cleaned</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can use this method to sample a set of new images and see how realistic they look. Given that the Gaussian distribution does not possess a sophisticated structure, we will get the best results by using the small 2x2 coarse-grained latent space.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src <span class="im">import</span> wavelet, mnist_model</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>(train_images, test_images) <span class="op">=</span> mnist_model.get_images()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> mnist_model.Wavelet_MNIST(wavelet.d_4)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>model.load()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> tf.reshape(model.sample_gaussian(train_images, <span class="dv">2</span>, <span class="dv">25</span>), [<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">28</span>, <span class="dv">28</span>])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>(fig, axes) <span class="op">=</span> plt.subplots(<span class="dv">5</span>, <span class="dv">5</span>, figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        axes[i][j].imshow(samples[i, j], cmap <span class="op">=</span> <span class="st">"gray"</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../..\assets/projects/other/wavelet/generated.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Novel images of digits generated using wavelet reconstruction.</figcaption>
</figure>
</div>
<p>As we can see from the plots, virtually all of the images are at least vaguely digit-shaped, with a fair number being reasonable depictions. That said, quite a few are clearly not digits, which suggests that there are portions of the latent space which do not map to decomposed MNIST images. One way to improve the quality of the generated images would be to fit a more flexible model to the latent space, so that it can avoid sampling from these invalid regions.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>