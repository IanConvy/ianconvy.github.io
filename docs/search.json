[
  {
    "objectID": "projects/tetris/tetris.html",
    "href": "projects/tetris/tetris.html",
    "title": "Tetris",
    "section": "",
    "text": "My interest in Tetris started around 2017, after I watched the 2016 CTWC finals match between Jeff Moore and the late Jonas Neubauer. This match had, for some reason, gone viral relative to previous Tetris matches on YouTube, and led to increased interest in competitive play. Although I never got good enough at the game to compete at these kinds of events (and top-level play has improved tremendously in recent years), I have found Tetris to be a bountiful playground for experimenting with cool technologies.\nThe projects in this section all involve Tetris in some significant way. Several of them are implementations of Tetris in both usual and unusual settings, while others involve analyzing the game’s properties. A list of the projects, along with brief descriptions, is given below:\n\nPostgreTETRIS: Tetris in SQL\n\nThis project implements a simplified version of Tetris in a PostgreSQL database. The player performs a table insertion to specify their move, and then a set of PL/pgSQL procedures are triggered to process the game logic. The game can be “installed” by running the SQL script hosted on GitHub.\n\nTetris in VBA\n\nThis project implements a simplified version of Tetris within a Microsoft Excel spreadsheet using Visual Basic for Applications (VBA). The player is given a simple graphical interface with which to position and drop pieces, which triggers a set of VBA routines behind the scenes. The game can be played by downloading the spreadsheet hosted on GitHub.\n\n“Solving” Tetris with Apache Spark\n\nThis project “solves” a portion of Tetris by computing optimal stacking patterns using Apache Spark (specifically PySpark). The solution specifies how to place pieces without creating holes in the stack. Example code can be run from the associated Jupyter notebook on GitHub.\n\nTetris Emulation with OpenGL\n\nThis project uses OpenGL to emulate the version of Tetris released in 1989 on the Nintendo Entertainment System. The program is written from scratch in C++, and recreates all of the subtle design patterns that are unique to this version of the game. It can be easily compiled to run on a Linux device by following the GitHub instructions."
  },
  {
    "objectID": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html",
    "href": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html",
    "title": "Post: Some Thoughts on VBA Tetris",
    "section": "",
    "text": "I would wager, boldly, that Visual Basic for Applications (VBA) is not the go-to language for game development. It is, however, widely used for scripting and automation within the Microsoft Office ecosystem, especially Excel. This is where I was first exposed to VBA, writing custom physics functions for processing and analyzing experimental data. I suspect that it is mostly institutional inertia that keeps the language going, chugging along as a kind of living fossil1 that is just too inconvenient to replace. And hey, if it’s not broken, why fix it?\nOn a personal level, I rather enjoy the look and feel of VBA. It is one of the tidiest languages that I’ve used, with every keyword nicely capitalized and no ugly bracket/parentheses nesting. My biggest gripe is how functions often cannot be called using parentheses. The lack of visual separation between the function name and the arguments can make invocations difficult to parse, especially if the passed variables are also capitalized:\n\n'Valid'\nSomeFunction, SomeVariable, SomeOtherVariable\n\n'Syntax Error'\nSomeFunction(SomeVariable, SomeOtherVariable)\nI would really like to know Microsoft’s reasoning for this design choice, but I have yet to locate a good source2. That aside, the rest of the language feels pretty natural, and I haven’t found it significantly harder to code with than something like JavaScript or Python. My positive(ish) sentiment toward VBA does not seem to be shared by many others though, as it was apparently voted the least-loved, least-wanted, and most-dreaded language on StackOverflow."
  },
  {
    "objectID": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#why-vba",
    "href": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#why-vba",
    "title": "Post: Some Thoughts on VBA Tetris",
    "section": "",
    "text": "I would wager, boldly, that Visual Basic for Applications (VBA) is not the go-to language for game development. It is, however, widely used for scripting and automation within the Microsoft Office ecosystem, especially Excel. This is where I was first exposed to VBA, writing custom physics functions for processing and analyzing experimental data. I suspect that it is mostly institutional inertia that keeps the language going, chugging along as a kind of living fossil1 that is just too inconvenient to replace. And hey, if it’s not broken, why fix it?\nOn a personal level, I rather enjoy the look and feel of VBA. It is one of the tidiest languages that I’ve used, with every keyword nicely capitalized and no ugly bracket/parentheses nesting. My biggest gripe is how functions often cannot be called using parentheses. The lack of visual separation between the function name and the arguments can make invocations difficult to parse, especially if the passed variables are also capitalized:\n\n'Valid'\nSomeFunction, SomeVariable, SomeOtherVariable\n\n'Syntax Error'\nSomeFunction(SomeVariable, SomeOtherVariable)\nI would really like to know Microsoft’s reasoning for this design choice, but I have yet to locate a good source2. That aside, the rest of the language feels pretty natural, and I haven’t found it significantly harder to code with than something like JavaScript or Python. My positive(ish) sentiment toward VBA does not seem to be shared by many others though, as it was apparently voted the least-loved, least-wanted, and most-dreaded language on StackOverflow."
  },
  {
    "objectID": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#why-tetris",
    "href": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#why-tetris",
    "title": "Post: Some Thoughts on VBA Tetris",
    "section": "Why Tetris?",
    "text": "Why Tetris?\nIn any case, I wanted to expand my understanding of VBA by using it to do something unnatural. This is often a fun way to practice new technical skills, since it pushes you away from the project-on-rails experience that is typical of many online tutorials. I have been a Tetris fan since 2017, and from then on I’ve enjoyed finding excuses to implement the game in increasingly ridiculous contexts3. Microsoft Excel was never meant to serve as a game engine, but it can serve as one in a rudimentary fashion using VBA, and that’s pretty cool."
  },
  {
    "objectID": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#improvements",
    "href": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#improvements",
    "title": "Post: Some Thoughts on VBA Tetris",
    "section": "Improvements?",
    "text": "Improvements?\nThe Tetris that I implemented here is a highly simplified and pared-down version of the real game. The most glaring omission is that there is no “game loop”, and thus the game will proceed at whatever pace the user wishes. As any Tetris player knows, this is not how the game usually works4. The lack of a game loop means that it is difficult to implement a reasonable gravity system that continuously pulls pieces downward, and thus my version just teleports pieces down to the bottom. While this simplifies the code, it eliminates important aspects of the game, such as tucking a new piece underneath an existing piece to fill in gaps.\nI do not see any technical reason why a timed game loop couldn’t be implemented using VBA. All you would really need is a means of tracking time increments on the order of 10-20 milliseconds5, and then processing a set of instructions at each increment. While I haven’t looked too closely at the speed or optimization of VBA code, it seems like it ought to be fast enough to process and render the game at lower drop speeds at least."
  },
  {
    "objectID": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#footnotes",
    "href": "projects/tetris/tetris-vba/post-thoughts-tetris-vba.html#footnotes",
    "title": "Post: Some Thoughts on VBA Tetris",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“Fossil” is probably a bit unfair, since Visual Basic was created in 1991 and is thus no older than Python.↩︎\nThis StackOverflow answer does a good job explaining the “what” of the rules, but not really the “why”.↩︎\nPostgreSQL is probably still the winner there, but really the sky’s the limit.↩︎\nThis should provide some sense of how fast a real game can go.↩︎\nNES Tetris, a very popular version of Tetris, runs at ~60 frames per second.↩︎"
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html",
    "href": "projects/tetris/tetris-spark/tetris-spark.html",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html#overview",
    "href": "projects/tetris/tetris-spark/tetris-spark.html#overview",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "Overview",
    "text": "Overview\nThis project implements an algorithm in Apache Spark that solves the stacking portion of Tetris for a specified board width. Since the piece order in Tetris is randomized, the challenge of stacking pieces lies in knowing what stack configuration can handle the widest variety of possible piece sequences before a hole is created in the stack. Starting from a given stack configuration, the algorithm uses recursion to compute the average number of pieces that a player will be able to place under optimal play before creating a hole. Once a table of these average values is computed, the optimal strategy is to always place the next piece such that the average for the new stack configuration is maximized.\nThe walkthrough.ipynb notebook in the GitHub repo (linked above) contains a description of the algorithm along with a sample calculation for a small Tetris board. The full source code is contained in the analyze.py, generate.py, and play.py Python modules, which can be run in the environment generated by requirements.txt.\nA non-interactive version of the Jupyter notebook is reproduced below."
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html#the-stacking-game",
    "href": "projects/tetris/tetris-spark/tetris-spark.html#the-stacking-game",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "The Stacking Game",
    "text": "The Stacking Game\nTetris is arguably the most popular video game ever made, having seen countless releases on virtually every piece of computer hardware imaginable. The game was originally developed by Alexey Pajitnov in 1985, and requires the player to stack a set of falling pieces called “tetrominos” into a continuous tower, such that there are no gaps between the pieces. Points are scored by filling in an entire row of blocks, at which point those blocks are removed from the board and the height of the tower is reduced. The game ends when the player is unable to clear rows fast enough and allows the tower to reach the top of the board.\nThe challenge of Tetris comes from the shapes of the tetrominos, which consist of all seven polygons that can be built from four equally-sized square blocks. These pieces can be rotated and translated as they fall, with the player needing to interlock them together into a continuous stack in order to clear rows. Since the order of the pieces is random and unknown to the player, an optimal strategy must consider not only the placement of the current piece, but also how the next piece (and all subsequent pieces) can be incorporated into the tower. The overarching goal is to ensure that each piece fits with the previous pieces to form a continuous surface devoid of holes, so that rows can be cleared. This is the challenge that we wish to “solve” using an algorithm.\nThe word “solve” is presented here in quotes because our goal is not to find the optimal strategy in its entirety. Instead, we seek only an optimal strategy for stacking pieces until it is impossible to prevent a hole from forming somewhere in the tower. In a real game of Tetris this does not cause play to end, as there are ways of repairing these holes and continuing the stack. By focusing solely on continous piece stacking, we drastically reduce the complexity of the problem, making it possible to find strong solutions with reasonable computational resources."
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html#problem-complexity",
    "href": "projects/tetris/tetris-spark/tetris-spark.html#problem-complexity",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "Problem Complexity",
    "text": "Problem Complexity\nTo pin down the overall complexity of this problem, we must define the height and width of the area where we are allowed to stack pieces (referred to as the board). In standard Tetris the board is 20 blocks high and 10 blocks across, but for maximum scoring it is common to initially leave the left-most column unfilled while stacking. This means that the maximum effective play area is 20 x 9, which can fit 21^9 = 794,280,046,581 differently-shaped piece stacks inside of it. In general, the number of possible stacks is given by (height + 1)^width, since each column can have a number of blocks in the range [0, height], and there are width distinct columns with their own independent configurations.\nFor each tower configuration, we will need to consider all of the possible ways that the tetrominos can be stacked on top without creating any holes. There is no simple formula for this quantity, as it is highly dependent on the specific contours of the stack. A more concrete quantity to consider is the maximum number of pieces that can be placed in a sequence. Since no piece can be placed when the board is completely full, and since each piece has four blocks, we can stack at most height * width / 4 pieces before completely running out of room. The full 20 x 9 board, for example, can have at most 45 pieces in any sequence, although most towers will terminate significantly earlier than this."
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html#description-of-the-algorithm",
    "href": "projects/tetris/tetris-spark/tetris-spark.html#description-of-the-algorithm",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "Description of the Algorithm",
    "text": "Description of the Algorithm\nSince Tetris is a game with incomplete information (the sequence of pieces), we will seek a strategy that maximizes the average performance over all sequences. Our measure of performance will be the number of pieces stacked before a hole is formed, with an optimal strategy maximizing this number. Such a strategy can be found via recursion by computing a set of sequence-limited averages, up to the maximum number that can fit on the board. The optimal strategy is then to place each piece such that you end up with a tower configuration that has the highest expected stack length, conditioned on the remaining number of pieces that can be stacked before filling the board.\nTo compute the required set of averages, we can follow an algorithm with the following steps for each tower configuration:\n\nCompute the valid placements for all seven tetrominos, taking into account every possible translation and rotation.\nCompute the probability that the next piece in the sequence will be possible to stack without creating a hole. This is the average number of placed pieces for a sequence of length 1.\nFor each piece type, find the tower configuration with the highest average computed in step 2 that can be reached by placing that piece type, and then compute a new average by taking the mean of these maximimal averages. This is the average number of placed pieces for a sequence of length 2.\nRepeat step 3 n more times, maximizing the averages generated from the previous iteration in the cycle. This gives the average number of placed pieces for a sequence of length n + 2. The value of n should be chosen so that n - 2 is less than the maximum number of pieces that can fit on the board.\n\nEach portion of this algorithm can be carried out using the DataFrame API in Apache Spark.\n\nComputing the connections\nFor step 1 of the algorithm, we need to compute all of the different ways that a starting tower configuration can transition to a different configuration after placing a piece. To do this, we start by defining two different ways to represent a Tetris board. Since we are only interested in towers without holes, we can describe each configuration uniquely by listing out the height of each column. This array-based representation can be compressed into a single integer (which we will call the board id) by adding together powers of the board height. For a standard height of 20, we construct an integer that is 21^0 = 1 times the height of the first column, 21^1 = 21 times the height of the second column, 21^2 = 441 times the height of the third column, and so on. This ensures that each board has a single unique integer that represents it. The code which converts between these two representations is given below.\nimport math\n\ndef get_board_columns(board_id, height, width):\n    board = []\n    for x in range(1, width + 1):\n        height_power = (height + 1)**(x - 1)\n        shift_to_ones = math.floor(board_id / height_power)\n        digit = shift_to_ones % (height + 1)\n        board.append(digit)\n    return board\n\ndef get_board_id(board, height):\n    width = len(board)\n    board_id = 0\n    for x in range(1, width + 1):\n        power = (height + 1)**(x - 1)\n        board_id += board[x - 1]*power\n    return board_id\n\ntest_id = 145672560876\ntest_board = get_board_columns(test_id, 20, 9)\ninverted_id = get_board_id(test_board, 20)\nprint(f\"Map id to columns and then back to id: {test_id} -&gt; {test_board} -&gt; {inverted_id}.\")\nMap id to columns and then back to id: 145672560876 -&gt; [3, 6, 8, 7, 4, 10, 18, 17, 3] -&gt; 145672560876.\nNote that the two representations are useful in different situations: the board id works great as a unique key to specify a given board, but is very difficult to visualize. The column heights, by contrast, are more verbose but somewhat easier to understand at a glance.\nTo compute the different connections between tower configurations, we will start with a Spark DataFrame that is populated with all possible board ids using the range function. Each row will then be expanded into its height-based representation using a set of column functions that mimic get_board_columns from the previous code block. To determine where pieces can be placed without creating holes, we must match the contour of the tower with the bottom of the piece. The possible contours for each of the seven tetrominos are returned by the following function:\ndef get_piece_maps():\n    pieces = {}\n    pieces[\"i\"] = [([0, 0, 0], [1, 1, 1, 1]), ([], [4])]\n    pieces[\"t\"] = [([-1, 1], [1, 2, 1]), ([-1], [1, 3]), ([0, 0], [1, 2, 1]), ([1], [3, 1])]\n    pieces[\"sq\"] = [([0], [2, 2])]\n    pieces[\"zr\"] = [([0, 1], [1, 2, 1]), ([-1], [2, 2])]\n    pieces[\"zl\"] = [([-1, 0], [1, 2, 1]), ([1], [2, 2])]\n    pieces[\"lr\"] = [([1, 0], [2, 1, 1]), ([-2], [1, 3]), ([0, 0], [1, 1, 2]), ([0], [3, 1])]\n    pieces[\"ll\"] = [([0, -1], [1, 1, 2]), ([0], [1, 3]), ([0, 0], [2, 1, 1]), ([2], [3, 1])]\n    return pieces\nEach piece is represented by a pair of tuples, with the first tuple containing the relative changes in column height that are needed (for each of the possible piece orientations) in order to place the piece without creating any holes. By looping through all positions, we can compute all valid placements and thus all connections to other tower configurations. The following code shows a Spark routine that will carry out these calculations for an arbitrary height and width (resources permitting):\nimport pyspark.sql.functions as sfn\nimport pyspark.sql.types as stype\n\nfrom src import analyze\n\ndef generate_connections(height, width, spark_session):\n\n    # Ths function finds all mappings from one tower configuration to\n    # another that occur when placing a Tetris piece. The resulting table\n    # has columns \"id\", \"new_id\", and \"piece\", with \"new_id\" being the tower\n    # configuration that can be reached by adding \"piece\" to the board represented\n    # by \"id\".\n\n    max_id = (height + 1)**width \n    ids = spark_session.range(max_id) # DataFrame populated by all possible board ids \n    all_cols = get_board_columns(height, width)\n    boards = ids.withColumns(all_cols) # Dataframe now has board heights as well as ids\n    schema = stype.StructType([\n        stype.StructField(\"id\", stype.LongType(), False), \n        stype.StructField(\"new_id\", stype.LongType(), True), \n        stype.StructField(\"piece\", stype.StringType(), False)])\n    all_connections = spark_session.createDataFrame([], schema = schema) # Empty dataframe that will be iteratively updated\n    for (piece_name, maps) in analyze.pieces.items():\n        for (surface, piece_heights) in maps:\n            piece_width = len(piece_heights)\n            if piece_width &lt;= width: # Pieces wider than the board cannot be placed\n                for pos in range(1, width - piece_width + 2): # Iterate over all positions that the piece can be stacked at\n                    col_list = [sfn.col(f\"{x + pos}\") for x in range(piece_width)] # List columns that are intersected by piece\n                    diff_list = [col_2 - col_1 for (col_1, col_2) in zip(col_list[:-1], col_list[1:])] # Get relative heights of columns\n                    board_surfaces = boards.select(\"*\", *diff_list)\n                    matched_boards = board_surfaces\n                    for (col, diff) in zip(diff_list, surface):\n                        matched_boards = matched_boards.filter(col == diff) # Piece can only be placed if it exactly matches the tower surface\n                    raised_cols = {f\"{x + pos}\":(col + added) for (x, (col, added)) in enumerate(zip(col_list, piece_heights))}\n                    raised_boards = matched_boards.select(*boards.columns).withColumns(raised_cols) # Generate new board after adding piece\n                    valid_boards = raised_boards\n                    for col in col_list:\n                        valid_boards = valid_boards.filter(col &lt;= height) # Remove tower configuration that are too tall\n                    new_id_col = get_board_id(height, width)\n                    connections = valid_boards.select(\"id\", new_id_col.alias(\"new_id\"), sfn.lit(piece_name).alias(\"piece\"))\n                    all_connections = all_connections.union(connections)\n    return all_connections\nThis function assembles the full connections table out of subtables corresponding to each piece and placement position. While the number of tower configurations and thus connections will scale exponentially with the board width, the operations themselves are all narrow and can be done in a distributed manner without any shuffle operations.\n\n\nComputing the averages\nAfter the connections are tabulated, the rest of the algorithm focuses on computing the average number of pieces that can be placed before the formation of a hole is unavoidable. Since our goal is to choose a strategy that maximizes this average, we will want to stack pieces such that we always move to a new configuration that itself has a high average. For a finite number of pieces, we can always construct an algorithm that starts with a piece sequence of length one and then recursively computes optimal averages for a sequence of length n using results from length n -1. The key observation is that the nth optimal average is just one plus a weighted sum of the n-1 averages maximized with respect to each of the seven possible pieces. The code for this portion of the algorithm is given below:\nimport pyspark.sql.functions as sfn\n\ndef generate_avgs(height, width, spark_session):\n\n    # This function uses the connection table created by generate_connections\n    # to compute the average number of successful piece placements before a hole\n    # is formed. This average is calculated with respect to optimal piece placement,\n    # which is enforced via a recursive algorithm.\n\n    all_connections = spark_session.read.format(\"parquet\").load(\"connection_path\")\n    ids = spark_session.range((height + 1)**width)\n    avgs = old_avgs = ids.withColumn(\"avg\", sfn.lit(0.0)) # This is the \"average\" for a piece sequence of length 0\n    max_depth = int(height*width / 4)\n    for depth in range(max_depth + 1):\n        if depth &gt; 0: # Iterations greater than length 0 are generated from previously-saved results\n            avgs.write.format(\"parquet\").save(f\"{width}-{height}/{depth}\")\n            old_avgs = spark_session.read.format(\"parquet\").load(f\"{width}-{height}/{depth}\")\n        print(f\"Depth: {depth}\")\n        # The first step of the algorithm is to append the previous averages for each \"new_id\" column in the connections table\n        connection_avgs = all_connections.alias(\"c\").join(old_avgs.alias(\"a\"), sfn.col(\"c.new_id\") == sfn.col(\"a.id\"), \"left\")\n        connection_avgs = connection_avgs.select(\"c.id\", \"c.piece\", \"a.avg\").fillna(0.0)\n        # Then, the maximum avg is chosen for each starting configuration and piece\n        best_choice = connection_avgs.groupBy(\"id\", \"piece\").agg(sfn.max(\"avg\").alias(\"max_avg\"))\n        # Finally, a weighted average of one plus the previous max averages is computed\n        avgs = best_choice.select(\"id\", (1/7 + sfn.col(\"max_avg\")/7).alias(\"max_avg\")).groupBy(\"id\").agg(sfn.sum(\"max_avg\").alias(\"avg\"))\n        depth +=1\nUnlike the connection algorithm from the previous section, the Spark operations here involve join and aggregation functions that require shuffling of the partition data. This is fundamentally unavoidable, as the data cannot be partitioned in a way that is efficient for both the extraction of previous averages (the join) and computation of the optimal piece placement (the aggregation) simultaneously."
  },
  {
    "objectID": "projects/tetris/tetris-spark/tetris-spark.html#results",
    "href": "projects/tetris/tetris-spark/tetris-spark.html#results",
    "title": "“Solving” Tetris with Apache Spark",
    "section": "Results",
    "text": "Results\nA single computer can comfortably compute results for a board width of around 6, but for simplicity we will look at a smaller playfield that is only 4 blocks wide. To validate the results of the algorithm, we can play a large number of Tetris games and compare the observed mean sequence length with the predicted length. This is implemented in the following code from play.py:\nimport random\n\nimport pyspark.sql as sql\nimport pyspark.sql.functions as sfn\n\nfrom src import analyze\n\nclass Avgs():\n    \n    # This class handles the retrieval of averages from the tables computed\n    # in generate.py.\n    \n    def __init__(self, spark, height, width, memory = False):\n        \n        # The class can operate in memory mode if the number of tower configurations is\n        # small enough, or it can read data directly from the parquet files.\n            \n        num_pieces = int(height*width / 4)\n        self.board_avgs = spark.read.format(\"parquet\").load(f\"example_data/avgs_20-4\")\n        if memory:\n            self.board_dict = {row.asDict()[\"id\"]:row.asDict()[\"avg\"] for row in self.board_avgs.toLocalIterator()}\n        self.memory = memory\n\n    def get(self, board_id):\n        if self.memory:\n            avg = float(self.board_dict.get(int(board_id), 0))\n        else:\n            rows = self.board_avgs.filter(sfn.col(\"id\") == board_id).select(\"avg\").collect()\n            avg = rows[0].asDict()[\"avg\"] if rows else 0\n        return avg\n\ndef play_game(start_board, height, num_moves, avgs):\n    \n    # This function plays a game of Tetris using the\n    # provided starting configuration, height, and number\n    # of moves. For each piece, the placement with the\n    # highest average is chosen.\n    \n    board = start_board\n    moves = [start_board]\n    for i in range(num_moves, 0, -1):\n        piece = random.choice(list(analyze.pieces.keys()))\n        connections = analyze.get_connections(board, height)\n        choices = []\n        for board in connections[piece]:\n            board_id = analyze.get_board_id(board, height)\n            avg = avgs.get(str(board_id))\n            choices.append((board, avg))\n        if len(choices) == 0:\n            break\n        board = max(choices, key = lambda tupl:tupl[1])[0]\n        moves.append(board)\n    return moves\n\ndef multiple_runs(runs, start_board, height, num_pieces, avgs):\n    \n    # This function plays a given number of Tetris games using the\n    # specified parameters, and then prints the theoretical average,\n    # observed average, and best performance.\n    \n    expected = avgs.get(analyze.get_board_id(start_board, height))\n    move_lists = []\n    for game in range(runs):\n        moves = play_game(start_board, height, num_pieces, avgs)\n        move_lists.append(moves)\n        print(f\"\\rGame {game + 1} / {runs}\", end = \"\")\n    totals = [len(moves[1:]) for moves in move_lists]\n    print(\"\")\n    print(f\"Exp: {expected:.4f} | Avg: {sum(totals) / runs:.4f} | Best:{max(totals)}\")\n    return move_lists\n\nboard = 1\nheight = 20\nwidth = 4\nruns = int(1e5)\nnum_pieces = int(height*width / 4)\n\nspark = sql.SparkSession.builder.config(\"spark.driver.memory\", \"15g\").config('spark.ui.showConsoleProgress', False).getOrCreate()\navgs = Avgs(spark, height, width, memory = True)\nstart_board = analyze.get_board_columns(board, height, width)\nruns = multiple_runs(runs, start_board, height, num_pieces, avgs)"
  },
  {
    "objectID": "projects/phd/phd.html",
    "href": "projects/phd/phd.html",
    "title": "Research at UC Berkeley",
    "section": "",
    "text": "From 2018 to 2023, I worked as a graduate researcher while completing my PhD at the University of California, Berkeley. My research projects were overseen by Professor K. Birgitta Whaley, who specializes in quantum technologies, and focused on the intersection of machine learning and quantum computing. In one direction, I used classical techniques from machine learning to improve the operations of quantum hardware, while in the other I investigated new machine learning algorithms that could be run on a quantum computer.\nDuring my time at UC Berkeley I published six peer-reviewed papers, four as the main author and two as a secondary author. A list of these papers is given below in reverse chronological order:\n\nLiao, H.; Convy, I.; Yang, Z.; Whaley, K. B. Decohering Tensor Network Quantum Machine Learning Models. Quantum Mach. Intell. 2023, 5 (1), 7.\nConvy, I.; Whaley, K. B. Interaction Decompositions for Tensor Network Regression. Machine Learning: Science and Technology 2022, 3 (4), 045027.\nConvy, I.; Liao, H.; et al. Machine Learning for Continuous Quantum Error Correction on Superconducting Qubits. New J. Phys. 2022, 24 (6), 063019.\nConvy, I.; Whaley, K. B. A Logarithmic Bayesian Approach to Quantum Error Detection. Quantum 2022, 6, 680.\nConvy, I.; Huggins, W.; Liao, H.; Whaley, K. B. Mutual Information Scaling for Tensor Network Machine Learning. Mach. Learn.: Sci. Technol. 2022, 3 (1), 015017.\nLiao, H.; Convy, I.; Huggins, W. J.; Whaley, K. B. Robust in Practice: Adversarial Attacks on Quantum Machine Learning. Phys. Rev. A 2021, 103 (4), 042427.\n\nMy dissertation Interrogating the Tensor Network Regression Model, which can be read here, focused specifically on tensor network machine learning, and included an additional unpublished paper in Chapter 5 which analyzed the tensor rank of multilinear regression models.\nFor the four papers that I directly authored, I have created three code demos that showcase the main methods that were employed:\n\nInteraction Decomposition for Tensor Network Machine Learning\n\nThis page describes the decomposition algorithm used in paper 2, and how it can be applied to tensor network machine learning algorithms. All of the paper’s major beats are covered in the demo, which can be run from the associated Jupyter notebook on GitHub.\n\nBayesian Inference for Quantum Error Correction\n\nThis page offers an introduction to the Bayesian error correction algorithms used in papers 3 and 4, and gives example code for it in PyTorch. The code provides a basic implementation of the algorithm, and does not include some of the details that were included in the published works. The code can be run from the associated Jupyter notebook on GitHub.\n\nQuantifying Mutual Information via Logistic Regression\n\nThis page describes the correlation analysis carried out in paper 5, including both the neural network algorithm and the Gaussian distributions used to test it. While the large Tiny Images dataset is too large to include, the algorithm can be run on MNIST using the associated Jupyter notebook on GitHub."
  },
  {
    "objectID": "projects/phd/decomp/deomp.html",
    "href": "projects/phd/decomp/deomp.html",
    "title": "Interaction Decomposition for Tensor Network Machine Learning",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/phd/decomp/deomp.html#overview",
    "href": "projects/phd/decomp/deomp.html#overview",
    "title": "Interaction Decomposition for Tensor Network Machine Learning",
    "section": "Overview",
    "text": "Overview\nThis research project introduced a novel approach to decomposing the contractions in a tensor network, and used it to analyze supervised tensor network machine learning algorithms. This work culminated in the publication “Interaction Decompositions for Tensor Network Regression”, whose abstract is given below:\n\nIt is well known that tensor network regression models operate on an exponentially large feature space, but questions remain as to how effectively they are able to utilize this space. Using a polynomial featurization, we propose the interaction decomposition as a tool that can assess the relative importance of different regressors as a function of their polynomial degree. We apply this decomposition to tensor ring and tree tensor network models trained on the MNIST and Fashion MNIST datasets, and find that up to 75% of interaction degrees are contributing meaningfully to these models. We also introduce a new type of tensor network model that is explicitly trained on only a small subset of interaction degrees, and find that these models are able to match or even outperform the full models using only a fraction of the exponential feature space. This suggests that standard tensor network models utilize their polynomial regressors in an inefficient manner, with the lower degree terms being vastly under-utilized.\n\nThe examples.ipynb notebook in the GitHub repo (linked above) provides a general overview of the paper’s methodology, along with sample code for some simple examples, while the remaining source code can be found in the src directory. A non-interactive version of the Jupyter notebook is reproduced below."
  },
  {
    "objectID": "projects/phd/decomp/deomp.html#a-brief-introduction-to-tensor-network-machine-learning",
    "href": "projects/phd/decomp/deomp.html#a-brief-introduction-to-tensor-network-machine-learning",
    "title": "Interaction Decomposition for Tensor Network Machine Learning",
    "section": "A Brief Introduction to Tensor Network Machine Learning",
    "text": "A Brief Introduction to Tensor Network Machine Learning\nTensor network machine learning is a fairly new area of ML research, in which a model is constructed out of a network of parameterized tensors. A tensor is best understood as a multidimensional array of numbers, which generalizes the matrix and vector objects from linear algebra. The number of dimensions in a tensor is referred to as its order, such that a vector is a first-order (1D) tensor and a matrix is a second-order (2D) tensor. Machine learning models can be built by joining multiple tensors together in a graph or network, with each edge of the graph denoting the multiplication of the tensors on the connected nodes.\nWhile a detailed description of tensor network machine learning is beyond the scope of this notebook, the basic pipeline can be summarized in the following steps:\n\nImplicitly transform the feature vectors of the target dataset into elements of an exponentially large space\nMultiply these transformed samples by the tensors in the network which parameterize the model\nOptimize the elements of those tensors using the output of the tensor multiplication\nRepeat steps 1-3 until the loss function converges.\n\nIn practice, we can implement these steps easily using the Keras API in TensorFlow (or another ML package) with custom layers for steps 1 and 2.\n\nAn example tensor network model\nIn the following code block, we can see a custom Keras layer that implements the first step in our procedure:\nimport tensorflow as tf\n\nclass Pow_Feat_Layer(tf.keras.layers.Layer):\n    def __init__(self, max_power, dtype = \"float32\"):\n        super().__init__(dtype = dtype)\n        self.powers = tf.range(max_power + 1, dtype = dtype)[None, None]\n\n    def call(self, inputs):\n        output = inputs[..., None] ** self.powers\n        return output   \nThis class inherits from the Keras Layer class, and operates by expanding the \\(n \\times m\\) batch of feature vectors into an \\(n\\times m \\times p + 1\\) batch of feature matrices. For a given sample matrix, the \\(i\\)th row has the form \\([1, x_i, x^2_i,...,x^p_i]\\), where \\(x_i\\) is the \\(i\\)th data feature and \\(p\\) is the maximum power. Implicitly, we view the sample matrix as representing a tensor formed from the tensor product of each row, which would be an element of a massive \\(p^m\\)-dimensional tensor space.\nFor step 2, can implement another custom Keras layer that carries out the tensor multiplication of our network with the output from Pow_Feat_Layer. The following code block provides an example of such a layer:\nimport tensorflow as tf\n\nclass MPS_Layer(tf.keras.layers.Layer):\n    def __init__(self, bond_dim, num_classes, dtype = \"float32\"):\n        super().__init__(dtype = dtype)\n        self.bond_dim = bond_dim\n        self.num_classes = num_classes\n        self.set_decomp(False)\n\n    def build(self, input_shape):\n        (_, num_sites, phy_dim) = input_shape[:3]\n        self.num_sites = num_sites\n        self.split = tf.Variable(num_sites // 2, trainable = False) # The output is placed in the middle\n        self.matrix_weights = self.add_weight(\"matrix_weights\",\n            [phy_dim, num_sites, self.bond_dim, self.bond_dim], self.dtype, self.initializer)\n        self.middle = self.add_weight(\"middle\", # This tensor is the output component of the network\n            [self.num_classes, self.bond_dim, self.bond_dim], self.dtype, self.middle_initializer)\n\n    def call(self, inputs, **kwargs):\n\n        # This function generates a prediction on the passed input batch.\n\n        split_data = tf.concat([inputs[:, self.split:], inputs[:, :self.split]], 1)\n        matrices = tf.einsum(\"nij,jikl-&gt;inkl\", split_data, self.matrix_weights)\n        matrix_prod = self.reduction(matrices)\n        outputs = tf.einsum(\"nkl,olk-&gt;no\", matrix_prod, self.middle)\n        return outputs\n\n    @staticmethod\n    def initializer(shape, dtype):\n\n        # This function initializes the component tensors of the network.\n        # The tensors need to be initialized such that they basically act \n        # like the identity.\n        \n        (phys_dim, num_sites, bond_dim, bond_dim) = shape\n        bias = tf.tile(tf.eye(bond_dim, dtype = dtype)[None, None], (1, num_sites, 1, 1))\n        kernel = tf.random.normal([phys_dim - 1, num_sites, bond_dim, bond_dim], 0, 1e-2, dtype)\n        weights = tf.concat([bias, kernel], 0)\n        return weights\n\n    @staticmethod\n    def middle_initializer(shape, dtype):\n        \n        # This function initializes the output component tensor.\n\n        (num_sites, bond_dim, bond_dim) = shape\n        weights = tf.tile([tf.eye(bond_dim, dtype = dtype)], (num_sites, 1, 1))\n        noised = weights + tf.random.normal(weights.shape, 0, 1e-2, dtype = dtype)\n        return noised\n\n    @staticmethod\n    def reduction(tensor):\n\n        # This function performs an efficient contraction of the MPS\n        # component matrices generated by contraction with the data\n        # vectors.\n\n        size = int(tensor.shape[0])\n        while size &gt; 1:\n            half_size = size // 2\n            nice_size = 2 * half_size\n            leftover = tensor[nice_size:]\n            tensor = tf.matmul(tensor[0:nice_size:2], tensor[1:nice_size:2])\n            tensor = tf.concat([tensor, leftover], axis = 0)\n            size = half_size + int(size % 2 == 1)\n        return tensor[0]\nAs before, this layer inherits from the Keras Layer base class, and overloads the build and call methods. The self.matrix_weights array holds the parameters of the tensor network model, with each slice along the first dimension corresponding to a third-order tensor on one of the graph nodes. There are many different kinds of tensor networks, with this layer implementing a matrix product state (MPS) architecture. Note that custom initialization functions are needed in order to generate a numerically-stable output, and that the tensor multiplication can be performed efficiently in parallel. Once an output is generated, the parameters in self.matrix_weights (and self.middle) can be optimized in step 3 using stochastic gradient descent as would be done for a neural network."
  },
  {
    "objectID": "projects/phd/decomp/deomp.html#the-interaction-decomposition",
    "href": "projects/phd/decomp/deomp.html#the-interaction-decomposition",
    "title": "Interaction Decomposition for Tensor Network Machine Learning",
    "section": "The Interaction Decomposition",
    "text": "The Interaction Decomposition\nFor a tensor network regression model using Pow_Feat_layer with \\(p = 1\\) (which is most common), the prediction \\(y\\) for sample vector \\(\\vec{x}\\) is given by\n\\[\\begin{equation}\ny = w_0 + \\sum^m_{i=1}w_ix_i + \\sum^{m-1}_{i=1}\\sum^m_{j = i+1}w_{ij}x_ix_j + ... + w_{1,2,...,m}x_1x_2\\cdots x_m,\n\\end{equation}\\]\nwhich is linear regression (with coefficients \\(w\\) generated by the tensor multiplication) on every possible product of the original features. In an interaction decomposition, we explicitly separate out contributions to \\(y\\) based on the number of features multiplied together in the regressors. This interaction degree ranges from 0 in the bias term \\(w_0\\) to \\(m\\) in the term \\(w_{1,2,...,m}x_1x_2\\cdots x_m\\) which is the product of all features. Once the different interactions are disentangled, we can analyze their properties and modify their values individually.\nIt turns out that the interaction decomposition can be implemented in a fairly straightforward manner by tweaking how the tensor operations are performed. The following code block performs an interaction decomposition for the MPS model shown previously:\nimport tensorflow as tf\n\ndef decomp(self, inputs, indices, **kwargs):\n    max_order = indices[-1].shape[0]\n    split_data = tf.concat([inputs[:, self.split:], inputs[:, :self.split]], 1)\n    order_matrices = tf.einsum(\"nsrj,jskl-&gt;rnskl\", split_data, self.matrix_weights)\n    cuml = order_matrices[:, :, 0]\n    for i in range(1, self.num_sites):\n        order_matrix = order_matrices[:, :, i]\n        contract = tf.einsum(\"rnkl,qnlm-&gt;qrnkm\", cuml, order_matrix)\n        combined = contract[0, 1:] + contract[1, :-1]\n        cuml = tf.concat([contract[0, :1], combined, contract[1, -1:]], 0)[:max_order]\n    order_output = tf.einsum(\"rnlm,oml-&gt;nor\", cuml, self.middle)\n    return order_output\nThe key modification is that each tensor is given an extra dimension which separates the different interaction degrees. When two tensors are multiplied together, the slices along this extra dimension are matched up and summed together to preserve the interaction degree."
  },
  {
    "objectID": "projects/phd/decomp/deomp.html#numerical-experiments",
    "href": "projects/phd/decomp/deomp.html#numerical-experiments",
    "title": "Interaction Decomposition for Tensor Network Machine Learning",
    "section": "Numerical Experiments",
    "text": "Numerical Experiments\nWe will now perform numerical tests using the interaction decomposition on two different tensor network models: the MPS introduced previously, and a binary tree network called a TTN. We will train these models to classify images from the MNIST and Fashion MNIST datasets, though we will shrink them down from \\(28 \\times 28\\) to \\(8 \\times 8\\) to speed up our computations. The following code retrieves and plots a pair of example images:\nimport tensorflow as tf\nfrom skimage import transform\nimport matplotlib.pyplot as plt\n\ndef get_example_image(fashion = False):\n    if fashion:\n        image = tf.keras.datasets.fashion_mnist.load_data()[0][0][1]\n    else:\n        image = tf.keras.datasets.mnist.load_data()[0][0][1]\n    image = image / 255\n    image = image[4:24, 4:24] # Remove black border before resizing\n    image = transform.resize(image, (8, 8)) - 0.5\n    return image\n\nmnist_image = get_example_image()\nfashion_image = get_example_image(fashion = True)\n\n(fig, axes) = plt.subplots(1, 2)\naxes[0].imshow(mnist_image, cmap = \"gray\")\naxes[1].imshow(fashion_image, cmap = \"gray\")\nplt.show()\n\n\n\nCode output: MNIST on left, Fashion MNIST on right.\n\n\nNote that both images are largely recognizable after being shrunk, though this can vary depending on the image for Fashion MNIST.\n\nCNN baseline\nTo get a sense of how difficult these two transformed datasets are to classify, we can run an experiment using an Inception-based CNN classifier as a state-of-the-art comparison point. The following code imports the model architecture from cnn.py and then trains it for 50 epochs on either MNIST or Fashion MNIST as specified.\nimport tensorflow as tf\n\nfrom src import data, cnn\n\nfashion = False\n\ndata_function = data.get_fashion_data if fashion else data.get_mnist_data\n((x_train, y_train), (x_test, y_test)) = data_function(border = False, size = (8, 8))\nx_train = tf.reshape(x_train, [-1, 8, 8])\nx_test = tf.reshape(x_test, [-1, 8, 8])\nx_train = tf.tile(x_train[..., None], (1, 1, 1, 3))\nx_test = tf.tile(x_test[..., None], (1, 1, 1, 3))\n\nmodel = cnn.build_inception(x_train)\nmodel.compile(loss = 'categorical_crossentropy', \n                optimizer = tf.keras.optimizers.Adamax(learning_rate = 0.006, beta_1 = 0.49, beta_2 = 0.999),\n                metrics = ['accuracy'])\nmodel.fit(x_train, y_train, 64, 50, validation_split = 1/6, verbose = 1)\nscore = model.evaluate(x_test, y_test, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\nAfter training, we find accuracies of 99.2-99.3% on MNIST and accuracies of 86.4-86.8% on Fashion MNIST. This shows that the \\(8 \\times 8\\) Fashion MNIST images are significantly harder to classify than the full \\(28 \\times 28\\) images, while MNIST does not seem to have been affected much by the resizing.\n\n\nMPS and TTN models\nThe next models that we will test are the regular MPS and TTN tensor network models. For this initial set of experiments, we will perform the tensor operations normally during training, and then carry out the interaction decomposition at the end on the test dataset. The following code imports the tensor network models from models.py, trains them, and then saves the results. There are four different training combinations that can be selected, using either an MPS or TTN model and either MNIST or Fashion MNIST for training.\nimport tensorflow as tf\n\nfrom src import data, factor, models\n\nmodel_name = \"ttn\" # either \"mps\" or \"ttn\"\ndataset = \"fashion\" # either \"mnist\" or \"fashion\"\nsave = True\n\n((train_x, train_y), (test_x, test_y), num_classes) = data.get_dataset(\n        dataset, size = (8, 8), border = False)\nmodel = models.get_model(model_name, num_classes, dtype = \"float64\", bond_dim = 20)\nmodel.compile(loss = \"mse\",\n    optimizer = tf.keras.optimizers.RMSprop(1e-3),\n    metrics = ['accuracy'],\n    run_eagerly = False)\nmodel.fit(train_x, train_y,\n    batch_size = 128,\n    epochs = 100,\n    verbose = 1,\n    validation_split = 1/6)\n\nscore = model.evaluate(test_x, test_y, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nif save:\n    save_path = f\"src/saved/{model_name}_{dataset}\"\n    model_string = f\"/{model_name}_{num_classes}_20_float64\"\n    model.save_weights(save_path + model_string, save_format = \"tf\")\n    print(\"Computing interaction degrees...\")\n    factor.factorize(save_path, (test_x, test_y))\n    print(\"\\nComplete.\")\nThe contributions from the different interaction degrees for each test sample are saved in the factor.npz compressed NumPy archive. These results can be aggregated into a more interpretable form by the following two functions:\nimport tensorflow as tf\nimport numpy as np\n\ndef get_labeled_order_acc(path):\n    data = np.load(path + \"/factors.npz\")\n    pred = np.argmax(data[\"results\"], 1)\n    labels = np.argmax(data[\"labels\"], -1)[:, None]\n    accs = (pred == labels).mean(0)\n    return tf.convert_to_tensor(accs)\n\ndef get_labeled_cuml_acc(path):\n    data = np.load(path + \"/factors.npz\")\n    labels = np.argmax(data[\"labels\"], -1)[:, None]\n    cum_factors = np.cumsum(data[\"results\"], -1)\n    pred = np.argmax(cum_factors, 1)\n    accs = (pred == labels).mean(0)\n    return tf.convert_to_tensor(accs)\nThese functions compute two different kinds of accuracy values with respect to the interaction decomposition. To get the accuracy of the interaction degrees individually, we use get_labeled_order_acc to compare the argmax for the prediction with the true label for each degree. To get the accuracy of the sum of all interaction degrees less than or equal to a given value, we use get_labeled_cuml_acc which sums the different predictions before taking the argmax. When these accuracy values are averaged across ten different model instantiations, we get the following plot:\n\n\n\nPlots of accuracys vs interaction degree.\n\n\nwhere “TR” stands for “tensor ring”, which is a more precise term for our MPS model. The solid lines mark the cumulative accuracy of the interaction degrees, while the scatter plot points mark the individual accuracies of each degree. These plots show that the cumulative accuracies require half or more of the interaction degrees before converging to the final accuracy value, while the individual accuracies all have very poor performances.\n\n\nInteraction-constrained models\nIn this final section, we consider tensor network models which make predictions using only a subset of interaction degrees. In particular, we consider models which use only the \\(j\\)th interaction degree (the degree-j models), or which use the cumulative sum of interaction degree contributions up to the \\(j\\)th degree (the cumulative-j models). We can train these models in precisely the same manner as the full models in the previous section, using only a slightly modified code block:\nimport tensorflow as tf\n\nfrom src import data, factor, models\n\nmodel_name = \"ttn\" # either \"mps\" or \"ttn\"\ndataset = \"mnist\" # either \"mnist\" or \"fashion\"\nsave = True\n\n((train_x, train_y), (test_x, test_y), num_classes) = data.get_dataset(\n        dataset, size = (8, 8), border = False)\nmodel = models.get_model(model_name, num_classes, dtype = \"float64\", bond_dim = 20)\n\nmax_order = [2] # max_order = j gives a cumulative-j model, max_order = [j] gives a degree-j model\nmodel.set_output(True, True)\nmodel.set_order(max_order)\n\nmodel.compile(loss = \"mse\",\n    optimizer = tf.keras.optimizers.RMSprop(1e-3),\n    metrics = ['accuracy'],\n    run_eagerly = False)\nmodel.fit(train_x, train_y,\n    batch_size = 128,\n    epochs = 100,\n    verbose = 1,\n    validation_split = 1/6)\n\nscore = model.evaluate(test_x, test_y, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nif save:\n    decomp = f\"cuml-{max_order}\" if isinstance(max_order, int) else f\"deg-{max_order[0]}\"\n    save_path = f\"src/saved/{model_name}_{dataset}_{decomp}\"\n    model_string = f\"/{model_name}_{num_classes}_20_float64\"\n    model.save_weights(save_path + model_string, save_format = \"tf\")\nIf we train models cumlative-1 through cumulative-10 and degree-1 through degree-10, we can create a plot of their average accuracies versus the interaction degree accuracies in the previous section:\n\n\n\nPlots of accuracy for the interaction-constrained models.\n\n\nwhere the previously plotted results are shown in black. From this new set of plots, we can see that the interaction-constrained models are often as effective as the full models, despite containing far fewer regressors. This suggests that the full tensor network models are using their low-degree regressors in a highly inefficient manner, since the corresponding interaction degree accuracies plotted in black are much lower."
  },
  {
    "objectID": "projects/other/wavelet/wavelet.html",
    "href": "projects/other/wavelet/wavelet.html",
    "title": "Dimensionality Reduction and Generative Modeling using Wavelets",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/other/wavelet/wavelet.html#overview",
    "href": "projects/other/wavelet/wavelet.html#overview",
    "title": "Dimensionality Reduction and Generative Modeling using Wavelets",
    "section": "Overview",
    "text": "Overview\nThis project describes a neural network algorithm that uses wavelets to reconstruct images. The model operates by outputting reasonable estimates of the wavelet coefficients for a sample when given a set of corresponding scale coefficients as an input. The algorithm can be used for generative modeling, with the latent space being the space of scale coefficients at an appropriate level of coarse-graining. Since the wavelet decomposition will significantly lower the dimension of the original data, it is possible to use a simple distribution, such as a Gaussian, to sample from the latent space and generate complex reconstructed outputs.\nThe walkthrough.ipynb Jupyter notebook in the GitHub repository (linked above) contains a description of the neural network model and a tutorial on its use. The full source code is contained in the wavelet.py and mnist_model.py modules in the src folder. A suitable virtual environment can be set up using the requirements.txt file (the requirements.in file lists the direct dependencies).\nA non-interactive version of the Jupyter notebook is reproduced below."
  },
  {
    "objectID": "projects/other/wavelet/wavelet.html#a-brief-introduction-to-wavelets",
    "href": "projects/other/wavelet/wavelet.html#a-brief-introduction-to-wavelets",
    "title": "Dimensionality Reduction and Generative Modeling using Wavelets",
    "section": "A Brief Introduction to Wavelets",
    "text": "A Brief Introduction to Wavelets\nA wavelet is a wave that has a finite extent, such that its amplitude is zero outside of a limited domain. This is a very general definition, and the wavelets of interest to mathematicians and engineers tend to have additional useful properties, such as certain orthogonality conditions. The utility of wavelets comes from their ability to act as a basis for virtually any signal, which allows us to decompose the signal into a linear combination of wavelets. This is similar to the Fourier series for periodic functions, except that wavelets can resolve signal properties in both the frequency and time domains simultaneously. This makes them an exceptionally powerful tool for signal analysis, especially on image and time-series data.\nWhen working with wavelets, there are two key sets of functions: the scaling functions \\(\\phi_{j,k}\\) and the wavelet functions \\(\\psi_{j,k}\\). Each set of functions is generated by a single mother function, which is scaled and translated by a fixed amount to generate the indexed functions:\n\\[\\begin{equation}\n\\phi_{j,k}(x) = 2^{\\frac{j}{2}} \\phi(2^jx - k), \\quad \\quad \\psi_{j,k}(x) = 2^{\\frac{j}{2}} \\psi(2^jx - k)\n\\end{equation}\\]\nFor a given \\(j\\), the scaling functions span a vector space that can describe a signal up to a certain level of detail, with higher values of \\(j\\) corresponding to greater resolution. The \\(j\\)th wavelet function set spans the difference between the scaling spaces corresponding to \\(j\\) and \\(j+1\\), and can be viewed as adding back the detail that is lost in the coarser space. In the following code, we plot examples of the scaling and wavelet mother functions for the “Daubechies 4” wavelet using the library PyWavelets:\nimport pywt\nimport matplotlib.pyplot as plt\n\nw = pywt.Wavelet('db4')\n(phi, psi, x) = w.wavefun(level=20)\n\n(fig, [ax_1, ax_2]) = plt.subplots(1, 2, sharey = True)\nax_1.plot(x, phi)\nax_2.plot(x, psi)\nax_1.set_title(r\"Scaling function $\\phi\\ (x)$\")\nax_2.set_title(r\"Wavelet function $\\psi\\ (x)$\")\nplt.show()\n\n\n\nScaling and wavelet mother functions.\n\n\nNote that the functions have a highly irregular shape, and do not possess any closed-form solution. Instead, their shapes are generated on demand using a numerical algorithm.\nIn a wavelet decomposition, we project a signal into a specified scaling space depending on the level \\(j\\) of detail desired, which generates a set of expansion coefficients for the \\(j\\)th set of scale functions plus coefficients for the wavelet spaces corresponding to each coarse-graining step. The original signal can always be reconstructed from the coarse-grained signal by adding back the wavelet terms, although if these terms are unknown then the fine-grained structure of the signal will be lost. The following code block shows a custom Keras layer in TensorFlow that carries out a wavelet decomposition on the input signal:\nimport tensorflow as tf\n\nclass Wavelet_Decon(tf.keras.layers.Layer):\n    def __init__(self, h, axis, **kwargs):\n\n        # The h_0 and h_1 attributes are the filter values for \n        # computing the scale coefficients and wavelet coefficients\n        # respectively.\n\n        super().__init__(**kwargs)\n        h = tf.constant(h)\n        indices = tf.range(tf.size(h))\n        self.h_0 = h[:, tf.newaxis, tf.newaxis]\n        self.h_1 = tf.reverse(tf.dynamic_stitch([indices[::2], indices[1::2]], [-h[::2], h[1::2]]), [0])[:, tf.newaxis, tf.newaxis]\n        self.basis_indices = tf.range(tf.size(h) - 1)\n        self.axis = axis\n\n    def build(self, input_shape):\n\n        # The permute attribute simply specifies indices for a \n        # transposition that places the target axis at the end\n        # of the tensor shape.\n\n        num_dims = input_shape.rank\n        self.permute = tf.dynamic_stitch([tf.range(num_dims), [self.axis, num_dims-1]], [tf.range(num_dims), [num_dims-1, self.axis]])\n\n    def call(self, inputs):\n\n        # To perform the decomposition, the input is first \n        # appended with a truncated copy of itself so that \n        # it is big enough to allow the filters to act on all\n        # featutes. Then the scale and wavelet coefficients \n        # are computed by convolving the expanded input\n        # with h_0 and h_1.\n\n        inputs = tf.transpose(inputs, self.permute)\n        cycle_indices = self.basis_indices % tf.shape(inputs)[-1]\n        periodic_coeff = tf.concat([inputs, tf.gather(inputs, cycle_indices, axis = -1)], axis = -1)\n        h_0_conv = tf.nn.conv1d(periodic_coeff[..., tf.newaxis], self.h_0, stride = 1, padding = \"VALID\")[..., 0]\n        h_1_conv = tf.nn.conv1d(periodic_coeff[..., tf.newaxis], self.h_1, stride = 1, padding = \"VALID\")[..., 0]\n        scale_coeff = tf.transpose(h_0_conv[..., ::2], self.permute)\n        wavelet_coeff = tf.transpose(h_1_conv[..., ::2], self.permute)\n        outputs = tf.concat([scale_coeff, wavelet_coeff], self.axis)\n        return outputs\nThe core operations within this layer are the pair of convolutions that act on a specified axis of the input. The filters for these convolution are based on the specific choice of wavelet, and allow us to easily compute the scale coefficients for the coarse-grained output along with the associated wavelet coefficients. To compute the wavelet decomposition on higher-dimensional data, we can simply apply this layer on each of the feature axes. The following code shows how the wavelet decomposition acts on an image from the MNIST dataset:\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom src import wavelet\n\nimage = tf.keras.datasets.mnist.load_data()[0][0][0]\nimage = tf.cast(image, \"float32\") / 255\npadded_image = wavelet.Pad_nD()(image)\ndecon_layer = wavelet.Wavelet_Decon_Layer(wavelet.haar)\n\ndecon = decon_layer(image[None])\n\n(fig, axes) = plt.subplots(1, len(decon), figsize = (9.3, 7))\nfor (ax, coeff) in zip(axes, reversed(decon)):\n    ax.imshow(coeff[0], cmap = \"gray\")\nplt.tight_layout()\nplt.show()\n\n\n\nImage coarse-graining from the wavelet decomposition.\n\n\nIn this sequence of plots, we can see the original image of a five on the left, followed by images of decreasing resolution which appear to be divided into four quadrants. The top left quadrant shows the coarse-grained image generated by the wavelet decomposition, while the other three quadrants show the fine-grained detail that was lost relative to the image before it. In the most extreme case, the wavelet decomposition reduces the image down to only a single pixel, but even this level of coarse-graining can be undone by recombining the other three quadrants via an inverse wavelet decomposition. Code for a Keras layer that carries out the inverse decomposition is given here:\nclass Wavelet_Recon(tf.keras.layers.Layer):\n    def __init__(self, h, axis, **kwargs):\n\n        # The h_0 and h_1 attributes are the filter values for \n        # reconstructing portions of the image from the scale\n        # coefficients and wavelet coefficients respectively.\n\n        super().__init__(**kwargs)\n        h = tf.constant(h)\n        indices = tf.range(tf.size(h))\n        self.h_0 = h[::-1, tf.newaxis, tf.newaxis]\n        self.h_1 = tf.reverse(tf.dynamic_stitch([indices[::2], indices[1::2]], [-h[::2], h[1::2]]), [0])[::-1, tf.newaxis, tf.newaxis]\n        self.basis_indices = tf.range(-(tf.size(h) - 2)//2 - 1, 0)\n        self.axis = axis\n\n    def build(self, input_shape):\n\n        # The permute attribute simply specifies indices for a \n        # transposition that places the target axis at the end\n        # of the tensor shape.\n\n        num_dims = input_shape[0].rank\n        self.permute = tf.dynamic_stitch([tf.range(num_dims), [self.axis, num_dims-1]], [tf.range(num_dims), [num_dims-1, self.axis]])\n\n    def call(self, inputs):\n\n        # The layer takes as input a list of two tensors,\n        # which hold the scale and wavelet coefficients\n        # respectively. To recover the original data shape,\n        # zeroes are inserted into the data and then convolved\n        # with the h_0 and h_ attributes to generate the \n        # reconstruction.\n\n        inputs = tf.stack([tf.transpose(inputs[0], self.permute), tf.transpose(inputs[1], self.permute)])\n        cycle_indices = self.basis_indices % tf.shape(inputs)[-1]\n        new_inputs = tf.concat([tf.gather(inputs, cycle_indices, axis = -1), inputs], axis = -1)[..., 1:]\n        batch_shape = tf.shape(inputs)[:-1]\n        up_shape = tf.concat([batch_shape, 2*tf.shape(new_inputs)[-1:]], 0)\n        coeff_up = tf.reshape(tf.stack([tf.zeros_like(new_inputs), new_inputs], -1), up_shape)\n        coeff_up = tf.concat([coeff_up, tf.zeros_like(coeff_up[..., 0:1])], -1)\n\n        scale_coeff = coeff_up[0]\n        wavelet_coeff = coeff_up[1]\n        h_0_conv = tf.nn.conv1d(scale_coeff[..., tf.newaxis], self.h_0, stride = 1, padding = \"VALID\")[..., 0]\n        h_1_conv = tf.nn.conv1d(wavelet_coeff[..., tf.newaxis], self.h_1, stride = 1, padding = \"VALID\")[..., 0]\n        outputs = tf.transpose(h_0_conv + h_1_conv, self.permute)\n        return outputs\nThis layer is similar to that of the wavelet decomposition, except that there are more manipulations of the input to get it into the correct configuration. The core operation though is still a pair of convolutions with filters that are determined by the type of wavelet used in the original decomposition."
  },
  {
    "objectID": "projects/other/wavelet/wavelet.html#wavelet-reconstruction-using-neural-networks",
    "href": "projects/other/wavelet/wavelet.html#wavelet-reconstruction-using-neural-networks",
    "title": "Dimensionality Reduction and Generative Modeling using Wavelets",
    "section": "Wavelet reconstruction using neural networks",
    "text": "Wavelet reconstruction using neural networks\nWavelet reconstruction (i.e. the inverse wavelet decomposition) can always be carried out exactly if we have access to the wavelet coefficients corresponding to each of the coarse-graining operations. However, what if all we had were the scale coefficients? Would it still be possible to reconstruct the signal? For a random signal the answer is clearly no, since a virtually infinite number of higher-resolution signals can correspond to a given coarse-grained signal. That said, if we restrict ourselves to a narrow class of inputs, then it may be possible to infer the missing wavelet coefficients based on the values of the scale coefficients.\nThis task can be understood as a problem in generative modeling, and it should be possible to carry out using a well-trained neural network. Given a full-resolution training sample, we can perform a sequence of wavelet decomposition down to a specified level of coarse-graining, with each decomposition yielding a set of scale coefficients and a set of wavelet coefficients. These sets of coefficients serve as our inputs and target outputs respectively, and we can use them to train a model at each coarse-graining level. Once these models have been trained, we can take a sample from the coarse-grained signal space and upscale it back to the original resolution. The following code shows a composite Keras model that can carry out wavelet reconstruction on MNIST images:\nimport math\nimport tensorflow as tf\n\nclass Wavelet_MNIST():\n    def __init__(self, h):\n\n        # Create layers that will carry out the wavelet decomposition\n        # and reconstruction. \n\n        self.pad_layer = wavelet.Pad_nD()\n        self.decon_layer = wavelet.Wavelet_Decon_Layer(h, coarse_only = True)\n        self.recon_layer = wavelet.Wavelet_nD_Recon(h)\n\n    def build(self):\n\n        # Each of the model cores correspond to a different\n        # coarse-grained input size. The 1x1 and 2x2 models\n        # are dense networks, while the remaining models\n        # are convolutional. \n\n        self.models = []\n        self.cores = []\n\n        model_1_core = tf.keras.models.Sequential([\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, \"relu\"),\n            tf.keras.layers.Dense(128, \"relu\"),\n            tf.keras.layers.Dense(32, \"relu\"),\n            tf.keras.layers.Dense(3),\n            tf.keras.layers.Reshape([1, 1, 3])\n        ])\n        model_1 = self.assemble_model(model_1_core, 1)\n        self.cores.append(model_1_core)\n        self.models.append(model_1)\n\n        model_2_core = tf.keras.models.Sequential([\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, \"relu\"),\n            tf.keras.layers.Dense(128, \"relu\"),\n            tf.keras.layers.Dense(32, \"relu\"),\n            tf.keras.layers.Dense(12),\n            tf.keras.layers.Reshape([2, 2, 3])\n        ])\n        model_2 = self.assemble_model(model_2_core, 2)\n        self.cores.append(model_2_core)\n        self.models.append(model_2)\n\n        model_4_core = tf.keras.models.Sequential([\n            tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1)),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(3, 3, padding = \"same\")\n        ])\n        model_4 = self.assemble_model(model_4_core, 4)\n        self.cores.append(model_4_core)\n        self.models.append(model_4)\n        \n        model_8_core = tf.keras.models.Sequential([\n            tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1)),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(3, 3, padding = \"same\")\n        ])\n        model_8 = self.assemble_model(model_8_core, 8)\n        self.cores.append(model_8_core)\n        self.models.append(model_8)\n\n        model_16_core = tf.keras.models.Sequential([\n            tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1)),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n            tf.keras.layers.Conv2D(3, 3, padding = \"same\")\n        ])\n        model_16 = self.assemble_model(model_16_core, 16)\n        self.cores.append(model_16_core)\n        self.models.append(model_16)\n\n    def train_all(self, train_images, test_images, epochs, batch_size, save = False):\n        for i in range(len(self.models)):\n            length = 2**i\n            print(f\"Training model_{length}\")\n            self.train(length, train_images, test_images, epochs, batch_size, save)\n\n    def train(self, length, train_images, test_images, epochs, batch_size, save = False):\n\n        # Each model is trained using the exact decomposition coefficients, rather than the\n        # reconstructed output from the previous layers. The \"length\" argument sets which\n        # coarse-graining level should be used for training.\n\n        train_data = self.wavelet_transform(train_images.shuffle(60000).batch(batch_size), length)\n        test_data = self.wavelet_transform(test_images.batch(batch_size), length)\n        index = int(math.log2(length))\n        model = self.models[index]\n\n        model.compile(\n            loss = \"mae\",\n            optimizer = tf.keras.optimizers.RMSprop(0.0005))\n        model.fit(\n            train_data,\n            epochs = epochs, \n            validation_data = test_data,\n            callbacks = [tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10, restore_best_weights = True)])\n        if save:\n            core = self.cores[index]\n            core.save(f\"mnist_models/wavelet/core_{length}\")\n\n    def assemble_model(self, core, length):\n\n        # This function adds the wavelet reconstruction layer\n        # to the model core.\n\n        first = tf.keras.layers.Input([length, length])\n        fine = core(first)\n        combined = tf.keras.layers.Lambda(\n            lambda x: tf.concat([\n                tf.concat([x[0], x[1][..., 0]], axis = 2),\n                tf.concat([x[1][..., 1], x[1][..., 2]], axis = 2)\n            ], axis = 1)\n        )([first, fine])\n        recon = self.recon_layer(combined)\n        model = tf.keras.Model(inputs = [first], outputs = [recon])\n        return model\n\n    def wavelet_transform(self, dataset, length, keep_orig = False):\n\n        # This function carries out a wavelet decomposition on the\n        # inputs using the decon_layer.\n\n        index = int(math.log2(length))\n        padded = dataset.map(lambda x: self.pad_layer(x))\n        if keep_orig:\n            coeff = padded.map(lambda y: (self.decon_layer(y)[index], y))\n        else:\n            coeff = padded.map(lambda y: (self.decon_layer(y)[index], self.decon_layer(y)[index + 1]))\n        return coeff\n\n    def reconstruct(self, inputs, length = None):\n\n        # This function uses the model to appoximately reconstructs \n        # the original input based on its coarse-grained scale \n        # coefficients.\n\n        if length is None:\n            length = tf.shape(inputs)[1]\n        start_index = int(math.log2(length))\n        next_input = inputs\n        for i in range(start_index, 5):\n            model = self.models[i]\n            next_input = model(next_input)\n        return next_input\nNote that there is a model core for each resolution, from the original (padded) 32 x 32 images to the maximally coarse-grained 1 x 1 pixel “image”. To evaluate the performance of the model, we can perform a sequence of wavelet decomposition on an image and then use the model to reconstruct the image starting from each of the possible coarse-graining levels. We should expect to get a nearly perfect reconstruction after only a single coarse-graining step, since little information has been lost. After several coarse-graining steps, however, perfect reconstruction is likely to be impossible due to the large amount of image detail that has been discarded. The code below shows the deconstruction and reconstruction of an image at different coase-graining levels:\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\nfrom src import wavelet, mnist_model\n\ntest_image = tf.keras.datasets.mnist.load_data()[1][0][4]\ntest_image = tf.cast(test_image, \"float32\") / 255\ndataset = tf.data.Dataset.from_tensors(test_image[None])\n\nmodel = mnist_model.Wavelet_MNIST(wavelet.d_4)\nmodel.load()\n\n(fig, axes) = plt.subplots(5, 3, figsize = (10, 10))\nfor (length, (ax_1, ax_2, ax_3)) in zip([16, 8, 4, 2, 1], axes):\n    decon = next(iter(model.wavelet_transform(dataset, length)))[0]\n    raw_recon = model.reconstruct(decon)[0]\n    final_recon = mnist_model.clip_pixels(raw_recon)[2:30, 2:30]\n    ax_1.imshow(test_image, cmap = \"gray\")\n    ax_2.imshow(decon[0], cmap = \"gray\")\n    ax_3.imshow(final_recon, cmap = \"gray\")\naxes[0][0].set_title(\"Original\", fontsize = 16)\naxes[0][1].set_title(\"Coarse-grained\", fontsize = 16)\naxes[0][2].set_title(\"Reconstructed\", fontsize = 16)\nplt.show()\n\n\n\nDigit reconstructed using different latent space dimensions.\n\n\nIn each row, the original image of the digit “4” is given on the left, and the reconstruction generated by the model is shown on the right. In the middle column, we show the coarse-grained image, which is seen to lose resolution by a factor of two along each dimension as we go down the rows. As the size of the coarse-grained image space decreases, we can easily see the expected degradation of the reconstruction quality, though the output still shows impressive fidelity.\nWhen working with reconstructions from the lower-resolution decompositions, we can observe an increase in noise or “static” from the reconstruction, which clearly does not fit into the normal appearance of the MNIST images. These reconstructions would look much more convincing if we could remove the obvious noise artifacts, so we will train a secondary model to perform this clean-up. The following code creates the cleaner model using a method on the Wavelet_MNIST class:\nimport tensorflow as tf\n\ndef train_cleaner(self, length, train_images, test_images, epochs, batch_size):\n    self.cleaner = tf.keras.models.Sequential([ # The cleaner is deliberately shallow.\n        tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1)),\n        tf.keras.layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n        tf.keras.layers.Conv2D(1, 3, activation = \"sigmoid\", padding = \"same\"),\n        tf.keras.layers.Reshape([32, 32])\n    ])\n    first = tf.keras.layers.Input([length, length])\n    recon = self.reconstruct(first, length)\n    cleaned = self.cleaner(recon)\n\n    model = tf.keras.Model(inputs = [first], outputs = [cleaned])\n    for core in self.cores:\n        core.trainable = False\n    model.compile(\n        loss = \"mae\",\n        optimizer = tf.keras.optimizers.RMSprop(0.0005))\n    \n    train_data = self.wavelet_transform(train_images.shuffle(60000).batch(batch_size), length, True)\n    test_data = self.wavelet_transform(test_images.batch(batch_size), length, True)\n    model.fit(\n        train_data,\n        epochs = epochs, \n        validation_data = test_data,\n        callbacks = [tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10, restore_best_weights = True)])\nWith this cleaning model, the reconstruction can be made to more closely resemble images from the MNIST dataset, even if its overall appearance still differs somewhat from the original image that was decomposed. The following code shows some examples of model reconstruction using the cleaner:\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\nfrom src import wavelet, mnist_model\n\ntest_images = tf.keras.datasets.mnist.load_data()[1][0]\ntest_images = tf.cast(test_images, \"float32\") / 255\ndataset = tf.data.Dataset.from_tensors(test_images[:10])\n\nmodel = mnist_model.Wavelet_MNIST(wavelet.d_4)\nmodel.load()\n\ndecon = next(iter(model.wavelet_transform(dataset, 4)))[0]\nrecon = model.reconstruct(decon)\nclipped = mnist_model.clip_pixels(recon)\ncleaned = model.clean(recon)\n(fig, axes) = plt.subplots(10, 3, figsize = (12 ,16))\nfor (orig_image, recon_image, clean_recon_image, (ax_1, ax_2, ax_3)) in zip(test_images, clipped, cleaned, axes):\n    ax_1.imshow(orig_image, cmap = \"gray\")\n    ax_2.imshow(recon_image, cmap = \"gray\")\n    ax_3.imshow(clean_recon_image, cmap = \"gray\")\naxes[0][0].set_title(\"Original\", fontsize = 16)\naxes[0][1].set_title(\"Reconstructed from 4x4\", fontsize = 16)\naxes[0][2].set_title(\"Cleaned\", fontsize = 16)\nplt.tight_layout()\nplt.show()\n\n\n\nDigits reconstructed using the cleaning algorithm.\n\n\nComparing the second and third columns, we can see that the cleaner is able to fix most irregularities in the brightness and location of the image pixels, although broader discrepancies in shape will not be addressed."
  },
  {
    "objectID": "projects/other/wavelet/wavelet.html#generating-novel-images",
    "href": "projects/other/wavelet/wavelet.html#generating-novel-images",
    "title": "Dimensionality Reduction and Generative Modeling using Wavelets",
    "section": "Generating novel images",
    "text": "Generating novel images\nSo far we have focused on reconstructing existing images that were coarse-grained via wavelet decomposition, but it is also possible to view the low-resolution image space as a latent space for an image-generating model. At the smallest resolution sizes, such as 2x2, it is possible to use a Gaussian distribution to generate the initial probability density on the latent space. The Gaussian distributions can be fit to a set of coarse-grained images generated from the wavelet decomposition of a training set. The following method for the Wavelet_MNIST class generates novel images using this Gaussian approach:\nimport tensorflow_probability as tfp\n\ndef sample_gaussian(self, dataset, length, num_samples):\n    decon = self.wavelet_transform(dataset.batch(60000), length)\n    data = tf.reshape(next(iter(decon))[0], [60000, -1])\n    cov = tfp.stats.covariance(data)\n    mean = tf.reduce_mean(data, 0)\n    samples = tfp.distributions.MultivariateNormalFullCovariance(mean, cov).sample([num_samples])\n    recon = self.reconstruct(tf.reshape(samples, [num_samples, length, length]))\n    cleaned = self.cleaner(recon)[:, 2:30, 2:30]\n    return cleaned\nWe can use this method to sample a set of new images and see how realistic they look. Given that the Gaussian distribution does not possess a sophisticated structure, we will get the best results by using the small 2x2 coarse-grained latent space.\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\nfrom src import wavelet, mnist_model\n\n(train_images, test_images) = mnist_model.get_images()\n\nmodel = mnist_model.Wavelet_MNIST(wavelet.d_4)\nmodel.load()\n\nsamples = tf.reshape(model.sample_gaussian(train_images, 2, 25), [5, 5, 28, 28])\n(fig, axes) = plt.subplots(5, 5, figsize = (12, 12))\nfor i in range(5):\n    for j in range(5):\n        axes[i][j].imshow(samples[i, j], cmap = \"gray\")\nplt.tight_layout()\nplt.show()\n\n\n\nNovel images of digits generated using wavelet reconstruction.\n\n\nAs we can see from the plots, virtually all of the images are at least vaguely digit-shaped, with a fair number being reasonable depictions. That said, quite a few are clearly not digits, which suggests that there are portions of the latent space which do not map to decomposed MNIST images. One way to improve the quality of the generated images would be to fit a more flexible model to the latent space, so that it can avoid sampling from these invalid regions."
  },
  {
    "objectID": "projects/other/other.html",
    "href": "projects/other/other.html",
    "title": "Miscellaneous Projects",
    "section": "",
    "text": "This section of the site holds projects which do not fall into an existing category, and for which there aren’t yet enough similar projects to create a new category. A list of projects currently placed here is given below, although many of these are likely to be moved over time.\n\nReverse Engineering NeoQuest II\n\nThis project documents my efforts to reverse engineer an online RPG game called NeoQuest II. The game logic is handled entirely on the server side, so its mechanics need to be extracted using statistical analysis of repeated playthroughs. I use Selenium to automate the gameplay and R to perform the data processing and visualization.\n\nDimensionality Reduction and Generative Modeling using Wavelets\n\nThis project implements a neural network algorithm that deconstructs and reconstructs images using the wavelet decomposition. The algorithm can be used for dimensionality reduction, denoising, or generative machine learning. Example code can be run in the associated Jupyter notebook on GitHub.\n\nState of Speedrunning: A Power BI Report\n\nThis project contains a Power BI report that documents trends within the speedrunning community, which is a group of people who attempt to complete games as quickly as possible. The reports is built off of DAX formulas operating on data requested from the API of speedrun.com, which hosts most speedrunning records."
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html",
    "title": "The Library of Juggling",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html#overview",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html#overview",
    "title": "The Library of Juggling",
    "section": "Overview",
    "text": "Overview\nThe Library of Juggling is a website that I created in early 2012 to catalog the wide variety of juggling tricks that were scattered across YouTube videos, message boards, and websites. It contains descriptions and step-by-step tutorials for 174 different patterns, with a focus on three-ball juggling. Each trick is shown using an animation created with JugglingLab, which is a piece of software that allows you to render a custom juggling pattern by controlling the position and timing of each throw/catch. These animations are also interspersed throughout the tutorial sections in order to help readers visualize different steps in the learning process.\n\n\n\n… let’s call it “rustic”, shall we?\n\n\nSince its inception, the Library of Juggling has become a go-to resource for jugglers of all levels, whether they are learning basic patterns like the Cascade or diabolical ones like the Inverted Shower. Unfortunately, I had to stop working on the website in 2015, so it sat in stasis for over eight years before I finally came back and provided a more reliable hosting setup. As part of this migration, I rebuilt the site using Jekyll and cleaned up some of the more egregious HTML code, but the original structure and aesthetic were left intact. All of the underlying data and resources for the site can now be found in its GitHub repository.\nIn the sections below, I go into more detail about the origins of the Library of Juggling and how it has evolved over time."
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html#the-early-years",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html#the-early-years",
    "title": "The Library of Juggling",
    "section": "The Early Years",
    "text": "The Early Years\nI can’t quite remember when I started learning to juggle, but it was probably in late 2010. My early props were scrounged up from whatever I had lying around, from rubber bouncy balls to wooden eggs. Eventually, I got one of those cheap juggling sets and began to practice with more regularity. The idea for a “library of juggling” came to me in late 2011, inspired by the now-defunct KingsCascade1 website. That site had used animations from JugglingLab to create tutorials for around sixty different tricks, and included some fairly obscure patterns that were difficult to find anywhere else. While KingsCascade seemed to be foremost a personal website for its creator Matt Mangham, I intended for the Library of Juggling to serve as an anonymous repository for as many juggling tricks as I could find.\nThis was all happening early on in my juggling career2, so I planned to essentially learn a trick, add it to the site, then learn another trick, add it to the site, and so on. This naturally led to me specializing in three-ball juggling, since almost all of the cool, named tricks were done using three balls. Progress was a bit slow at first, but by the start of 2013 I had written tutorials for 57 different tricks. One thing that has helped set the Library of Juggling apart was that I broke down the tricks into a set of digestible pieces, often starting from simple one-ball and two-ball exercises before working up to the full pattern. Each of these steps was paired with an animation that provided a visual demonstration of the exercise, which made the text much easier to understand and follow.\nGiven that the evolution of the site mirrored my personal development as a juggler, it is interesting to browse through older versions of the site on the Wayback Machine3 and see what is effectively a snapshot of my abilities almost a decade ago. My unorthodox progression was already evident at this stage, where I apparently knew the obscure Olas pattern before the simple 423 (I’m skeptical that this is actually true, but it’s an amusing possibility). Looking at these site captures, it’s also rather striking just how quickly everything came together. The website was in its infancy in early 2013, and then mostly complete by the middle of 2014. By that point I had begun to exhaust the existing base of online juggling tutorials, and was increasingly adding tricks that had not previously been explained by anyone in a permanent or accessible medium."
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html#the-middle-years",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html#the-middle-years",
    "title": "The Library of Juggling",
    "section": "The Middle Years",
    "text": "The Middle Years\nI began attending college in 2014, and this naturally led to me (reluctantly) prioritizing other work over the Library of Juggling. I still kept at it though, and added several more tricks to the site in my freshman and sophomore years. These included patterns that had languished on more obscure sites, as well as tricks that had recently been invented by well-known jugglers on YouTube. I even hosted a few tutorials submitted by another juggler, Andrew Olson, who was (and is) an incredible inventor of three-ball patterns. The most significant changes to the site, however, were a pair of improvements to its navigation interface.\nOne of the first design choices that I grappled with when creating the Library of Juggling was how to display its collection of patterns. I wanted all of them to be easily accessible from any page on the site, so I decided to create a navigation sidebar to house the links. My plan was for the list of tricks to be organized based on the number of balls that were needed to perform the pattern, with each sublist being collapsible in order to save space. While modern-day me could have easily written a bit of JavaScript code to achieve the desired effect, high-school me barely knew anything about programming and instead opted to use an existing library called jsTree. Now I don’t think that there is anything inherently wrong with this library, but it was big and slow relative to what I actually needed it to do, and the particular tree that I implemented was just kind of ugly.\n\n\n\nTo be clear, this picture of the site from 2013 says much more about me than it does about jsTree.\n\n\nIn late 2014, a man by the name of Jon4 reached out to me with a rather exasperated email. He wrote, in colorful detail, about how using jsTree (in the way that I had, at least) was an absolutely awful decision, and did far more harm than good. It was quite an entertaining message, opening with the following lines:\n\nIt’s no good.\nI can’t take it any longer.\nI’ve put up with it for as long as I can but I feel our relationship is at a crisis point & I have to put it to you as an ultimatum:\nEither that javascript menu goes or I go.\n\nNeedless to say, it was the JavaScript menu that ultimately went. Jon was even kind enough to provide me with a simple bit of CSS code to make the plain-text replacement look somewhat decent, code which remains in some form within the site’s source to this very day.\nThe second significant addition I made to the Library of Juggling during its middle years was the “Tricks by Difficulty” page. When first designing the site, I needed to decide what kind of information should be included for each trick. Aside from obvious things like the pattern’s name and siteswap, I also wanted to provide some indication of how challenging the trick was to learn. What I ultimately came up with was a numerical value from 1-10 that would denote the difficulty of the pattern in ascending order5. Amusingly, I never gave a value of 1 to any trick, so the lowest difficulty level on the site is 2. I was also never willing to give a trick the maximum value of 10, for fear that someday I would come across something that was even more challenging. These quirks point toward a fundamental shortcoming of my approach, which is that the difficulty of every juggling pattern cannot possibly be compared along a single axis.\nNevertheless, the values were a quick and dirty way to sort the Library of Juggling into a set of tiers that could be used to guide a newbie juggler, which was good enough for me. It was also apparently good enough for many of the site’s visitors, as one of the top requests that I received was to add a page that listed every pattern in order of difficulty. Despite this pleading, I always told myself that I would “do it later”. I honestly can’t recall why I thought it would be so hard to add this page, but ultimately it wouldn’t matter because in October of 2014 I received an email from a literal twelve-year-old who kindly provided me with the organized list6. And the rest, as they say, was history."
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html#the-twilight-years",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html#the-twilight-years",
    "title": "The Library of Juggling",
    "section": "The Twilight Years",
    "text": "The Twilight Years\nIn late 2014, I had a unicycling accident7 and hurt my wrist. At first it seemed like the injury would heal, but after juggling for any sustained amount of time I would inevitably experience sharp pain in my joint. Not wanting to exacerbate things any further, I simply stopped juggling. There was still a backlog of tutorials for me finish, so I was able to put out a final pair of updates in December of 2014 and June of 2015, but that was it. For the next eight years I basically abandoned the Library of Juggling, despite the ever-present text on its homepage promising frequent updates.\n\n\n\nI only just removed this in October of 2023.\n\n\nIn all that time, however, no other resource emerged to truly replace the site, and it remained one of the largest and most thorough collections of three-ball juggling patterns on the internet. According to an old Statcounter plugin that I used, the Library of Juggling continued to receive over 1000 page views a day, from around 500-700 unique visitors. Perhaps the very existence of the site discouraged others from making their own, as they would simply be duplicating the large amount of effort that I had already spent. Based on some retrospective reseach, it seems that a website called Skilldex.org may have arisen in 2019 as a possible replacement for the Library of Juggling, boasting a huge catalog of patterns with video demonstrations. I write “may have” because the site no longer exists, and the archived version on the Wayback Machine appears to be completely broken. I’m frankly kind of baffled that the combined efforts of the juggling community haven’t been able to outdo a single teenager with some time on his hands, but here we are.\nIn around September of 2023, I resolved to do a bit more work on the Library of Juggling. I wouldn’t be changing any of the site’s content, but I wanted to ensure that it would remain accessible for the foreseeable future. Back in 2012, I chose to host the site and domain on iPage, whose services and reputation have deteriorated severely over the subsequent decade. Nowadays there are countless companies that provide more services than iPage while also being substantially cheaper. My first move was to take the libraryofjuggling.com domain name (probably my most valuable asset given its recognition and search engine history) and transfer it to Cloudflare. To serve the content of the site, which is made up entirely of static files, I decided to host out of a GCP bucket. This is an extremely cheap option, but a major downside is that requests can only be made over HTTP, not HTTPS8. To address this, I followed advice from DevOps Directive and set up a reverse proxy through Cloudflare. Requests to the Library of Juggling are sent first to the Cloudflare proxy servers over HTTPS, which in turn make requests to GCP over HTTP (all for less than $1 per month).\n\n\n\nA nice perk of Cloudflare is that they give you free analytics, such as a geographic breakdown of your site’s traffic.\n\n\nWith the hosting situation stabilized, my second goal was to clean up the Library of Juggling’s HTML/CSS code. This wasn’t necessary to bolster the longevity of the site, but it would make any future updates easier to deploy. Plus the state underlying code was just kind of offensive. I chose to rebuild the site using Jekyll, which relies on the Liquid templating language to generate HTML code out of smaller, reusable building blocks. In my case, this meant that the code for the navigation bar, top banner, and footer could be separated from the page content, with any changes being automatically propagated across all pages9. It also meant that I could create pages using very concise Liquid code, such as the following for the “Tricks by Difficulty” page:\n&lt;h1 id=\"difficultytitle\"&gt;Tricks By Difficulty&lt;/h1&gt;\n{%- for diff in (2..9) -%}\n    &lt;p class=\"level\"&gt;Level {{ diff }}&lt;/p&gt;\n    &lt;ul&gt;\n    {%- assign filteredTricks = site.data.tricks | where: \"difficulty\", diff | sort: \"name\" -%}\n    {%- for trick in filteredTricks -%}\n        &lt;li class=\"difficultytricks\"&gt;\n            &lt;a href=\"{{ trick.url | prepend: \"/\" | relativize_url }}\"&gt;\n                {{ trick.name }}\n            &lt;/a&gt;&lt;/li&gt;\n    {%- endfor -%}\n    &lt;/ul&gt;\n{%- endfor -%}\nOn the CSS side, I really just needed to consolidate styles that had been applied to redundant elements. It was important to me that the appearance of the website not change, so I did careful side-by-side comparisons for each change in the CSS code. Ultimately there ended up being a few small differences, but only the most obsessive of users would be able to notice. One major exception was a yellow-ish background on the navigation bar, which had come from the CSS code that I got from Jon. It was intended to match the background of the original jsTree widget, but I incorporated the code in a half-assed manner that left some parts of the navigation bar with a white background and other parts with that yellow background. In the end, I simply chose to go with the white background, presumably to the delight of anyone with an even marginally aesthetic eye.\nAnd that’s pretty much it. After rendering the new page files, I copied them into the GCP bucket and modified the domain’s DNS records to point away from iPage’s servers. The Library of Juggling is now hosted using the services of two very reliable companies at only a fraction of the original cost. While I don’t see myself ever making tutorials again, I hope that my website can remain a useful resource for years to come."
  },
  {
    "objectID": "projects/other/libraryofjuggling/libraryofjuggling.html#footnotes",
    "href": "projects/other/libraryofjuggling/libraryofjuggling.html#footnotes",
    "title": "The Library of Juggling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn archived copy of the site can be found here, courtesy of the Wayback Machine. In an interesting coincidence, the website went offline shortly after the Library of Juggling was created.↩︎\nI use this term very loosely. The only money I’ve ever made from juggling was $20 for appearing at the end of this commercial.↩︎\nUnfortunately this is the best that I can do, since I kept few historical records of the site’s content. I guess fifteen-year-old me didn’t believe in version control.↩︎\nThis was in fact the legendary “Orinoco” from the UK’s Tunbridge Wells Juggling Club, who was (is?) very active in the online juggling community.↩︎\nThese completely arbitrary difficulty values are actually used by Wikipedia. I am apparently considered a “reliable source” for juggling, much to my horror.↩︎\nIn his email he helpfully pointed out that it had taken him only an hour to compile the list, after I had initially explained that I “could never seem to find the time”.↩︎\nI’m not joking. Unicyclers, remember to tie your shoelaces.↩︎\nYou can use HTTPS by setting up a load balancer on GCP, but that is ~10x the cost.↩︎\nI had originally achieved something like this by using template files in Macromedia Dreamweaver 8. Make of that what you will.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Portfolio",
    "section": "",
    "text": "This website serves as a repository for my past and present projects. Each project has a webpage that provides a comprehensive description of its goals and methodology, and some also have informal blog-style posts about the work process and final product.\nAt the moment, my projects are currently subdivided into research work, Tetris stuff, and a miscellaneous section (projects here will eventually be moved to a distinct section). A full listing of these projects, along with the main concepts and technologies used to implement them, is given below. Longer descriptions for each set of projects can be found on the corresponding category page, along with any blog posts about the subject more broadly.\n\nPhD Research:\n\nInteraction Decomposition for Tensor Network Machine Learning\n\nPython, TensorFlow, tensor analysis\n\nBayesian Inference for Quantum Error Correction\n\nPython, PyTorch, Bayesian probability, quantum computing\n\nQuantifying Mutual Information via Logistic Regression\n\nPython, machine learning, information theory\n\n\n\n\n\nTetris:\n\nPostgreTETRIS: Tetris in SQL\n\nPostgreSQL, PL/pgSQL, relational databases\n\nTetris in VBA\n\nMicrosoft Excel, Visual Basic For Applications (VBA)\n\n“Solving” Tetris with Apache Spark\n\nPySpark, distributed computing\n\nTetris Emulation with OpenGL\n\nC++, OpenGL\n\n\n\n\n\nOthers:\n\nReverse Engineering NeoQuest II\n\nPython, R, Selenium, BeautifulSoup\n\nThe State of Speedrunning\n\nPower BI, DAX, M, data visualization\n\nDimensionality Reduction and Generative Modeling using Wavelets\n\nPython, TensorFlow, wavelet analysis, generative machine learning"
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html",
    "href": "projects/other/neoquest/neoquest.html",
    "title": "Reverse Engineering NeoQuest II",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#overview",
    "href": "projects/other/neoquest/neoquest.html#overview",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Overview",
    "text": "Overview\nNeoQuest II is a web-based RPG game found on Neopets.com, an old website built around caring for virtual critters called Neopets. Although there exist many guides on how to play NeoQuest II, none of them discuss anything beyond surface-level mechanics. The main reason for this is that all of NeoQuest’s game logic is processed server-side, and therefore hidden from direct observation. While this causes immediate problems for those wanting to develop a deeper understanding of the game, it also raises broader concerns about the fate of NeoQuest II if Neopets.com were to ever shut down.\nTo probe the inner workings of NeoQuest II, I have written a Python-based auto-player for it using Selenium. This program can operate autonomously, playing through the game and collecting huge quantities of data involving movement, combat, and loot mechanics. To extract useful information from this raw data, I have written a set of R scripts to clean and transform it in search of statistical patterns. This work is still in its early stages, but I have assembled my current methods and conclusions in walkthrough.html, which outlines some mechanics that I have likely solved and others that still elude me.\nAlthough the code in this repository is not intended as a fully-fledged application or library, it is documented and can be easily run in an environment with Python and R. The only external dependencies of the auto-player are BeautifulSoup for HTML parsing and Selenium for browser automation.\nA comprehensive write-up of my methodology and preliminary findings is given below."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#the-game",
    "href": "projects/other/neoquest/neoquest.html#the-game",
    "title": "Reverse Engineering NeoQuest II",
    "section": "The Game",
    "text": "The Game\nNeopets.com is an interactive website and media franchise created by Adam Powell and Donna Williams in 1999. Your main task as a user is to care for a set of Neopets, which are virtual creatures that you adopt after creating an account1. The designers of Neopets worked hard to create a coherent fictional world for the game, which unfolds across various web pages on the site. These pages range from maps to storefronts to interactive mini-games, all designed to entertain the player and increase their immersion.\n\n\n\nThe main Neopets marketplace as it looks in 2023.\n\n\nMy experience with Neopets dates back to 2005, when I created my first account along with my sister2. One of my favorite games on the site was NeoQuest II, a simple RPG that had you battle monsters and level up your characters across five lands lifted from the Neopets world. Given how undemanding their young audience was, I would say that the creative team put a surprising amount of heart and charm into the game, although it certainly won’t (and didn’t) win any awards. Ten-year-old me loved it, in any case."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#the-problem",
    "href": "projects/other/neoquest/neoquest.html#the-problem",
    "title": "Reverse Engineering NeoQuest II",
    "section": "The Problem",
    "text": "The Problem\nTo make a long story short, Neopets.com has seen better days. The website’s architecture was mediocre even in its prime, and from what I’ve heard the PHP code base has not been updated in decades. This has led to numerous bugs, crashes, and shenanigans3. The death of Flash in 2021 was also a massive blow to the site, as most of its mini-games and infrastructure had been originally built on Flash and never migrated. While none of these issues are necessarily fatal, their combined weight is dragging Neopets into a death spiral that it seems unlikely to recover from.\nSo what does this mean for our beloved NeoQuest II? Unlike the many flash-based games on Neopets, NeoQuest II is exclusively server-side, with the browser simply sending POST requests to update the game’s remote state and retrieve a new HTML page. Want to move? Gotta reload the page. Aside from making the game a bit awkward to play, this has the added effect of tying NeoQuest’s very existence to the continued operation of the Neopets servers. Should they go down, which seems a very real possibility, there will be no way to recreate the game unless an employee happens to preserve and release its source code4.\n\n\n\nThis is what we could lose, if we do not act now."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#the-solution",
    "href": "projects/other/neoquest/neoquest.html#the-solution",
    "title": "Reverse Engineering NeoQuest II",
    "section": "The Solution",
    "text": "The Solution\nAlthough NeoQuest’s code is hidden, it is certainly not isolated. Every time the player makes a move, attacks an enemy, levels up a skill, etc., some information about the underlying game logic is revealed. By performing a large number of different actions and recording their effects, it should be possible to reverse engineer the mechanics of the game. For cases in which the game’s behavior is deterministic, only a single observation needs to be made to understand the relevant mechanic. This is the kind of information that can be easily found in existing NeoQuest II game guides5, such as enemy names, map layouts, and item types.\nRandomized game mechanics pose a far greater challenge. Even when performed under identical conditions, multiple observations of a random or stochastic mechanic can yield very different outcomes. The goal in these cases is not to replicate any given output but to instead characterize the structure of the probability distribution being sampled. This will in general require a very large number of observations (hundreds or even thousands), far exceeding what is usually seen in normal playthroughs.\nWith all of this in mind, it seems obvious that I can’t gather the data necessary to reverse engineer NeoQuest II by just sitting down and playing the game. Not only would it be incredibly tedious to record all of the relevant information after every action, but the sheer quantity of data needed to pin down the stochastic mechanics would require an inhuman amount of playtime (even for ten-year-old me). Instead, my approach will be to create a program that can play NeoQuest II in an automated and consistent fashion, and pair it with an HTML parsing algorithm that can extract all of the necessary information from each page refresh. Once the data is collected, it is simply6 a matter of analyzing the data and extracting the underlying game mechanics."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#game-overview",
    "href": "projects/other/neoquest/neoquest.html#game-overview",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Game Overview",
    "text": "Game Overview\nNeoQuest II is a simple turn-based role-playing game (RPG), in which the player leads a plucky band of heroes on a quest to save the world7. The main protagonist of the series is Rohane, a standard knight-type character who specializes in hitting things hard with his sword. He is the sole member of the player’s party at the beginning of the game, but over time three more characters can be recruited: Mipsy the wizard, Talinia the archer, and Velm the cleric. Each of them brings a unique set of abilities to the party, which will be needed to defeat the wide variety of monsters that await the player.\n\n\n\nOur heroes, from left to right: Rohane, Mipsy, Talinia, and Velm.\n\n\nTo progress through NeoQuest II, the player must lead their party across a set of two-dimensional maps. Each map is broken up into a large number of square tiles, which the player can move between using eight directional arrows spanning the cardinal8 and inter-cardinal9 directions. These tiles contain different basic scenery items, with the most important distinction being between tiles that are passable, such as forests, and those that are impassable, such as mountains. The maps themselves can depict localized areas such as towns, castles, and caves, or much larger overworlds that hold entrances to the smaller locations.\nEach time the player makes a move, there is a chance (in most areas outside of towns) for the party to be ambushed by between one and four enemies. During combat, the player can choose to attack, use a potion, wait, or attempt to flee. If the player opts to attack, they can use either a default melee attack or a special ability unique to the character. Every action takes a certain amount of time to complete, which determines when a character gets to make their next move. In between player moves, the enemies will complete their own actions by either performing a melee attack on a party member or using a special ability. Fully depleting a combatant’s hitpoints will render them inactive for the remainder of the fight, which continues turn-by-turn until all party members or all enemies are incapacitated.\n\n\n\nAn example fight between the starting character Rohane and a low-level enemy. The buttons on the left-hand side show different actions the player can take, while the portraits at the top and bottom contain information about the status of each combatant.\n\n\nWhen the player is victorious in combat, each party member will be awarded a certain number of experience points based on their current level and the strength of the defeated enemies. After earning enough experience, a character will level up and gain a skill point, which can be spent on one of seven different skills for each character (up to a maximum of fifteen points per skill). Examples of different skills are healing spells for Velm, stunning attacks for Rohane and Talinia, and damage spells for Mipsy. In addition to leveling up, the performance of a character can also be improved using weapons or armor looted off of defeated enemies or purchased at shops."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#foundations-for-automation",
    "href": "projects/other/neoquest/neoquest.html#foundations-for-automation",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Foundations for Automation",
    "text": "Foundations for Automation\nTo gather the large quantity of data necessary for this project, I need some method of playing NeoQuest II in an automated fashion (an auto-player). In practice, this will mean some type of computer program that can:\n\nPerform in-game actions by sending the appropriate request to Neopets.com.\nParse the returned HTML document to extract relevant information.\nUnderstand the game logic well enough to play NeoQuest II in a somewhat intelligent fashion.\n\nFortunately, the simplicity of NeoQuest II makes it relatively straightforward to build an auto-player that satisfies all three of these requirements.\nTo start, I need a way to interact with the Neopets website in a manner that won’t trigger any bot-detection algorithms10. The best tool for this job is Selenium, a web scraping browser testing library that can launch automated instances of popular web browsers like Chrome or Firefox. The Selenium web drivers come with a wide array of different settings and options, but I found the simple configuration below to be sufficient (I used Selenium’s Python bindings for this project):\noptions = Options()\noptions.page_load_strategy = \"none\"\ndriver = webdriver.Firefox(options = options)\ndriver.install_addon(\"ublock_origin-1.50.0.xpi\")\nThe most notable choice I made here was to install uBlock Origin as an ad blocker. While not strictly necessary, it prevented Neopets’ many banner and sidebar ads from consuming the browser’s memory and dragging down its performance11. Additionally, I set the page_load_strategy option to none so that the Selenium code will not block the rest of the program as it tries to load a page.\nOnce the Selenium driver is initialized, it gets wrapped in a larger class which handles various commands and queries sent by the auto-player. The core of the class is the _do_action method, which takes a requested web action and executes it:\ndef _do_action(self, func, args, safe_url):\n    while True:\n        try:\n            game_div = self.driver.find_element(\n                By.CSS_SELECTOR, \".contentModule.phpGamesNonPortalView\"\n            )\n            func(*args)\n            WebDriverWait(self.driver, 20).until(staleness_of(game_div))\n            WebDriverWait(self.driver, 20).until(\n                lambda d: d.find_element(By.CSS_SELECTOR, \".contentModule.phpGamesNonPortalView\")\n            )\n            break\n        except TimeoutException:\n            print(\"Action failed.\")\n            while True:\n                try:\n                    self._hard_refresh(safe_url)\n                    break\n                except TimeoutException:\n                    pass\n    self.soup = self._get_page_soup()\n    self.source = get_source(self.soup)\n    time.sleep(0.3)\n        \ndef _hard_refresh(self, return_url):\n    self.driver.get(\"https://www.google.com/\")\n    WebDriverWait(self.driver, 20).until(\n        lambda d: d.find_elements(By.CSS_SELECTOR, \"img.lnXdpd\")\n    )\n    self.driver.get(return_url)\n    WebDriverWait(self.driver, 20).until(\n        lambda d: d.find_element(By.CSS_SELECTOR, \".contentModule.phpGamesNonPortalView\")\n    )\nOnly the func(*args) portion of the code is truly needed to perform the requested action, while everything else is there to ensure that Selenium actually executes it. Since calls to the web driver are inherently asynchronous, the code needs to verify that the page has reloaded by monitoring elements in the DOM tree12. If the page fails to reload, as can often happen, the _hard_refresh method is called to navigate off of Neopets.com and then return to the NeoQuest II page."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#playing-the-game",
    "href": "projects/other/neoquest/neoquest.html#playing-the-game",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Playing the Game",
    "text": "Playing the Game\nUsing the base _do_action driver method, it is fairly easy to perform all of the actions required to play NeoQuest II. To navigate through the world, the player normally clicks on a set of arrows, which are represented internally as an image map. Different areas of the map are assigned event handlers for the eight movement directions, so the auto-player can move by simply executing the appropriate JavaScript:\ndef move(self, direction):\n    direction_id = explore_parser.get_direction_id(direction)\n    if not self.is_fighting():\n        while self.source != \"explore\":\n            self._return_to_map()\n        self._do_action(\n            self.driver.execute_script,\n            [f\"dosub({direction_id});\"],\n            \"https://www.neopets.com/games/nq2/nq2.phtml\"\n        )\nThe structure of this movement code is similar to that of most other actions, and consists of three main steps:\n\nExtract and interpret information from the structure of the HTML page source.\nNavigate to the game page which matches the requested action.\nPerform the action by executing the appropriate script or navigating to the correct page.\n\nWhen the auto-player makes a move, the specified direction needs to first be converted into the correct script ID (step 1), then the browser must navigate to the map page (step 2), and finally a JavaScript function must be called to send the action to the server (step 3). The most common error in this process is that the server will not send back an updated page after the request is made, but this can be easily remedied by simply reloading the game page13.\nBy stringing together different actions, I can assemble a game loop that will play NeoQuest II at a basic level14:\ndef game_step(driver, game_state, handler, conn):\n    fought = False\n    moved = make_move(driver, handler, game_state)\n    if not moved:\n        game_state.live = False\n        return game_state\n    game_state.move_id += 1\n    if driver.is_fighting():\n        fight_loop(driver, handler, game_state.game_id, game_state.move_id, conn)\n        fought = True\n    state_update(driver, game_state, [\"explore\", \"characters\"])\n    process_inventory(driver, handler, game_state, update = fought)\n    process_skills(driver, handler, game_state, update = fought)\n    return game_state\n  \ndef fight_loop(driver, handler, game_id, move_id, conn):\n    turn_id = 0\n    driver.begin_fight()\n    fight_dict = driver.get_fight_dict()\n    fight_state = fight.FightState(fight_dict)\n    while not fight_state.ended:\n        if fight_state.is_player_turn():\n            make_fight_move(driver, handler, fight_state)\n        else:\n            driver.take_enemy_turn()\n        fight_dict = driver.get_fight_dict()\n        fight_state = fight.FightState(fight_dict)\n        turn_id += 1\n    driver.end_fight()\n    driver.return_from_fight()\nThe game_step function processes movement from one map tile to another, and is broken up into three stages. First, a direction is specified by the handler, which contains preset rules dictating player movement (more on this shortly). Next, the auto-player detects whether any enemies have attacked, in which case control is passed to the fight_loop function, which completes the battle. Following this, the auto-player queries its associated web driver to get the new location and party status. Finally, if this new information indicates that one or more of the party members has leveled up or needs to be healed, then the auto-player will open the inventory and/or skill pages to perform any necessary actions.\nThe most critical piece of the auto-player is the aforementioned handler, which serves as the “brains” of the operation. This object is a thin wrapper around a set of four “sub-handlers”, which control actions related to movement, combat, inventory items, and skills respectively. As an example, here is the code for a combat handler that will either attack an enemy or try to flee:\nclass SimpleMelee():\n    def __init__(self, flee_rate = 0):\n        self.target_picked = False\n        self.flee_rate = flee_rate\n\n    def perform(self, fight_state):\n        if not self.target_picked:\n            self.target_picked = True\n            target = fight_state.get_alive_enemies()[0]\n            action = f\"trg_{target}\"\n        else:\n            self.target_picked = False\n            sample = random.uniform(0, 1)\n            if (self.flee_rate &gt; 0) and (sample &lt;= self.flee_rate):\n                action = \"flee\"\n            else:\n                action = \"attk\"\n        return action\nWhen the auto-player wants to make its next move, it calls the perform method and gets back an action string which the web driver can then execute. When prompted, the handler shown above will first target an enemy if it hasn’t done so already, then it will either perform a melee attack or attempt to flee based on a previously-specified probability. This logic simply repeats until the fight concludes."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#recording-the-game",
    "href": "projects/other/neoquest/neoquest.html#recording-the-game",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Recording the Game",
    "text": "Recording the Game\nWith an auto-player for NeoQuest II now in hand, all that’s left is to extract and record the relevant game information. For extraction, I will need a way to parse the HTML that is generated after each action and identify any important information. To then record this information, I will need a database that can serve as an intermediate between the auto-player code and my subsequent data analysis scripts.\nFor HTML parsing, the go-to Python library is BeautifulSoup, which takes as input an HTML string and parses it into a tree of HTML tags that can be easily navigated. Unfortunately, the architects of Neopets.com apparently subscribed to the “tables as formatting” philosophy of web design, which means that the underlying page source code is a frustrating cacophony of &lt;td&gt;s and &lt;tr&gt;s. Nevertheless, it is still possible to extract information, as seen in the following parsing function:\ndef get_potions(soup):\n    potion_dict = {}\n    potion_table = soup.select('table[width=\"100%\"]')[0]\n    potion_strings = list(potion_table.tbody.tr.td.stripped_strings)\n    for (quant, name) in zip(potion_strings[::5], potion_strings[1::5]):\n        potion_dict[name] = quant\n    return potion_dict\nDue to the almost complete absence of tag IDs or classes, I ended up navigating the DOM tree using relative positioning and nested selectors. Once the desired information has been extracted, it can be placed into a dictionary and used to update the internal game state of the auto-player.\nAfter an iteration of the game loop is complete, the final step is to log the game state so that it can be analyzed later. The most straightforward way to do this is via a SQLite database, which can easily interface with the auto-player using the sqlite3 Python package. I chose to have the game data be stored in as unedited a form as possible, leaving any necessary cleaning to the subsequent analysis phase. As an example, the actions taken during combat were stored in the following table:\n\n\n\n\ngame_id\nmove_id\nturn_id\nelapsed_time\nmessage\n\n\n\n\n0\n7\n0\n1.1\nThe fight begins!\n\n\n0\n7\n1\n1.8\nRohane hits a plains lupe for 1 damage!\n\n\n0\n7\n2\n6.4\nA plains lupe tries to claw Rohane, but misses!\n\n\n0\n7\n3\n7.1\nRohane tries to hit a plains lupe, but misses!\n\n\n0\n7\n4\n12.1\nA plains lupe claws Rohane for 2 damage!\n\n\n\nNote that while the message contains comprehensive information about the action and its effects, this data still needs to be extracted from the text before it can be used."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#encounters",
    "href": "projects/other/neoquest/neoquest.html#encounters",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Encounters",
    "text": "Encounters\nIn short: Enemy encounters occur randomly after moving to a new map tile. The probability of encountering an enemy appears to be ~10% in normal mode and ~67% in hunting mode, with some variation based on region. Within a particular region, enemies have different relative encounter probabilities, which do not seem to depend on the player’s travel mode.\n\nWith the auto-player gathering data en masse, I can begin to probe some of NeoQuest’s underlying mechanics. One of the most visible components of the game is the random encounter system, where every move (outside of certain safe zones) can potentially trigger a fight. The player is provided with two travel modes, “normal” and “hunting”, which alter the frequency of these encounters.\n\n\n\nEnemies in the first regions of NeoQuest II, with their level in parentheses.\n\n\nThe following bar chart provides a breakdown of the observed encounter rates in different regions based on data from ~37,500 different moves, with error bars enclosing a 95% confidence interval15:\n\n\n\nEncounter rates by location and mode.\n\n\nAs its name suggests, “hunting” mode significantly increases the rate of enemy encounters, raising their probability from ~10% (in “normal” mode) to ~66%. These probabilities appear to be largely consistent across regions, although some variation can be observed in e.g. the Hills of Trest. The location has a much more obvious effect on the types of enemies that are encountered, as can be seen in the next table:\n\n\n\n\nRegion\nEnemy\nEncounter Rate\n\n\n\n\nan abandoned gold mine\ncave lupe\n2%\n\n\nan abandoned gold mine\ncave spyder\n15%\n\n\nan abandoned gold mine\nminer ghost\n42%\n\n\nan abandoned gold mine\nminer skeleton\n41%\n\n\nan underground cave\ncave ogre\n64%\n\n\nan underground cave\nskeleton guard\n31%\n\n\nan underground cave\nskeleton knight\n5%\n\n\nthe Golden Forest\nforest bearog\n68%\n\n\nthe Golden Forest\nplains aisha\n10%\n\n\nthe Golden Forest\nplains lupe\n22%\n\n\nthe Hills of Trest\nplains aisha\n66%\n\n\nthe Hills of Trest\nplains lupe\n34%\n\n\nthe Western Plains\nplains lupe\n100%\n\n\n\nEach area of the map is generally home to at least two enemies, who will attack the player at their own distinct frequencies. The relative encounter rates for different enemy types do not appear to be impacted by the use of “hunting” mode, nor by the level of the player."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#combat",
    "href": "projects/other/neoquest/neoquest.html#combat",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Combat",
    "text": "Combat\nCombat is by far the most complicated aspect of NeoQuest II, and it encompasses a wide array of different gameplay components. As a first treatment, I will focus on the core mechanics of attack damage, recovery time, and fleeing. More exotic quantities like potion damage and magic resistance will be left to future work. I will also restrict my focus to fights between Rohane and a single enemy, so when I talk about the player’s actions I am referring to Rohane specifically.\n\nFirst Move\n\nIn short: The player will move first in a fight ~76.6% of the time. This is because the player’s first move time is distributed uniformly on [0, 1.4], while the enemy has a time distributed uniformly on [0, 2.9] and will always move second when there is a tie. These distributions do not appear to vary with enemy or player level.\n\nWhen a fight begins, either the player or the enemy will get to make the first move. This determination is made using a mechanism that is distinct from that of subsequent move-speed calculations, which I will discuss in the next section. Based on first-round data from ~8,000 different encounters, the following table gives the probability that the player will move first when facing a selection of different enemies:\n\n\n\n\n\n\n\n\n\n\n\n\n\nplains lupe\nplains aisha\ncave spyder\ncave lupe\nshadow gelert\ncave ogre\nskeleton knight\n\n\n\n\n76.0%\n76.0%\n76.2%\n73.7%\n76.9%\n75.1%\n78.5%\n\n\n\nAside from some minor fluctuations, the probability of the player moving first is observed to be 75-77% for any encounter, and does not increase with player level or after improving innate haste with skill points.\nTo better assess the underlying mechanism at work here, I can take each encounter and plot how long it takes for the player to make their first move versus how long it takes for the enemy to do so. This will not only show the range of possible start times, but also reveal any correlation that might exist between player and enemy times. Since fight times are only given to the tenth of a second16, a binned scatterplot can be used to easily visualize the data:\n\n\n\nFrequency plot of player and enemy first move times.\n\n\nThis plot strongly supports the following conclusions:\n\nThe player will begin their turn between 0.0 and 1.4 seconds, with times distributed uniformly in this range.\nThe enemy will begin their turn between 0.0 and 2.9 seconds, with times distributed uniformly in this range.\nThe first move times of the player and enemy are uncorrelated with each other in an encounter.\n\nA final question to consider is what happens when the player and enemy are assigned the same first move time? In this scenario, it turns out that the player is always given the first-move advantage, so the probability that the enemy moves first is 1/2 (probability of being in [0.0, 1.4]) times 7/15 (probability of having a time less than the players time in [0.0, 1.4]), which is equal to 7/30 or 0.2333 repeating. This is consistent with the earlier empirical observation that the player moves first in 75-77% of encounters.\n\n\nRecovery Time\n\nIn short: The time between enemy attacks, i.e. their recovery time, is uniformly distributed between 5 and 6 sec. The player’s recovery time follows this same distribution at all levels, except when points are put into the “Increase Melee Haste” skill. For each skill point, the lower bound on the player’s recovery time is reduced by ~0.2 sec, while the upper bound is reduced by ~0.3 sec.\n\nThe “recovery time” of a combat action refers to the amount of time that will take before the actor can move again17. NeoQuest II helpfully provides a “time until next turn” counter for each combatant, which allows recovery times to be easily computed. Histograms of these times are shown below for a selection of enemies:\n\n\n\nRecovery time distributions for a selection of enemies.\n\n\nThe recovery time for each enemy is bounded between 5.0 and 6.0 seconds, and distributed uniformly across that range. This pattern holds for all enemies found in random encounters before crossing the bridge at White River, but may not apply for stronger enemies in later parts of the game18.\nBy default, the player’s recovery time follows the same distribution as the enemy’s, regardless of level. The only way to change this is by putting skill points (or an item buff) into the “Increase Melee Haste” skill, which will decrease the recovery time for an attack. The magnitude of this effect can be seen by comparing histograms of recovery time with different amounts of innate haste:\n\n\n\nPlayer recovery time at different haste levels.\n\n\nThe upper-left plot, with zero innate haste, shows the same uniform [5, 6] range as the enemy distributions. Once points start being added to haste, however, the distribution shifts to shorter recovery times. The probabilities themselves remain mostly uniform, but the minimum and maximum times will sometimes have greatly reduced likelihoods, far below what would be expected from mere sample noise19. The upper and lower bounds do not decrease with haste level in multiples of 0.1 sec, but instead appear to zigzag:\n\n\n\nMaximum and minimum recovery time by haste level.\n\n\nNote that the upper bound decreases at a slightly greater rate than the lower bound, which causes the range of recovery times to narrow as the player’s innate haste level increases.\n\n\nEnemy Damage\n\nIn short: The damage done by an enemy follows a unimodal bounded distribution of unknown specification. The upper and lower damage bounds increase linearly with enemy level, with the slope and intercept depending on the player’s level (and likely other factors). Enemies generally have a ~36% chance of missing their attack and dealing zero damage, although this probability abruptly jumps to ~95% when the player’s level is significantly greater than the enemy’s.\n\nThe amount of damage done by an enemy’s melee attack will depend on the strength of both the enemy and the player20. NeoQuest II does not provide any formal quantification of enemy power, so I will use experience points as a proxy. In my formulation, the level of a given enemy is equal to the level that the player must be in order to receive 100 experience points from defeating it. This threshold level is equal to one less than the number of enemy hitpoints divided by five.\nBy looking first at data where the player’s level is equal to the enemy’s level, I can establish a baseline damage distribution for enemies when they attack a player of equal strength. The following histograms show these distributions for three different enemies21, organized by increasing strength from left to right:\n\n\n\nDamage from enemies when player and enemy levels are equal.\n\n\nThere are a few noteworthy observations to make here:\n\nThe range of each distribution is strictly bounded.\nHigher-level enemies have a broader range of damage values than weaker enemies.\nThe probability of doing zero damage is consistent across enemies.\nWithin the bounded range, the damage probabilities are not uniform.\n\nConcerning the fourth observation, I have so far been unable to determine how the damage distributions are generated. Although their overall shapes broadly resemble unimodal bell curves, the probability ratios do not match those from a Gaussian distribution, nor from the sum of uniform random variables. As an example, the observed frequency of each damage amount for the plains lupe is given below:\n\n\n\n\n0\n2\n3\n4\n5\n\n\n\n\n36.28%\n22.81%\n22.27%\n14.37%\n4.27%\n\n\n\nLeaving aside for now the chance of doing no damage (i.e. of missing), the different damage probabilities do not appear to share a common denominator or otherwise bear the signature of any obvious functional form. While it is very unlikely that all of these probabilities were specified manually by the developers, the equations that they used remain elusive.\nFortunately, much more can be gleaned by looking at the bounds of the damage distributions. Focusing again on fights where the player and enemy are at the same level, I can plot the change in the upper and lower damage bound as a function of enemy level:\n\n\n\nMaximum and minimum enemy damage by level.\n\n\nIt is clear from this plot that both the upper and lower damage bounds vary linearly with enemy level, at least when the player and enemy levels are equal. The zigzagging shape of the curves could arise from discretized linear functions with fractional slopes, such that the lower bound increases by ~0.5 damage per level while the upper bound increases by ~1.5 damage per level.\nThe relationship between the damage bounds and enemy level appears to remain linear even when the player and enemy levels are not equal, although the slope of the line and its intercept22 will vary. I give these parameters for different values of player level - enemy level in the following table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoefficient\n-2\n-1\n0\n1\n2\n3\n4\n5\n\n\n\n\nlower slope\n0.58\n0.52\n0.49\n0.51\n0.40\n0.41\n0.29\n0.27\n\n\nlower intercept\n0.96\n1.16\n1.29\n0.71\n0.82\n0.43\n0.73\n0.48\n\n\nupper slope\n1.75\n1.60\n1.49\n1.41\n1.18\n1.1\n0.81\n0.82\n\n\nupper intercept\n2.75\n2.91\n3.29\n2.43\n2.54\n1.76\n2.25\n1.18\n\n\n\nInterestingly, the slope values do not appear to change continuously with the level gap, which could imply that they are generated by an inherently discrete process. Without more data from stronger enemies, however, it is difficult to draw any firm conclusions.\nThe final game mechanic to cover here is the enemy miss rate. This is the probability that an enemy attack deals zero damage, which is described in-game as the enemy “missing” its attack. The probability of a miss appears to be independent of the enemy’s level (when facing a player of equal level), as shown in the following plot:\n\n\n\nEnemy miss rate by level when player and enemy levels are equal.\n\n\nTaking an average across levels (weighted by the number of samples) gives a combined miss rate of 36.3%, which is very close to 4/1123. The consistency of this rate suggests that the miss mechanic is separate from the damage mechanics discussed above, which vary significantly with enemy and player level. However, if I plot the frequency of misses for a single enemy as the level of the player increases, we can see that the miss rate does eventually change:\n\n\n\nMiss rate of plains lupe versus player level.\n\n\nFor a plains lupe (an enemy with level one), the miss rate is consistently near 4/11 until the player reaches level eight, at which point the probability jumps to ~95%. This sharp transition can be seen in other enemies, although as expected the player level at which this occurs increases with the level of the enemy.\n\n\nPlayer Damage\n\nIn short: The distributions of player damage closely resemble those of enemy damage (unimodal, bounded), although their probability values differ. The upper and lower damage bounds vary linearly with player level, and encompass a wider range at higher levels. When using a weapon, the upper bound increases by an amount roughly equal to the in-game damage value, while the lower bound is unchanged. The player’s chance of missing an attack is ~10%, although it is unclear whether this varies as a function of player and enemy level.\n\nMy analysis of player damage will largely mirror that of enemy damage, except that I must also consider the effect of wielding a weapon. The histograms below show damage dealt by the player to four different enemies when the player and enemy levels are equal:\n\n\n\nDamage done by player when enemy and player levels are equal.\n\n\nThese plots show patterns similar to those found in the enemy damage distributions:\n\nThe range of each distribution is strictly bounded.\nDamage done at higher levels has a wider range than at lower levels.\nThe probability of doing zero damage is broadly consistent across enemies.\nWithin the bounded range, the damage probabilities are not uniform.\n\nAs with enemy damage, I have been unable to determine what formula the developers used to generate the player damage distributions, but it is still possible to analyze the upper and lower bounds. The following scatter plot shows these bounds when the player attacks an enemy of the same level, both with and without a sword:\n\n\n\nMaximum and minimum damage done by player when enemy and player levels are equal.\n\n\nThe damage bounds again show a linear dependence on level, with the upper bound increasing much more rapidly than the lower bound. Interestingly, wielding a sword that gives +3 damage (according to the in-game description) only affects the upper damage bound, and does not increase it uniformly (some of the bounds are only raised by two). The slopes and intercepts for the bounds are given in the following table as a function of player level - enemy level:\n\n\n\n\nCoefficient\n0\n1\n2\n3\n4\n\n\n\n\nlower slope\n0.24\n0.20\n0.27\n0.29\n0.26\n\n\nlower intercept\n1.19\n1.36\n0.97\n0.87\n1.20\n\n\nupper slope\n0.71\n0.76\n0.82\n0.82\n0.82\n\n\nupper intercept\n3.27\n3.05\n2.81\n2.99\n3.11\n\n\nupper w/ sword slope\n0.80\n0.73\n0.81\n0.81\n0.77\n\n\nupper w/ sword intercept\n5.44\n5.75\n5.42\n5.83\n6.20\n\n\n\nFrom these values, it is clear that the sword’s attack bonus does not alter the regression coefficient between the damage upper bound and the enemy level, only the intercept. Given that the bound values do not appear to have just been shifted upward, the weapon bonus is likely modified in some way before being added to the damage value. Since the slope is unchanged, this modification should be independent of enemy level.\nTurning finally to missed attacks, I can plot the player’s miss rate as a function of level when the player and enemy levels are equal:\n\n\n\nPlayer miss rate when player and enemy levels are equal.\n\n\nThe miss rates appear to fluctuate around 5-15%, seemingly due to the low sample size (judging by the confidence intervals). A weighted average across the different rates gives 9.7%, which is roughly 1/10. While it is likely that the miss rate would increase when fighting a much stronger opponent, I do not have combat data with a large enough level gap to verify this.\n\n\nFleeing\n\nIn short: The probability of successfully fleeing a fight is 62-63%, and this does not seem to change with the number of previous attempts. It is possible that the success probabilities could vary for different enemies, but there is not enough data to draw any firm conclusions.\n\nThe final combat mechanic that I will consider is fleeing. During their turn, the player can attempt to exit a fight and avoid any further combat, although whether they actually succeed is random. To begin my analysis, I will look broadly at how the probability of success changes with the number of prior fleeing attempts, based on ~500 samples:\n\n\n\nFlee success rate by attempt number.\n\n\nBased on these values, the success probability does not appear to change significantly after a previous attempt has been made (and failed). Looking at probabilities for individual levels also does not reveal any particular pattern or relationship:\n\n\n\nFlee success rate by player level.\n\n\nLevel eight could potentially have an elevated probability, but with only ~20 samples this apparent increase is unlikely to be significant. Finally, we can look at the success probabilities when fleeing from different enemies:\n\n\n\nFlee success rate by enemy.\n\n\nThere is enough variation here to suggest that some mechanism might be at play, especially when comparing the plains lupe and plains aisha. Still, without more data it is impossible to discern a clear pattern. Assuming that the flee success probability is constant, the average over all attempts yields a final probability of 62.3%, which is very close to 5/8."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#loot",
    "href": "projects/other/neoquest/neoquest.html#loot",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Loot",
    "text": "Loot\nIn short: The amount of gold found after defeating an enemy follows a Gaussian distribution, with the mean increasing linearly by ~2.3 gold per enemy level and the standard deviation increasing by ~0.7 gold per level. The number of experience points awarded to a party member decreases by 15 from 100 for every level the character has above the enemy’s level, and increases by 5 for every level below the enemy’s. The frequency of item loot does not follow any discernible pattern based on the gathered data, except that stronger enemies tend to drop more powerful items.\n\nThe third and final class of game mechanics that I will analyze here deals with “loot” that enemies give to the player when they are defeated. Whenever the player is victorious in a fight they will always find some quantity of gold24, regardless of any other variable. In addition, the player will usually gain experience points, and sometimes receive an item. These three types of loot will be the focus of this section.\n\nGold\nTo begin, we will look at the amount of gold that is found after defeating an enemy. The scatter plots below show gold distributions for a set of progressively stronger enemies as a function of player level25:\n\n\n\nAmount of gold versus player level for different enemies.\n\n\nAs expected, the amount of gold received tends to be higher for stronger enemies (skeleton knight) than weaker enemies (plains lupe). There does not appear to be any relationship between gold and player level, with one exception: when the gap between player and enemy level is very large, the game appears to glitch and give the exact same amount of gold (and items) for many victories in a row. This explains the clustering that is seen in several of the plots (especially the cave spyder’s) and is presumably not an intended game mechanic. For the remainder of this section I will exclude data from fights with a very high level gap.\nTurning now to the shapes of the distributions, I can use the observed mean and variance at a given enemy level to fit a Gaussian distribution, and then check whether it matches the shape of the empirical distribution:\n\n\n\nDistributions of gold loot for the first four enemy levels.\n\n\nThe Gaussian distributions show good agreement with the data, especially when considering distortions introduced by discretization. That said, the developers could be using a different formula that only appears Gaussian due to the central limit theorem26, although in that case we would expect to see greater deviations when the histogram is narrower (and we do not). Regardless, the characteristics of the data appear to be well-captured using normal distributions.\nAssuming that the data is Gaussian-distributed, the only two parameters that need to be characterized are the mean and standard deviation. Computing the average gold loot at each enemy level reveals a highly linear relationship27:\n\n\n\nAverage gold loot versus enemy level.\n\n\nThe slope and intercept of the best-fit line are 2.31 gold/level and 2.23 gold respectively. The standard deviation also has a broadly linear relationship with enemy level, although the fit is poorer:\n\n\n\nStandard deviation of gold loot versus enemy level.\n\n\nThe slope and intercept for the standard deviation are 0.70 gold/level and 1.12 gold respectively. Without data for stronger enemies, it is difficult to tell whether this apparently linear relationship will continue to hold or instead give way to a more complicated pattern at higher levels.\n\n\nExperience\nWhen an enemy is defeated, the player will gain experience based on the gap between their level and the enemy’s level. The simple relationship between this level gap and the number of experience points awarded can be seen in the following plot:\n\n\n\nExperience points versus the difference between player and enemy level.\n\n\nUnlike the other quantities that I have analyzed here, experience points are assigned by a deterministic game mechanism. Whenever a party member’s level is equal to the enemy’s level, 100 experience points will be given28. For every level the character has above the enemy’s level they will gain 15 less experience points, and for every level below the enemy’s level they will gain an additional 5 experience points. A strange exception to this is the miner ghost, who gives 110 experience points to a character of equal level and then has its points decrease by alternating values of 17 and 16 points per level. It is unclear whether this is intended behavior or a bug.\n\n\nItems\nThe third and final loot mechanic to discuss is item drops. Whenever an enemy is defeated, there is a chance that the player will find an item in addition to gold. In the first few regions of the game, the only items that can be looted from random encounters are Healing Vials, Healing Flasks, and Healing Potions, which will heal the player by 15, 25, and 35 hitpoints respectively. The frequency of receiving these three items (or no item at all) is shown in the following set of plots\n\n\n\nItem loot probabilities by type and enemy level.\n\n\nLooking at the distribution of points, there does not seem to be any obvious pattern that applies to all items and levels. For Healing Potions and Healing Flasks, which appear gradually as the enemy level increases, the initial rise in probability is more quadratic than linear. The probability of receiving no item gradually increase with level at first, and then drop significantly at level nine. We should expect that most items would follow a bell-like curve, with probabilities increasing at first but then beginning to drop as more powerful items become available for higher-level enemies to drop. Since each enemy only drops a small subset of items, it is possible for the developers to have manually set each item probability, without following any precise formula, but I will need more data to assess this."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#whats-next",
    "href": "projects/other/neoquest/neoquest.html#whats-next",
    "title": "Reverse Engineering NeoQuest II",
    "section": "What’s Next?",
    "text": "What’s Next?\nThis work represents the first stage of my efforts to reverse engineer NeoQuest II, serving as a useful proof of concept. However, for each game mechanic there were a number of complicating factors that I purposefully ignored in my analysis, either because they were absent from earlier stages of the game or because they require much larger quantities of data to resolve. Below is a (non-exhaustive) list with many examples of such factors:\n\nEncounters\n\nWhat is the probability of encountering more than one enemy at a time?\nHow do encounter probabilities vary between tiles in the same region?\n\nCombat\n\nDoes the first-move mechanic remain consistent when there are multiple party members and enemies?\nDo all enemies have a recovery time between 5 and 6 seconds? What about bosses?\nDo all party members have the same recovery time as a function of innate haste?\nDo different kinds of actions (melee attacks, spells, potions, abilities) have different recovery times?\nHow do haste spells and potions interact with haste skill points?\nHow does stunning work?\nWhat effect does armor have on enemy damage?\nHow do damage-based skills affect melee damage?\nHow much damage do spells do?\nHow do special abilities work?\nDoes the success rate of fleeing depend on the player’s map location?\n\nLoot\n\nHow do the mechanics for loot change when multiple enemies are defeated in a single encounter?\nHow is the weapon/armor loot for bosses determined?\n\n\nMost of these questions are unanswered because my analysis focused exclusively on Rohane, and only considered encounters with one of thirteen enemies (spanning the first nine enemy levels). In the next stage of my analysis, I will need to develop effective data-gathering schemes for later parts of the game, where resetting is no longer an easy option29. Fortunately, the preliminary analysis that I have done here provides a good roadmap for what to aim for in future playthroughs, so that the entirety of NeoQuest II can eventually be unlocked."
  },
  {
    "objectID": "projects/other/neoquest/neoquest.html#footnotes",
    "href": "projects/other/neoquest/neoquest.html#footnotes",
    "title": "Reverse Engineering NeoQuest II",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSimilar games in this genre are Tamagotchi and Nintendogs, although Neopets is fairly unique in being entirely web-based.↩︎\nI don’t know for sure whose idea it was to name my first Neopet fatty_tubby_lard_big, but it did happen.↩︎\nEuphemism for “game-breaking hacking which supplies a real-world Neopets black market”.↩︎\nThe future is much brighter for Neopets’ flash games, which are being preserved by BlueMaxima’s Flashpoint project.↩︎\nA nice example is the guide on Jellyneo.net.↩︎\nTurns out that this was not, in fact, simple.↩︎\nThe plot is actually much weirder than this, but I won’t spoil it here.↩︎\nNorth, South, East, West↩︎\nNorthwest, Northeast, Southwest, Southeast↩︎\nTo be honest, I suspect that just sending bare POST requests from a script would have worked, given the sad state of the site.↩︎\nOver time these memory demands will actually crash the browser unless it is periodically paused.↩︎\nThis is the data structure that HTML documents are parsed into by the browser when it loads a web page.↩︎\nThe game state itself is usually updated even if a new page isn’t returned, but occasionally even that will fail.↩︎\nI have removed some logging functions from this example code, as they will be discussed in the next section.↩︎\nThese are Wilson score intervals for a binomial distribution.↩︎\nNote that these are in-game seconds, with no relationship at all to actual playtime.↩︎\nAssuming they are not stunned or slowed.↩︎\nIt certainly will not apply for enemies that have cast haste spells.↩︎\nThe source of these tails is not obvious, but they could perhaps result from some discretization procedure.↩︎\nPlus any armor that the player has equipped, although I will not be considering that here.↩︎\nThese enemies were selected because it was easy to gather ~5,000 damage samples from them.↩︎\nThe intercept here is the theoretical value when the enemy level is zero.↩︎\nIt seems likely that the developers would favor simple rational numbers in their mechanics.↩︎\nThere is actually a very small chance that the player will not receive any gold, but this is almost certainly a bug.↩︎\nThese plots have had some jitter applied to them for better visualization of overlapping points, but the actual gold amounts are all whole integers.↩︎\nThis theorem states that the sum of random variables will tend toward a Gaussian distribution as the number of variables increases.↩︎\nNote that the trend line shown below was fit to the individual samples, not to the per-level means directly.↩︎\nEquivalently, whenever the player’s level is equal to one less than the number of enemy hitpoints divided by five, 100 experience points will be awarded.↩︎\nThe biggest issue is that you cannot un-level a character without restarting the game, so victories in combat must be tightly controlled.↩︎"
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html",
    "href": "projects/other/speedrunning/speedrunning.html",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#overview",
    "href": "projects/other/speedrunning/speedrunning.html#overview",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Overview",
    "text": "Overview\nIn this project, I present a set of data visualizations that describe the current state of speedrunning, which is a form of competitive gaming where players attempt to complete a game or level as quickly as possible. These visualizations were created using Microsoft Power BI, and built atop data from ~1.5 million players retrieved using the API of speedrun.com (a website used by the vast majority of speedrunners to log their progress).\nPower BI reports can be challenging to share outside of Microsoft Power Platform and the surrounding ecosystem, especially when they include large amounts of data. In the following sections, I provide images of each report page along with a description of its key conclusions and some of the DAX code used to create the visualizations. The GitHub repository for this project contains a PDF of the report and a Python file with the API request code. The complete .pbix file, including data, can be downloaded here (420 MB) and imported into Power BI Desktop in order to make the report interactive."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#the-data-model",
    "href": "projects/other/speedrunning/speedrunning.html#the-data-model",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "The Data Model",
    "text": "The Data Model\nBefore diving into the visualization within the report, we will first take a closer look at its underlying data model. There are fourteen tables within the model that have relationships between one another, and which hold all of the data1. Their model diagram is given below:\n\n\n\nThe table relationships which form the data model.\n\n\nThe most important tables are users and runs, which hold information about the individual players and speedruns respectively. Since it is possible for one user to have multiple speedruns and for one speedrun to be performed by multiple users, the two tables must be linked together using the bridge table run_user. The run_user table is also connected to world_records, which holds information about the subset of speedruns which were the fastest ever at the time of their submission. Another important table is games, which holds information about every game that has had at least one speedrun submitted. The platforms and game_genre tables provide further information about the game’s hardware and genre type.\nThe table with the most relationships is Date, which as its name suggests is a date table. Date tables contain information about individual dates within some period of interest, such as the year, month, day of the week, etc. While all of this information can be calculated on the fly, the date table guarantees that all dates are covered and allows for DAX filtering across various date/time attributes."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#runs-overview",
    "href": "projects/other/speedrunning/speedrunning.html#runs-overview",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Runs Overview",
    "text": "Runs Overview\nThe first page of the report provides summary statistics for all of the speedruns that have been submitted to the speedrun.com website:\n\n\n\nThe first page of the report.\n\n\nThe upper-left quadrant contains a slicer that restricts the data to all runs that were submitted at or before the chosen year2. The quadrant also contains a “card” visualization that counts the total number of runs within the filter context, which is computed using the following DAX code:\ncumulative_runs := IF(\n    HASONEVALUE(year_slices[Year]), \n    CALCULATE(\n        [total_runs], \n        FILTER(\n            runs, \n            YEAR(runs[date_run]) &lt;= VALUES(year_slices[Year])\n        ), \n        NOT(ISBLANK(runs[date_run]))\n    ), \n    [total_runs]\n)\nThe CALCULATE function computes the total_runs measure (which just counts the rows in the runs table) under a filter context whose condition is based on the state of the slicer. The slicer propagates the context onto the measure using the stand-alone year_slices table, which is filtered directly by the slicer and then queried using the VALUES function. If no year is chosen on the slicer, or multiple values are chosen, no additional filters are applied to the total_runs measure. The bar charts in the other three quadrants are also calculated using the cumulative_runs measure, just with different types of filtering (platform, game title, and genre) applied on top of the slicer’s context."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#users-overview",
    "href": "projects/other/speedrunning/speedrunning.html#users-overview",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Users Overview",
    "text": "Users Overview\nThe second page of the report gives information about the speedrun.com userbase:\n\n\n\nThe second page of the report.\n\n\nThere is less information available about users than there is for speedruns, so this page focuses on their gender breakdown and home country. The slicer in the upper-left of the page divides the users into categories based on their role/activity on speedrun.com: administrators run the site, examiners determine the legitimacy of runs submitted to the site, runners have submitted at least one speedrun to the site, users with no activity have only created an account on the site, and banned players committed some transgression that got them kicked off of the site.\nAcross all categories, the United States is the most common home country for speedrunners. The rank of the other countries varies depending on the type of user, with countries such as Vietnam and India being especially overrepresented among banned players. Although information about gender is not directly gathered by speedrun.com, the site does provide a user’s preferred pronouns (if they have been declared). In the report, these pronouns are classified into gender categories using the following calculated column:\nusers[pronouns_simplified] = IF(\n    EXACT(\"She/Her\", users[pronouns]) || EXACT(\"He/Him\", users[pronouns]) || ISBLANK(users[pronouns]),\n    users[pronouns],\n    IF(\n        EXACT(\"\", users[pronouns]),\n        \"None given\",\n        \"Non-binary\"\n    )\n)\nWhile this transformation is imperfect, it can broadly capture trends in male/female representation among speedrunners."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#covid-impact",
    "href": "projects/other/speedrunning/speedrunning.html#covid-impact",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Covid Impact",
    "text": "Covid Impact\nThe third page of the report looks at trends in speedrunning activity over time, with particular interest paid to how the COVID-19 pandemic impacted participation:\n\n\n\nThe third page of the report.\n\n\nThe most complicated aspect of these plots is the trend line, which needed to be fit to the data and then extrapolated forward in the plot. This was done using a sequence of DAX measures based off of regression coefficients contained in the stand-alone tables runs_trend_coeff and users_trend_coeff. The functions for computing the speedruns trend line are given below:\nruns_trend[diff] = DATEDIFF(DATE(2015, 1, 1), runs_trend[Date], MONTH) \n\nruns_trend[trend] = \n    VALUES(runs_trend_coeff[Intercept]) + runs_trend[diff] * VALUES(runs_trend_coeff[Slope1])\n\nruns_trend_val := CALCULATE(\n    SUM(runs_trend[trend]), \n    KEEPFILTERS(runs_trend[Date] &gt; DATE(2019, 1, 1))\n)\nThe diff calculated column computes the time difference between the starting date of the regression function (1/1/2015) and the sequence of dates from 1/1/2015 to 4/30/2023 (the date the data was retrieved from speedrun.com). Using the regression coefficients in runs_trend_coeff, the diff column is then further transformed into the trend column, which holds the value of the trend line at each date. The runs_trend_val measure at the end is simply used to control how much of the trend line should be displayed on the plot3, by combining the chosen end date filter with the existing context generated by the graph."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#distribution-of-runs",
    "href": "projects/other/speedrunning/speedrunning.html#distribution-of-runs",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Distribution of Runs",
    "text": "Distribution of Runs\nThe fourth page of the report describes how runs are distributed across games, platforms, and players:\n\n\n\nThe fourth page of the report.\n\n\nThe histograms on this page show that the vast majority of players have submitted fewer than five speedruns, and that only a small fraction of games are able to attract more than a thousand speedruns. Creating histograms with customized bin widths and labels can be a bit awkward in Power BI, with the easiest method being the creation of stand-alone calculated tables. For example, the table user_run_hist used for the runners plot at the bottom of the page is given by the following DAX code:\nuser_run_hist = DATATABLE(\n    \"start\", INTEGER, \"end\", INTEGER, \"label\", STRING, \n    {{1, 1, \"1\"}, \n    {2, 2, \"2\"},\n    {3, 3, \"3\"},\n    {4, 4, \"4\"},\n    {5, 5, \"5\"},\n    {6, 10, \"6-10\"}, \n    {11, 20, \"11-20\"}, \n    {21, 100, \"21-100\"}, \n    {101, 1000, \"101-1000\"},  \n    {1001, 100000000000, \"&gt;1000\"}}\n)\n\nuser_run_hist[run_count] = COUNTROWS(\n    FILTER(\n        users, \n        (users[run_count] &gt;= user_run_hist[start]) && (users[run_count] &lt;= user_run_hist[end])\n    )\n) \nThe functions above show the basic logic for this type of histogram table, where a set of start and end values are specified to define the different bins, along with a set of labels. The count for each bin is then computed by filtering a data table (users in this case) using its start and end points."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#world-records",
    "href": "projects/other/speedrunning/speedrunning.html#world-records",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "World Records",
    "text": "World Records\nThe fifth page of the report shows a variety of statistics involving world records on the speedrun.com site, which are the speedruns that have the fastest times:\n\n\n\nThe fifth page of the report.\n\n\nThe upper-left quadrant gives the total number of world record submissions, and the total number of users who have held at least one world record. This latter value is derived from the calculated column record_count on the users data table, which utilizes the relationship between users and the world_records table:\nusers[record_count] = COUNTROWS(\n    CALCULATETABLE(\n        world_records, \n        CALCULATETABLE(\n            run_user, \n            USERELATIONSHIP(world_records[id], run_user[run_id])\n        )\n    )\n)\nThe USERELATIONSHIP function is necessary since the relationship between users and world_records (via the run_user bridge table) is inactive in the data model.\nThe plots in the remaining three quadrants all show different statistics for the world record speedruns. In the upper-right quadrant, we can see that some speedrunners have set thousands of world records, with the most prolific runner having submitted close to 10,000 records. In the bottom-left quadrant, a histogram of speedrun lengths for the current world records is given, showing that most world-record speedruns last from 1 - 10 minutes. The bottom-right histogram looks at how the number of world record submissions has changed over time, compared to the number of total speedruns."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#example-record-progression",
    "href": "projects/other/speedrunning/speedrunning.html#example-record-progression",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Example Record Progression",
    "text": "Example Record Progression\nThe sixth page of the report focuses on a single game, and shows how the world record progressed over time:\n\n\n\nThe sixth page of the report.\n\n\nThe example game used here is SpongeBob SquarePants: Battle for Bikini Bottom, which has a fairly robust speedrunning scene. The ribbon chart in the upper-left shows the first, second, and third-place speedrunners on the leaderboard from 2015 to 2023. This plot is based on a calculated table sponge_bob that computes the fastest times for each speedrunner:\nsponge_bob = SUMMARIZE(\n    spongebob, \n    spongebob[Year], \n    spongebob[username], \n    \"best_run\", \n    MIN(spongebob[run_time])\n)\nThe SUMMARIZE function operates on an existing table and performs an aggregation operation (MIN) using the provided grouping columns (Year and username). With this information calculated, it is easy to pick out the top three speedrunners for each year and plot them in the ribbon chart.\nThe bottom line chart shows the game’s world record progression over time, with each scatter point denoting a new world record. We can see that progress was greater in the earlier stages, but then slowed down as the speedrun becomes more optimized and competitive."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#progression-statistics",
    "href": "projects/other/speedrunning/speedrunning.html#progression-statistics",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Progression Statistics",
    "text": "Progression Statistics\nThe seventh and final page of the report describes general patterns for how world records tend to progress:\n\n\n\nThe seventh page of the report.\n\n\nThe bottom-left plot shows the percentage improvement that is observed when a new world record replaces the older record. This plot is computed using the improvements table, which gives the difference between sequential records:\nimprovements[prc_gap] = 100 * improvements[time_gap] / RELATED(runs[run_time])\nimprovements[gap_bin] = (FLOOR(improvements[prc_gap], 1) + 1) / 100\nThe prc_gap calculated column computes the ratio of the time gap over the total run duration, which is accessed from the runs table using RELATED. The gap_bin column groups together those improvement ratios into clear percentages, which are then aggregated and plotted.\nThe funnel plot at the top-right of the page shows how old the current set of world records are, with a record counting for a particular bin if it is at least as old as the label. As can be easily seen, most speedrunning world records are less than a year old.\nIn the bottom-right of the page, there is a histogram that shows the distribution of speedrunners across categories. Although this data does not explicitly involve world records, it shows that most categories have only one or two speedrunners that ever submitted records. This implies that a large number of world records are uncompetitive, and that the speedrunning community as a whole is spread thin across many different games."
  },
  {
    "objectID": "projects/other/speedrunning/speedrunning.html#footnotes",
    "href": "projects/other/speedrunning/speedrunning.html#footnotes",
    "title": "State of Speedrunning: A Power BI Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere are an additional ten unconnected tables used to facilitate some of the visualizations and filtering.↩︎\nWhen nothing is selected, all runs are included.↩︎\nVALUES could also have been used in this measure instead of SUM.↩︎"
  },
  {
    "objectID": "projects/phd/bayesian/bayesian.html",
    "href": "projects/phd/bayesian/bayesian.html",
    "title": "Bayesian Inference for Quantum Error Correction",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/phd/bayesian/bayesian.html#overview",
    "href": "projects/phd/bayesian/bayesian.html#overview",
    "title": "Bayesian Inference for Quantum Error Correction",
    "section": "Overview",
    "text": "Overview\nThese two research projects used Bayesian statistical methods to perform error correction for quantum computers, as described in “A Logarithmic Bayesian Approach to Quantum Error Detection”:\n\nWe consider the problem of continuous quantum error correction from a Bayesian perspective, proposing a pair of digital filters using logarithmic probabilities that are able to achieve near-optimal performance on a three-qubit bit-flip code, while still being reasonable to implement on low-latency hardware. These practical filters are approximations of an optimal filter that we derive explicitly for finite time steps, in contrast with previous work that has relied on stochastic differential equations such as the Wonham filter. By utilizing logarithmic probabilities, we are able to eliminate the need for explicit normalization and can reduce the Gaussian noise distribution to a simple quadratic expression. The state transitions induced by the bit-flip errors are modeled using a Markov chain, which for log-probabilties must be evaluated using a LogSumExp function. We develop the two versions of our filter by constraining this LogSumExp to have either one or two inputs, which favors either simplicity or accuracy, respectively. Using simulated data, we demonstrate that the single-term and two-term filters are able to significantly outperform both a double threshold scheme and a linearized version of the Wonham filter in tests of error detection under a wide variety of error rates and time steps.\n\nand “Machine Learning for Continuous Quantum Error Correction on Superconducting Qubits”:\n\nContinuous quantum error correction has been found to have certain advantages over discrete quantum error correction, such as a reduction in hardware resources and the elimination of error mechanisms introduced by having entangling gates and ancilla qubits. We propose a machine learning algorithm for continuous quantum error correction that is based on the use of a recurrent neural network to identify bit-flip errors from continuous noisy syndrome measurements. The algorithm is designed to operate on measurement signals deviating from the ideal behavior in which the mean value corresponds to a code syndrome value and the measurement has white noise. We analyze continuous measurements taken from a superconducting architecture using three transmon qubits to identify three significant practical examples of non-ideal behavior, namely auto-correlation at temporal short lags, transient syndrome dynamics after each bit-flip, and drift in the steady-state syndrome values over the course of many experiments. Based on these real-world imperfections, we generate synthetic measurement signals from which to train the recurrent neural network, and then test its proficiency when implementing active error correction, comparing this with a traditional double threshold scheme and a discrete Bayesian classifier. The results show that our machine learning protocol is able to outperform the double threshold protocol across all tests, achieving a final state fidelity comparable to the discrete Bayesian classifier.\n\nwhose abstracts are given above.\nThe examples.ipynb notebook in the GitHub repo (linked above) provides a description of the Bayesian error correction algorithm, along with sample code that runs a toy example. The full model code can be found within the log_bayes.py and real_data.py modules in the src directory.\nA non-interactive version of the Jupyter notebook is reproduced below."
  },
  {
    "objectID": "projects/phd/bayesian/bayesian.html#a-brief-introduction-to-quantum-error-correction",
    "href": "projects/phd/bayesian/bayesian.html#a-brief-introduction-to-quantum-error-correction",
    "title": "Bayesian Inference for Quantum Error Correction",
    "section": "A Brief Introduction to Quantum Error Correction",
    "text": "A Brief Introduction to Quantum Error Correction\nWhen using a quantum computer, we are interested in the behavior of objects known as qubits. A qubit is similar to the classical bit used in standard computers, except that it can take on states that are in-between the usual 0 and 1 binary values. These intermediate configurations are known as superpositions, and are what allow quantum computers to carry out certain tasks much more efficiently than standard computers.\nOne of the disadvantages of quantum computers is that they are very susceptible to errors. These errors perturb the state of the qubits, and will ultimately corrupt the output of the algorithm if not corrected. Fortunately, it is possible to monitor the state of the qubits in real time during a calculation and detect when an error occurs. An operation can then be performed on the affected qubit to undo the error and bring the qubit back into its correct state.\nThe qubits are monitored by performing quantum measurements, which will generate time-series data that can be analyzed to check for errors. The form of these measurements will change depending on the number of qubits and the type of errors that are expected, but for simplicity we will focus on a three-qubit system that is perturbed by bit-flip errors. Under normal operations, each qubit should be in the same state as the other qubits, but a bit-flip error on one of the qubits will break this symmetry. To determine which qubit has been flipped, we can perform a parity measurement on two different pairs of qubits, which gives a value of -1 if the two qubits are in the same state and +1 if they are in different states. If at least one measurement returns a value of +1, then we know that an error has occurred and can figure out which qubit was flipped.\nThe process described above is very straightforward if we can know the exact values of the parity measurements, but unfortunately this is often not possible. Instead, we end up with a signal whose mean will be centered on +1 or -1, but which will also have a large amount of Gaussian noise on top of it. To extract out the parity measurement, we must apply some kind of filtering algorithm to the signal, which is where Bayesian inference can be very useful."
  },
  {
    "objectID": "projects/phd/bayesian/bayesian.html#the-measurement-data",
    "href": "projects/phd/bayesian/bayesian.html#the-measurement-data",
    "title": "Bayesian Inference for Quantum Error Correction",
    "section": "The Measurement Data",
    "text": "The Measurement Data\nBefore describing the Bayesian model, we will first take a closer look at the measurement data itself. Since we are interested in training an algorithm to detect bit-flip errors, we will want to look at measurements from qubits that have been deliberately flipped in a consistent and controlled manner. The following code loads a set of sample measurement data and plots one of the time series:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.load(\"src/data/measurements.npz\")\nmeasurements = data[\"measurements\"][0, 1, :, 0] # Index 1 marks the qubit state, Index 2 marks the flipped qubit\nprint(f\"The data has {measurements.shape[1]} measurements in the time series for each of the two qubit pairs.\")\nplt.plot(data[\"times\"], measurements.T)\nplt.xlabel(r\"Time ($\\mu$s)\", fontsize = 16)\nplt.ylabel(\"Measurement\", fontsize = 16)\nplt.gcf().set_size_inches(10, 7)\nplt.show()\nThe data has 192 measurements in the time series for each of the two qubit pairs.\n   \n\n\n\nCode output showing noisy measurements.\n\n\nAlthough it is difficult to tell from this plot, both of the parity measurements (the parity of the first and second qubit is shown in blue, while the parity of the second and third qubits is shown in orange) are centered on -1 until the 3 \\(\\mu\\)s mark. Then an error occurs on the first qubit, which causes the mean of the blue line to shift down to +1. It is clear from the plot that there is a significant amount of noise in the measurements, with noticeable autocorrelation between neighboring values.\nGiven the large variance in the measurements, the changes induced by the bit flips are easiest to see by plotting the measurement means.\n\n\n\nSyndrome dynamics during bit flips.\n\n\nEach row of plots corresponds to a different starting configuration of the qubits, with each qubit either in the 0 or 1 state. The different columns correspond to different bit flips, with the first column containing no bit flips and columns 2, 3, and 4 corresponding to flips of qubits 1, 2, and 3 respectively. The figure as a whole shows several interesting behaviors, such as a clear oscillation pattern that occurs after certain flips. We can also see that the means do not exactly align at +1 and -1, but instead drift somewhat over time. These imperfections are something that will need to be dealt with by the filtering algorithm."
  },
  {
    "objectID": "projects/phd/bayesian/bayesian.html#the-bayesian-filter",
    "href": "projects/phd/bayesian/bayesian.html#the-bayesian-filter",
    "title": "Bayesian Inference for Quantum Error Correction",
    "section": "The Bayesian Filter",
    "text": "The Bayesian Filter\nOur goal in quantum error correction is to determine what error, if any, has perturbed the state of the qubits in our quantum computer. Given the measurement signals plotted in the previous section, the detection of an error is equivalent to detecting when the mean of the measurement signal switches from -1 to +1. Assuming that the errors are uncorrelated, we can describe the system of qubits and measurement signals using a hidden Markov model. The qubit states represent a hidden Markovian variable, with a probability of transition depending only on the current state. Since the measurement signal follows a Gaussian distribution whose mean is determined by the qubit states, we can use observations of the signal to make inferences about the hidden Markov variable. The following code shows the basic features of the hidden Markov model:\nimport torch\n\nclass Bayesian():\n\n    # This class represenrs the Bayesian classifier designed to handle\n    # the autocorrelations present in imperfect measurement data.\n\n    def __init__(self, depth):\n\n        # The depth attribute determines how many prior syndrome measurements to\n        # condition on when calculating the Gaussian likelihood of a new syndrome\n        # measurement. For depth &gt; 0, this allows the model to leverage any\n        # autocorrelation that may be present in the data.\n\n        self.depth = depth\n\n        # This is simply a list of the other attributes that will be used.\n\n        self.transition_matrix = None\n        self.gauss_means = None\n        self.gauss_precs = None\n        self.prior = None\n        self.prev_synd = None\n\n    def classify(self, measurements):\n\n        # This method returns the posterior probability, with shape (num_runs, 8),\n        # of each label given a batch of measurments with shape (num_runs, 2). The\n        # internal state of the classifier is also updated appropriately, with the\n        # prior being updated to the posterior and the previous syndromes being\n        # updated to include the new measurements.\n\n        m_1_batch = torch.cat(\n            [self.prev_synd[:, 0:1], measurements[None, 0:1]], dim=1)\n        m_2_batch = torch.cat(\n            [self.prev_synd[:, 1:2], measurements[None, 1:2]], dim=1)\n        likelihood = self.get_gaussian_outputs(m_1_batch, m_2_batch)\n        unnorm_probs = torch.einsum(\n            \"al,lr-&gt;ar\", self.prior.float(), self.transition_matrix.float()) * likelihood\n        posteriors = unnorm_probs / \\\n            torch.sum(unnorm_probs, dim=1, keepdim=True)\n        self.prior = posteriors\n        if self.depth:\n            self.prev_synd = torch.cat(\n                [self.prev_synd[1:, :], measurements[None, :]])\n        return posteriors[0]\n\n    def get_gaussian_outputs(self, m_1_batch, m_2_batch):\n\n        # This method calculates the Gaussian likelihoods for the syndrome pair in\n        # the most recent step, conditioned on a number of prior measurements determined\n        # by the depth attribute. This means that the m_1_batch and m_2_batch must both\n        # have shapes of (num_runs, depth + 1).\n\n        (num_runs, num_steps) = m_1_batch.shape\n        joint_batch = torch.cat([m_1_batch, m_2_batch], dim=1)\n        marg_batch = torch.cat([m_1_batch[:, :-1], m_2_batch[:, :-1]], dim=1)\n\n        joint_centered = joint_batch.reshape(\n            [num_runs, 1, 2*(self.depth + 1)]) - self.joint_means.reshape([1, 8, 2*(self.depth + 1)])\n        joint_expon = -0.5*torch.einsum(\"ali,lij,alj-&gt;al\", joint_centered.float(\n        ), self.joint_precs.float(), joint_centered.float())\n        joint_output = joint_expon + 0.5*torch.slogdet(self.joint_precs)[1]\n\n        if self.depth &gt; 0:  # The marginal distribution only exists if depth &gt; 0\n            marg_batch = torch.cat(\n                [m_1_batch[:, :-1], m_2_batch[:, :-1]], dim=1)\n            marg_centered = marg_batch.reshape(\n                [num_runs, 1, 2*self.depth]) - self.marg_means.reshape([1, 8, 2*self.depth])\n            marg_expon = -0.5*torch.einsum(\"ali,lij,alj-&gt;al\", marg_centered.float(\n            ), self.marg_precs.float(), marg_centered.float())\n            marg_output = marg_expon + 0.5*torch.slogdet(self.marg_precs)[1]\n            log_output = joint_output - marg_output\n        else:\n            log_output = joint_output\n        outputs = torch.exp(log_output)  # Only exponentiate at the end\n        return outputs\nThe main method of interest here is classify, which takes as input two parity measurements (one for each pair of qubits) and returns a set of posterior probabilities for each qubit configuration (i.e. the state of the hidden Markov variable). The model starts by transforming its prior distribution, which are the probabilities generated by the previous call to classify (or the initial state of the qubits) using the bit-flip transition matrix, and then updates them based on the measurement data. Since the measurements are Gaussian distributed, we can easily compute the likelihood associated with each qubit state by setting the means to +1 or -1, which is done in the get_gaussian_outputs method. In order to take into account any autocorrelation between sequential samples, we can store the previous measurement values and use them as input to the Gaussian likelihood.\nIn the code block above, the transition matrix and Gaussian parameter are left uninitialized. To get values for them, we can fit to a set of measurement data like that shown in the previous section. For each qubit state, the means of the measurement values can be computed and stored in self.gauss_means, while variance and covariance values are stored in self.gauss_precs. The transition matrix cannot be fit using data with artificial errors, but its elements can be computed by assuming some plausible error rate for the quantum computer based on its hardware.\nTo evaluate a trained model, we can simulate measurement data and then test how well the model is able to predict the state of the (simulated) qubits. An example test is shown in the following code:\nimport torch\n\nfrom src import tools, real_data\n\nprint(\"Generating data...\")\n(train_data, train_labels) = tools.Real_Simulated(error_rate_sec = 0.01*1e6).generate_data(30000, 60)\n(test_data, test_labels) = tools.Real_Simulated(error_rate_sec = 0.01*1e6).generate_data(30000, 60)\n\nmodel = real_data.Bayesian(0)\nmodel.train(train_data, train_labels)\n\nm_1 = test_data[:, :, 0]\nm_2 = test_data[:, :, 1]\n(num_runs, num_steps) = m_1.shape\noutputs = torch.zeros([num_runs, 0])\nmodel.prior = torch.zeros([num_runs, 8])\nmodel.prior[torch.arange(num_runs), test_labels[:, 0].type(torch.long)] = 1\nnum_correct = torch.zeros([num_runs])\nprint(\"Testing...\")\nfor step in range(num_steps):\n\n    # For each step, the new prior is calculated by contracting the previous\n    # prior with the transition matrix, then scaling by the measurement \n    # probabilities.\n\n    m_1_slice = m_1[:, step:step + 1]\n    m_2_slice = m_2[:, step:step + 1]\n    sample_probs = model.get_gaussian_outputs(m_1_slice, m_2_slice)\n    unnorm_probs = torch.einsum(\"al,lr-&gt;ar\", model.prior.float(), model.transition_matrix.float()) * sample_probs\n    model.prior = unnorm_probs / torch.sum(unnorm_probs, dim = 1, keepdim = True)\n    predictions = torch.argmax(model.prior, dim = 1)\n    true_states = test_labels[:, step]\n    fidelity = (predictions == true_states)\n    num_correct = num_correct + fidelity\n    outputs = torch.cat([outputs, predictions[:, None]], dim = 1)\n    print(\"\\rStep {}/{}\".format(step, num_steps), end = \"\")\n\nacc = num_correct * 100 / num_steps\nprint(\"\\nAcc: {:.2f}%\".format(torch.mean(acc)))\nThe final accuracy value reports how often the model correctly predicted the state of the system. Due to the irreducible noise in the measurement value, an accuracy of 100% will be virtually impossible for any large sample size. Indeed, the performance of this model is effectively optimal on the simulated data, since we use a Gaussian distribution to sample the measurement values and assume that the qubits states follow Markovian dynamics."
  },
  {
    "objectID": "projects/phd/mi-scaling/mi-scaling.html",
    "href": "projects/phd/mi-scaling/mi-scaling.html",
    "title": "Quantifying Mutual Information via Logistic Regression",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/phd/mi-scaling/mi-scaling.html#overview",
    "href": "projects/phd/mi-scaling/mi-scaling.html#overview",
    "title": "Quantifying Mutual Information via Logistic Regression",
    "section": "Overview",
    "text": "Overview\nThis research project sought to characterize how correlations between patches of pixels in an image dataset scaled as a function of the patch size. This approach is analogous to the well-known entanglement scaling analysis that is done in quantum physics. The work here culminated in the publication “Mutual Information Scaling for Tensor Network Machine Learning”, whose abstract is given here:\n\nTensor networks have emerged as promising tools for machine learning, inspired by their widespread use as variational ansatze in quantum many-body physics. It is well known that the success of a given tensor network ansatz depends in part on how well it can reproduce the underlying entanglement structure of the target state, with different network designs favoring different scaling patterns. We demonstrate here how a related correlation analysis can be applied to tensor network machine learning, and explore whether classical data possess correlation scaling patterns similar to those found in quantum states which might indicate the best network to use for a given dataset. We utilize mutual information as a measure of correlations in classical data, and show that it can serve as a lower-bound on the entanglement needed for a probabilistic tensor network classifier. We then develop a logistic regression algorithm to estimate the mutual information between bipartitions of data features, and verify its accuracy on a set of Gaussian distributions designed to mimic different correlation patterns. Using this algorithm, we characterize the scaling patterns in the MNIST and Tiny Images datasets, and find clear evidence of boundary-law scaling in the latter. This quantum-inspired classical analysis offers insight into the design of tensor networks which are best suited for specific learning tasks.\n\nA summary of the project is presented in the examples.ipynb notebook on GitHub (linked above), along with a portion of the experiments used to generate the paper’s numerical results. The full source code is given in the src folder, although it is missing some of the large data files that are needed for all portions of the code to run.\nA non-interactive version of the Jupyter notebook is reproduced below."
  },
  {
    "objectID": "projects/phd/mi-scaling/mi-scaling.html#a-brief-introduction-to-mutual-information-estimation",
    "href": "projects/phd/mi-scaling/mi-scaling.html#a-brief-introduction-to-mutual-information-estimation",
    "title": "Quantifying Mutual Information via Logistic Regression",
    "section": "A Brief Introduction to Mutual Information Estimation",
    "text": "A Brief Introduction to Mutual Information Estimation\nThis work focuses on a quantity called the mutual information (MI), which describes the dependence between two variables \\(a\\) and \\(b\\) obeying the joint probability distribution \\(p(a, b)\\). It is defined as the difference between the entropy of \\(p(a)p(b)\\), which is the product of the marginal distributions, and the entropy of \\(p(a, b)\\):\n\\[\\begin{equation}\n\\text{MI}(a,b) = \\text{S}[p(a)p(b)] - \\text{S}[p(a, b)] = \\text{S}[p(a)] + \\text{S}[p(b)] - \\text{S}[p(a,b)],\n\\end{equation}\\]\nwhere \\(\\text{S}\\) is the usual Shannon entopy. The MI can be qualitatively understood as a generalization of the Pearson correlation coefficient to non-linear relationships between variables, and it serves as the most general measure of dependence. This means that a non-zero correlation coefficient always implies a non-zero MI value, but the converse is not necessarily true.\nGiven access to the underlying probability distributions \\(p(a, b)\\), \\(p(a)\\), and \\(p(b)\\), it is usually straightforward to compute the individual entropies and thus the MI. However, what if we only had access to \\(N\\) samples from the joint distribution \\(p(a, b)\\)? If the variables are discrete and span a relatively small number of values, then the entropy could be estimated from \\(\\text{S}[p(x)] = \\sum_x p(x)\\log p(x)\\) using the observed frequencies in place of the probabilities. However, in cases where the variable \\(x\\) is continuous or effectively continuous, the observed frequencies of each value in the domain will not carry sufficient information for the entropies and thus the MI to be estimated.\nTo get around this issue, we need to impose some functional form on \\(p(a, b)\\) and \\(p(a)p(b)\\). One powerful method is to represent the probability distributions using a neural network trained on the \\(N\\) samples from \\(p(a, b)\\). This can be done in a straightforward manner by constructing artificial samples from the product-of-marginal distribution \\(p(a)p(b)\\), and then optimizing the neural network model using a cross-entropy loss function to distinguish between samples from \\(p(a)p(b)\\) and samples from \\(p(a, b)\\). The general workflow is:\n\nFrom samples \\(\\{(a_i, b_i)\\}^N_{i=1}\\), generate a new set \\(\\{(a_i, b_j)\\}_{i \\neq j}\\) by randomly shuffling values for the variable \\(b\\) between different samples. This simulates sampling from \\(p(a)p(b)\\).\nTrain a logistic regression neural network algorithm to distinguish between samples taken from the two datasets in the previous step.\nUse the output of the neural network to estimate the MI of \\(\\{(a_i, b_i)\\}^N_{i=1}\\).\n\nIn our case, we will be interested in the MI between different sets of pixels in an image dataset, so our \\(a\\) and \\(b\\) variables will correspond to different groups of pixels in the same image. The shuffling in step 1 will consist of stitching together new images using pixel patches taken from the original samples."
  },
  {
    "objectID": "projects/phd/mi-scaling/mi-scaling.html#testing-on-gaussian-markov-random-fields",
    "href": "projects/phd/mi-scaling/mi-scaling.html#testing-on-gaussian-markov-random-fields",
    "title": "Quantifying Mutual Information via Logistic Regression",
    "section": "Testing on Gaussian Markov Random Fields",
    "text": "Testing on Gaussian Markov Random Fields\nTo ensure that our algorithm works properly, we can test it on data samples from distributions with known MI values. The most convenient class of distribution for this purpose is the Gaussian Markov random field, which is a multivariate Gaussian distribution parameterized by its precision matrix. The precision matrix is simply the inverse of the covariance matrix, and its off-diagonal elements determine the conditional correlation between the corresponding Gaussian variables. The following code shows functions which generate the precision matrix for three different MI patterns:\nimport numpy as np\n\ndef get_area_law_prec(length, rho):\n    q = np.eye(length**2)\n    for i in range(length):\n        for j in range(length):\n            q_row = i * length + j\n            for (m, l) in [(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1)]:\n                if (m &lt; length and m &gt;= 0) and (l &lt; length and l &gt;= 0):\n                    q_col = m * length + l\n                    q[q_row, q_col] = rho\n    return q\n\ndef get_diffuse_volume_prec(length, rho):\n    q = np.full([length**2, length**2], rho)\n    for i in range(length**2):\n        q[i, i] = 1\n    return q\n\ndef get_sparse_volume_prec(length, rho):\n    gen = np.random.RandomState(123456789)\n    q = np.eye(length**2)\n    for i in range(length):\n        for j in range(length):\n            q_row = i * length + j\n            for (m, l) in [(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1)]:\n                if (m &lt; length and m &gt;= 0) and (l &lt; length and l &gt;= 0):\n                    q_col = m * length + l\n                    q[q_row, q_col] = rho\n    shuffle = gen.permutation(length**2)\n    q = q[shuffle, :]\n    q = q[:, shuffle]\n    return q\nThe get_area_law_prec function creates a precision matrix in which variables are conditionally correlated with only their four nearest neighbors when arranged on a 2D grid. The get_diffuse_volume_prec function, by contrast, constructs a precision matrix in which every variable is equally correlated with every other variable, regardless of their positions on the grid. Finally, the get_sparse_volume_prec creates a precision matrix that is a mix of the other two, in that it starts out by generating nearest-neighbor correlations but then randomizes the position of the variables on the grid. This results in each variable being correlated with four other variables at random locations on the grid.\nUsing samples from these Gaussian distributions (we can set the means arbitrarily to zero, since it does not affect the MI value), we can now train our neural network classifier. Because we are interested in capturing the MI structures of the different distributions, we will use a fully-connected neural network rather than, say, a convolutional network to avoid introducing spatial biases into the model. The code used to build the model is given below:\nimport ast\n\nfrom tensorflow import keras as ks\n\nclass Model():\n    def __init__(self, image_shape, settings):\n        self.drop = float(settings['drop'])\n        self.learn_rate = float(settings['learn'])\n        self.layers = ast.literal_eval(settings['layers'])\n        self.build_model(image_shape)\n\n    def build_model(self, image_shape):\n        joint_input = ks.Input(shape = image_shape)\n        marginal_input = ks.Input(shape = image_shape)\n        model_core = ks.models.Sequential()\n        model_core.add(ks.layers.Flatten(input_shape = image_shape))\n        for layer_size in self.layers:\n            model_core.add(ks.layers.Dense(layer_size, activation = 'relu'))\n            model_core.add(ks.layers.Dropout(self.drop))\n        model_core.add(ks.layers.Dense(1, activation = None))\n        joint_output = model_core(joint_input)\n        marginal_output = model_core(marginal_input)\n        self.model = ks.Model(inputs = [joint_input, marginal_input], outputs = [joint_output, marginal_output])\nThe model structure is fairly standard, with the exception of the inputs and outputs being split based on the kind of image being fed in. This has been done simply to make the model easier to work with when doing MI estimation, and is not necessary.\nThe following code trains the model on samples from the specified Gaussian Markov random field. The size of the “image” (i.e. the grid of variables) is set to 28 x 28, which matches the size of the real image datasets that we will be working with later on. The samples are separated into two regions, a square set of variables in the middle of the grid and the remaining set of pixels surrounding it. The collective states of these two pixel patches represent the variables \\(a\\) and \\(b\\) whose correlation we will be aiming to estimate.\nimport itertools\n\nimport numpy as np\n\nfrom src import mine, image as img\n\nimage_type = \"diffuse\" # Set to \"area\". \"diffuse\", or \"sparse\".\nstrength = \"large\" # Set to \"small\" or \"large\"\nnum_images = 700000\ninner_length = 10\nbatch_size = 64\nmax_epochs = 100\nmodel_settings = dict(\n    drop = 0, \n    learn = 1e-4, \n    layers = \"[256, 256]\", \n    patience = 20, \n    optm = \"rms\")\n\nrho = img.rho_values[image_type][strength]\nprint(f\"Sampling {num_images} images...\")\n(images, _, _) = img.get_images(image_type, num_images, strength)\n(_, height, width) = images.shape\nimages = np.expand_dims(images, axis = 3)\ninner_region = img.get_center_region(inner_length, height, width)\n\nmodel = mine.LogsiticRegression(images.shape[1:], model_settings)\n\nval_start = int(images.shape[0] * float(1 / 7))\ntrain_images = images[val_start:]\nval_images = images[:val_start]\n\ntrain_steps = np.ceil(train_images.shape[0] / batch_size)\nval_steps = np.ceil(val_images.shape[0] / batch_size)\n\ntrain_itr = mine.get_finite_dataset(train_images, inner_region, batch_size, loop = True)\nval_itr = itertools.cycle(mine.get_finite_dataset(val_images, inner_region, batch_size, loop = False))\n\nprint(\"Training model...\")\nmodel.train(train_itr, val_itr, train_steps, val_steps, max_epochs)\nAfter the model has been trained, it can evaluate the MI of a dataset using two different equations. In direct estimation, we compute the average log-ratio of \\(p(a, b)\\) and \\(p(a)p(b)\\) to get the MI. In indirect estimation, we compute this same log-ratio but then subtract a quantity that should be zero if the MI estimate is exact, but will otherwise cancel some of the error in the direct estimate. Either approach may be preferred depending on the nature of the target dataset. The following method function of the Model class uses the trained model to compute both MI estimates:\nimport numpy as np\n\ndef evaluate_MI(self, image_iterator, num_steps):\n    cum_joint = 0\n    cum_marginal = 0\n    for (count, (image_batch, _)) in enumerate(image_iterator):\n        [joint_outputs, marginal_outputs] = self.model.predict_on_batch(image_batch)\n        cum_joint += np.mean(joint_outputs)\n        cum_marginal += np.mean(np.exp(marginal_outputs))\n        if count &gt;= num_steps:\n            break\n    indirect_mi = cum_joint / num_steps - np.log(cum_marginal / num_steps)\n    direct_mi = cum_joint / num_steps\n    return (indirect_mi, direct_mi)\nWhen the models are trained on center patches of different lengths, their estimates can be combined together to show how the MI scales with the size of the patch. By averaging over a sufficient number of models, we can generate the following plots:\n\n\n\nNearest-neighbor correlations\n\n\n\n\n\nUniform correlations\n\n\n\n\n\nRandomized correlations\n\n\nwith the three rows corresponding to get_area_law_prec, get_diffuse_volume_prec, and get_sparse_volume_prec respectively, while the two columns correspond to small and large correlation strengths respectively. We can see that each of the three forms for the precision matrix gives rise to a different pattern of MI scaling, and that the model estimates are able to closely match the exact MI in most cases, especially when the training set is large."
  },
  {
    "objectID": "projects/phd/mi-scaling/mi-scaling.html#mi-scaling-of-mnist-and-tiny-images",
    "href": "projects/phd/mi-scaling/mi-scaling.html#mi-scaling-of-mnist-and-tiny-images",
    "title": "Quantifying Mutual Information via Logistic Regression",
    "section": "MI Scaling of MNIST and Tiny Images",
    "text": "MI Scaling of MNIST and Tiny Images\nNow that we have verified that the model is able to perform accurate MI estimation, we can carry out experiments on real image datasets. The two datasets we will focus on are MNIST and Tiny Images, with MNIST having simple images of digits and the Tiny Images set having much more complicated images scraped from the internet. Example images from each dataset are shown below:\n\n\n\nSample images from Tiny Images (left) and MNIST (right).\n\n\nNote that the Tiny Images have been cropped from \\(32 \\times 32\\) to \\(28 \\times 28\\), and converted to grayscales using the following weighted luminance coding:\ndef convert_to_grayscale(images):\n    (r, g, b) = (0.3, 0.59, 0.11)\n    grayscale = r * images[..., 0] + g * images[..., 1] + b * images[..., 2]\n    return grayscale\nThe neural network model introduced in the previous section can be trained on MNIST and the Tiny Images datasets in precisely the same manner as it was for the Gaussian Markov random fields. As an example, the following code block trains a model for MI estimation on MNIST:\nimport itertools\n\nimport numpy as np\n\nfrom src import mine, image as img\n\nnum_images = 70000\ninner_length = 10\nbatch_size = 64\nmax_epochs = 100\nmodel_settings = dict(\n    drop = 0, \n    learn = 1e-4, \n    layers = \"[256, 256]\", \n    patience = 20, \n    optm = \"rms\")\n\n(images, _, _) = img.get_images(\"mnist\", num_images, strength)\n(_, height, width) = images.shape\nimages = np.expand_dims(images, axis = 3)\ninner_region = img.get_center_region(inner_length, height, width)\n\nmodel = mine.LogsiticRegression(images.shape[1:], model_settings)\n\nval_start = int(images.shape[0] * float(1 / 7))\ntrain_images = images[val_start:]\nval_images = images[:val_start]\n\ntrain_steps = np.ceil(train_images.shape[0] / batch_size)\nval_steps = np.ceil(val_images.shape[0] / batch_size)\n\ntrain_itr = mine.get_finite_dataset(train_images, inner_region, batch_size, loop = True)\nval_itr = itertools.cycle(mine.get_finite_dataset(val_images, inner_region, batch_size, loop = False))\n\nmodel.train(train_itr, val_itr, train_steps, val_steps, max_epochs)\nmodel.evaluate_MI(val_itr, 5000)\nAs with the Gaussian distributions in the previous section, we can compute MI estimates for pixel patches of different sizes and plot how the MI changes. By averaging over many such models, we generate the following plot which shows the MI scaling behavior for both MNIST and the Tiny Images datasets.:\n\n\n\nMI scaling for MNIST and Tiny Images\n\n\nThe difference in scaling behavior between the two datasets is stark, with the Tiny Images dataset showing a fairly linear pattern that is very reminiscent of the nearest-neighbor Gaussian Markov random field. This would suggest that local correlations are more dominant in the Tiny Images than in MNIST."
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html",
    "title": "Tetris Emulation with OpenGL",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html#overview",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html#overview",
    "title": "Tetris Emulation with OpenGL",
    "section": "Overview",
    "text": "Overview\nThis project seeks to emulate the version of Tetris played on the Nintendo Entertainment System (NES). Released in 1989, NES Tetris was one of the first mass-market editions of the game, and helped to greatly expand its popularity. While a more standardized set of rules now exists for modern Tetris releases, earlier versions were given a large amount of freedom in how they implemented many aspects of the game, from overall piece speed and drop mechanics to the randomization and scoring algorithms. My goal here is to recreate all of these details in an application that can run on a desktop computer.\n\n\n\nScreenshot of the emulator in action.\n\n\nThe program can be compiled on Linux (tested specifically on Ubuntu 18.04) by following the instructions on the project’s GitHub page. The only external dependency is GLFW, an open-source library that interfaces with OpenGL and handles user inputs. The following sections provide a broad outline of the emulator’s underlying code, which is written in C++ and uses OpenGL to render graphics. The source code itself is also heavily commented, and comprehensively explains the emulator’s finer details."
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html#general-structure-and-game-loop",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html#general-structure-and-game-loop",
    "title": "Tetris Emulation with OpenGL",
    "section": "General Structure and Game Loop",
    "text": "General Structure and Game Loop\nThe emulator’s source files (in the src directory) are broadly divided into code that runs the game logic (in the game subdirectory) and code that generates the game’s graphics (in the graphics subdirectory). The third subdirectory glad contains a single file glad.c that was generated using the glad OpenGL loading library, and is used to find the correct OpenGL functions at runtime.\nThe emulator is initialized by the main function in main.cpp, which performs the following setup operations:\n\nCreate the game window and its associated OpenGL context.\nParse user-provided information about the game mode, starting level, and asset directory.\nInitialize handlers for user inputs and graphics rendering.\nCreate a new game object and connects it to the handlers.\n\nThe code for these three steps is given below (the handlers will be discussed in more detail later):\n// 1. Create the game window and assign to it an OpenGL context loaded by GLEW\nint windowHeight = 899, windowWidth = 1035;\nGLFWwindow* window = glfwCreateWindow(windowWidth, windowHeight, \"Tetris\", nullptr, nullptr);\nglfwMakeContextCurrent(window);\ngladLoadGL();\n\n// 2. Extract image/shader parent directory, game type, and level from command line\nconst std::string drawingLocation = argv[1];\nconst std::string mode = (argc &gt; 2) ? argv[2] : std::string(\"nes\");\nconst int startLevel = (argc &gt; 3) ? std::stoi(argv[3]) : 0;\n\n// 3. Create the keyboard/mouse input handler and the OpenGL drawer\nInputHandler inputs{window};\nBoardDrawer drawer{drawingLocation}\n\n// 4. Create game object and assign variables to graphics handler\nNESTetris game{startLevel};\ngame.assignInput(inputs);\ndrawer.assignGrid(game.displayGrid);\ndrawer.assignLevel(game.dynamic[\"level\"]);\ndrawer.assignLineCount(game.board.lineCount);\ndrawer.assignlineTypeCount(game.board.lineTypeCount);\ndrawer.assignNextPiece(game.nextPiece);\ndrawer.assignScore(game.dynamic[\"score\"]);;\nAfter completing these initialization steps, the main function then begins to execute the game loop, which processes each frame. The loop is divided into two stages, one which handles the game logic and another that handles graphics:\ndouble engTime = 0;\ndouble rendTime = 0;\nconst double engSecs = 1 / 60.1; // Recipricol of FPS\nconst double rendSecs = 1 / 60.1; // Recipricol of FPS\n\n// Run the main game loop, with game frames run and drawn seperately\nwhile (!glfwWindowShouldClose(window)) {\n    double newTime = glfwGetTime();\n    if (newTime - engTime &gt;= engSecs) {\n        game.runFrame();\n        engTime = newTime;  \n    }\n    if (newTime - rendTime &gt;= rendSecs) {\n        drawer.drawFrame();\n        glfwSwapBuffers(window);\n        rendTime = newTime;\n    }\n    glfwPollEvents();\n}\nThe three key functions in the loop are game.runFrame, drawer.drawFrame, and glfwPollEvents. The first two function calls have many effects that will be examined in subsequent sections, but glfwPollEvents simply processes GLFW events that are in the queue, such as user inputs. This function is executed as frequently as possible to minimize input lag, while the game.runFrame and drawer.drawFrame functions are called with specific frequencies based on the desired frame and refresh rates."
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html#running-a-frame",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html#running-a-frame",
    "title": "Tetris Emulation with OpenGL",
    "section": "Running a Frame",
    "text": "Running a Frame\nThe NES console runs at 60.1 frames per second (FPS), which means that the game logic is executed approximately once every 17 milliseconds. In the emulator, each frame is marked by a call to game.runFrame, which is a method of the master game object that holds all methods, attributes, and sub-objects related to gameplay. The game.runFrame method is itself a fairly simple function, tasked with deciding how the frame should be processed:\nvoid NESTetris::runFrame()\n{\n    setCommands();\n    if (commands[\"reset\"]) {\n        resetGame();\n    }\n    if (flags[\"frozen\"] == true) {\n        runFrozenFrame(); // Run during the entry delay\n    }\n    else {\n        if (!filledRows.empty()) {\n            runClearFrame(); // Run during line clears\n        }\n        else {\n            runActiveFrame(); // Run during regular play\n        }\n    }\n    resetBool(commands);\n    ++ dynamic[\"totalFrames\"];\n}\nThe “frozen” and “clear” frames are both fairly similar in that they halt play when executed, which slows down the game and offers some respite for the player. An “active” frame is the type of frame that is run during normal gameplay, and consists of the following operations:\n\nProcess commands from the input handler.\nApply gravity to the current piece.\nCheck if the piece has landed and if any rows have been filled.\n\nThe first operation is done via the setCommands function, which takes key presses logged by the input handler and translates them into game actions. A portion of the setCommands is reproduced below, focusing on horizontal movement of the current Tetris piece:\n    // Left key:\n    if (keyMap[\"left\"] == \"pressed\" && keyMap[\"right\"] == \"off\") {\n        commands[\"doLeft\"] = true;\n    }\n    if (keyMap[\"left\"] == \"held\") {\n        commands[\"leftDAS\"] = true;\n        }  \n\n    // Right key:\n    if (keyMap[\"right\"] == \"pressed\" && keyMap[\"left\"] == \"off\") {\n        commands[\"doRight\"] = true;\n    }\n    if (keyMap[\"right\"] == \"held\") {\n        commands[\"rightDAS\"] = true;\n    }\nAs can be seen from the if statements, the mapping between a key press and a command can vary based on the present and past state of other keys. Once the commands are processed, the emulator then checks to see if the piece needs to be shifted downward by gravity. The following code excerpt shows the logic which implements this process:\nif (!flags[\"dropDelay\"] && dynamic[\"dropFrames\"] &gt;= dynamic[\"gravity\"]) {\n        dynamic[\"dropFrames\"] = 0;\n        currPiece-&gt;translate(-1, 0);\n    }    \n    else {\n        ++ dynamic[\"dropFrames\"];\n        displayPiece();\n    }\nThe emulator counts the number of frames that have occurred since gravity was last applied, and compares this to the target rate (which depends on the game level). If the specified number of frames have elapsed, then the piece coordinates are all translated one unit downward. Otherwise, the frame counter is incremented and will be checked again on the next active frame.\nAs its final step, an active frame will check whether the current piece has collided with an existing piece and/or the bottom of the playfield. This is done by querying the game’s grid object (which stores the location of all existing pieces) using the coordinates of the current piece. If a collision is detected, then the last downward shift is reversed and the emulator checks whether any rows are filled. This is all handled in the following code block:\nif (board.grid.collisionCheck(currPiece-&gt;coords)) {\n    ++ dynamic[\"move\"];\n    currPiece-&gt;translate(1, 0);\n    setEntryDelay();\n    displayPiece();\n    filledRows = displayGrid.getFilledRows();\n    board.placePiece(*currPiece);\n    if (!filledRows.empty()) {\n        updateScore();\n        checkLevel();\n    }    \n    else{\n        flags[\"frozen\"] = true;\n    }\n}\nIf at least one row has been filled, then those blocks will be cleared in subsequent frames. If not, a set of “frozen” frames will be run in order to delay the arrival of a new piece and give the player time to reorient themselves."
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html#displaying-the-game",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html#displaying-the-game",
    "title": "Tetris Emulation with OpenGL",
    "section": "Displaying the Game",
    "text": "Displaying the Game\nThe graphical portion of the emulator is handled by the drawer object, whose drawFrame method is called in the game loop during each rendering cycle. This function performs the following tasks:\n\nDraw the pieces that have been placed in the playfield.\nDisplay a preview of the piece that will appear after the current one is placed.\nWrite text that gives the total line count and the number of different line clears.\nWrite text showing the score and current level.\n\nThese operations prepare the new display configuration in a buffer, which is then applied to the emulator window by calling the glfwSwapBuffers function at the end of each rendering cycle.\nTo draw the Tetris pieces, the emulator extracts the coordinates and color of each block from its underlying grid object and then draws them:\nvoid BoardDrawer::drawPieceBlocks() {\n    for (auto& rowColIndex : gridSource-&gt;getFilledBlocks()) {\n        int row = rowColIndex[0];\n        int col = rowColIndex[1];\n        int index = rowColIndex[2];\n        int texture = blockTextures[pieceTexMap[index]];\n        const double x0 = playFieldPos[0] + col*blockWidthSpacing;\n        const double x1 = playFieldPos[0] + (col + 1)*blockWidthSpacing;\n        const double y0 = playFieldPos[5] - row*blockHeightSpacing;\n        const double y1 = playFieldPos[5] - (row + 1)*blockHeightSpacing;\n        std::vector&lt;double&gt; vertices = {\n        x0, y1,      0, 1,\n        x1, y1,      1, 1,\n        x0, y0,      0, 0,\n        x1, y0,      1, 0};\n        drawSquare(vertices, texture);\n    }\n}\nThe blockWidthSpacing and blockHeightSpacing attributes of the drawer object are computed based on the size of the emulator window, and serve to transform the grid coordinates to pixel coordinates. These new coordinates are then passed to the drawSquare function, which ultimately sends them to an OpenGL shader for rendering. A similar process is used to generate the piece preview, except that those blocks are drawn in their own separate portion of the emulator window.\nFor generating text, the emulator uses characters defined by a bitmap stored in the assets folder (which also holds textures for the piece blocks and playfield background). When the emulator needs to render a specific character, it looks up the corresponding pixel coordinates in the bitmap image file and then passes that segment to the shader. The most complicated part of this process is positioning each character in the target string, which is done by the following method:\nstd::vector&lt;std::vector&lt;double&gt;&gt; TextDrawer::getTextVertices(\n    std::string text, double x0, double x1, double y0, double y1)\n{\n    // Get horizontal and vertical spacing\n    double horiz_spacing = (x1 - x0) / text.length();\n    // 106/94 is the aspect ratio of the font\n    double vert_spacing = horiz_spacing*(94.0/106.0);\n    // Text is vertically centered in the rectangle \n    double vert_offset = (y1 - y0 - vert_spacing); \n    double y0char = y0 + 0.5*vert_offset;\n    double y1char = y1 - 0.5*vert_offset;\n\n    // Iterate through each character and generate the four vertices to use when drawing\n    double charCount = 0;\n    std::vector&lt;std::vector&lt;double&gt;&gt; textVertices;\n    for (auto& c : text) {\n        // The x-coordinates of each character are generated from the horizontal spacing\n        double x0Char = x0 + horiz_spacing*charCount;\n        double x1Char = x0Char + horiz_spacing;\n        // Get relative texture coordinate by dividing by total bitmap width\n        double x0Tex = charTexCoords[c][0] / 4066.0; \n        double x1Tex = charTexCoords[c][1] / 4066.0;\n        // The text is drawn in a line, so the y-coordinate is uniform across all characters\n        std::vector&lt;double&gt; charVertices{\n            x0Char, y1char,  x0Tex, 0,\n            x1Char, y1char,  x1Tex, 0,\n            x0Char, y0char,  x0Tex, 1,\n            x1Char, y0char,  x1Tex, 1};\n        textVertices.push_back(charVertices);\n        ++charCount;\n    }\n    return textVertices;\n}\nThis function takes a string of text and a set of coordinates marking the four corners of a rectangle and determines the amount of space that can be allotted to each character. The basic approach is to divide the horizontal length by the number of characters to get the width-per-character, then multiply this spacing by the height/width ratio of the font to get the vertical spacing. The text is then iterated through and each character is assigned its position and texture coordinates.\nUsing the getTextVertices method, the process for writing text is fairly consistent. First, a string is generated that contains the desired text. Then, this string and the coordinates describing its intended position are passed to getTextVertices, which returns the character-level coordinates. Finally, each of the characters is individually passed to the OpenGL shader via drawSquare. The following example shows the code used to generate text for the total number of lines cleared:\nvoid BoardDrawer::drawLineCount()\n{\n    if (lineCountSource) {\n        int x0 = 408, x1 = 695;\n        int y0 = 64, y1 = 95;\n        std::string lineCountRaw = std::to_string(*lineCountSource);\n        std::string lineCountStr = std::string(\"lines-\") + \n            (lineCountRaw.size() &lt; 3 ? \n                std::string(3 - lineCountRaw.size(), '0') + lineCountRaw \n                : lineCountRaw);\n        auto textVertices = textDrawer.getTextVertices(lineCountStr, x0, x1, y0, y1);\n        for (auto& charVertices : textVertices) {\n            drawSquare(charVertices, fontTexture);\n        }\n    }\n}\nThe desired string, which always has the form “Line-XXX”, is constructed using a pointer to the game object’s line count variable. The output coordinates are based on the layout of the playfield, and therefore do not change."
  },
  {
    "objectID": "projects/tetris/tetris-emulator/tetris-emulator.html#handling-inputs",
    "href": "projects/tetris/tetris-emulator/tetris-emulator.html#handling-inputs",
    "title": "Tetris Emulation with OpenGL",
    "section": "Handling Inputs",
    "text": "Handling Inputs\nIn order for someone to actually play a game of Tetris using the emulator, it must have a way of detecting user inputs. This is provided by the InputHandler object, which interfaces with the GLFW library to detect specific events like a mouse click or key press. The handler first converts the GLFW event variable into a string which describes the source of the input event, and then determines whether the event was newly-triggered or instead “held” (i.e. had already been triggered in the previous event poll). This logic is all handled in the getStates method of the InputHandler class:\nstd::map&lt;const std::string, std::string&gt; InputHandler::getStates(\n    std::vector&lt;std::string&gt; keyNames) \n{\n    std::map&lt;const std::string, std::string&gt; states;\n    for (auto keyName : keyNames) {\n        auto keyIntItr = keyToInt.find(keyName);\n        std::string state; \n        if (keyIntItr != keyToInt.end()) { // Only proceed if key name is valid\n            int key = keyIntItr-&gt;second;\n            if (actionMap[key] == GLFW_RELEASE) {\n                prevQueried[key] = false;\n                state = \"off\";\n            }\n            else if (actionMap[key] != GLFW_RELEASE) { // True for GLFW_PRESS / GLFW_REPEAT\n                if (!prevQueried[key]) {\n                    prevQueried[key] = true;\n                    state = \"pressed\";\n                }\n                else if (prevQueried[key]) {\n                    state = \"held\";\n                }\n            }\n        }\n        else { // If no matching key is found, return empty string to indicate failure\n            state =  \"\";\n        }\n        states[keyName] = state;\n    }\n    return states;\n}\nThis function returns the state of the desired keys, which is “off” if the key is not pressed, “pressed” if the key has just been pressed, or “held” if the key is held down. In order to make this feedback instantaneous, the input handler records whether it has been previously queried about a particular key while that key is being pressed (i.e. while GLFW has registered a press but not yet a release). If the key had previously been queried, the function returns the state “held” rather than “pressed”. After the event states have been resolved, they can be used to configure commands that will be executed when a frame is processed."
  },
  {
    "objectID": "projects/tetris/tetris-sql/tetris-sql.html",
    "href": "projects/tetris/tetris-sql/tetris-sql.html",
    "title": "PostgreTETRIS: Tetris in SQL",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/tetris/tetris-sql/tetris-sql.html#overview",
    "href": "projects/tetris/tetris-sql/tetris-sql.html#overview",
    "title": "PostgreTETRIS: Tetris in SQL",
    "section": "Overview",
    "text": "Overview\nThis project implements a form of Tetris that can be played within a PostgreSQL database, using code written in the PL/pgSQL scripting language. The object definitions are all contained in the tetris.sql file, which can be executed by running \\i tetris.sql in psql after connecting to an empty database.\n\n\n\nTetris played in psql, with revolutionary graphics. The diagrams at the bottom show possible orientations for the next piece.\n\n\nOnce the script has been run, the reset procedure must be called in order to prepare the components and print the blank playfield. To place a piece, you insert a (pos, orient) tuple into the moves table using CALL place(pos, orient), where “pos” is an integer from 1 to 10 that marks the leftmost column to place the piece, and “orient” is an integer that determines how the piece is rotated.\nThe following sections provide an exhaustive description of the tables, views, functions, and procedures used by the application."
  },
  {
    "objectID": "projects/tetris/tetris-sql/tetris-sql.html#table-structure",
    "href": "projects/tetris/tetris-sql/tetris-sql.html#table-structure",
    "title": "PostgreTETRIS: Tetris in SQL",
    "section": "Table structure",
    "text": "Table structure\nThe data needed for the Tetris application to function is stored in five tables: moves, lines, piece_log, board, and pieces. The table creation statements for the first four tables are given below:\nCREATE TABLE IF NOT EXISTS moves (\n    pos INT,\n    orient INT\n);\n\nCREATE TABLE IF NOT EXISTS lines (\n    num_lines INT,\n    num_cleared INT\n);\n\nCREATE TABLE IF NOT EXISTS piece_log (piece_name)\n    AS SELECT 'blank';\n    \nCREATE TABLE IF NOT EXISTS board (\n    height INT,\n    width INT,\n    state BOOL DEFAULT 'false'\n);\nThe moves table is the only one that the player interacts with directly, and has a column for the position of the Tetris piece (measured from its leftmost block) and its orientation. These are the two pieces of information that the player must provide to make a move, a process which is described in more detail later. The lines table is used to keep track of the number (column num_cleared) and type (column num_lines) of each line clear that occurs, and serves as the effective scoreboard of the game. The piece_log is used to keep track of the current piece, and only ever contains a single value. Finally, the highly dynamic board table keeps track of where pieces are placed, and lies at the heart of the application. Each row in the table corresponds to a specific tile in the 20x10 playfield, with the height and width columns defining its exact position. The state boolean column stores whether the tile is currently occupied by a piece block, and thus plays a key role in determining where the player can drop pieces and which lines need to be cleared. Upon calling the reset procedure (described later), the board table is populated using the following INSERT statement:\nINSERT INTO board (height, width) \n    SELECT * \n    FROM generate_series(1, 20) t1 \n        CROSS JOIN generate_series(1, 10) t2;\nwhich generates all 200 rows with a default state of false, indicating that the associated tile is unoccupied. The placement of a piece is performed by simply setting the state of the affected rows to true.\nThe last table to discuss is the pieces table, which is unique in that it is not altered in any manner after creation. This is because it holds immutable information about the seven Tetris pieces, laid down when Tetris was first invented in the eighties. The code to create the pieces table and define its contents is given below:\nCREATE TABLE IF NOT EXISTS pieces (\n    name, orient, b1, b2, b3, b4, \n        prev1, prev2, prev3, prev4)\nAS VALUES\n    ('sq', 1, ARRAY [0,0], ARRAY [0,1], ARRAY [1,0], ARRAY [1,1], \n         'X X', 'X X', '   ', '   '),\n    ('i', 1, ARRAY [0,0], ARRAY [0,1], ARRAY [0,2], ARRAY [0,3], \n         'X X X X', '       ', '       ', '       '),\n    ('i', 2, ARRAY [-1,0], ARRAY [0,0], ARRAY [1,0], ARRAY [2,0], \n         'X', 'X', 'X', 'X'),\n    ('t', 1, ARRAY [0,0], ARRAY [0,1], ARRAY [1,1], ARRAY [0,2], \n         'X X X', '  X  ', '     ', '     '),\n    ('t', 2, ARRAY [0,0], ARRAY [0,1], ARRAY [1,1], ARRAY [-1,1], \n         '  X', 'X X', '  X', '   '),\n    ('t', 3, ARRAY [0,0], ARRAY [0,1], ARRAY [-1,1], ARRAY [0,2], \n         '  X  ', 'X X X', '     ', '     '),\n    ('t', 4, ARRAY [0,0], ARRAY [0,1], ARRAY [-1,0], ARRAY [1,0], \n         'X  ', 'X X', 'X  ', '   '),\n    ('zr', 1, ARRAY [1,0], ARRAY [1,1], ARRAY [0,1], ARRAY [0,2], \n         '  X X', 'X X  ', '     ', '     '),\n    ('zr', 2, ARRAY [0,0], ARRAY [-1,0], ARRAY [0,1], ARRAY [1,1], \n         'X  ', 'X X', '  X', '   '),\n    ('zl', 1, ARRAY [0,0], ARRAY [0,1], ARRAY [1,1], ARRAY [1,2], \n         'X X  ', '  X X', '     ', '     '),\n    ('zl', 2, ARRAY [0,0], ARRAY [1,0], ARRAY [0,1], ARRAY [-1,1], \n         '  X', 'X X', 'X  ', '   '),\n    ('lr', 1, ARRAY [0,0], ARRAY [1,0], ARRAY [0,1], ARRAY [0,2], \n         'X X X', 'X    ', '     ', '     '),\n    ('lr', 2, ARRAY [0,1], ARRAY [-1,1], ARRAY [-1,0], ARRAY [1,1], \n         'X X', '  X', '  X', '   '),\n    ('lr', 3, ARRAY [0,0], ARRAY [0,1], ARRAY [0,2], ARRAY [-1,2], \n         '    X', 'X X X',  '     ', '     '),\n    ('lr', 4, ARRAY [0,0], ARRAY [-1,0], ARRAY [1,0], ARRAY [1,1], \n         'X  ', 'X  ', 'X X', '   '),\n    ('ll', 1, ARRAY [0,0], ARRAY [0,1], ARRAY [0,2], ARRAY [1,2], \n         'X X X', '    X', '     ', '     '),\n    ('ll', 2, ARRAY [1,0], ARRAY [1,1], ARRAY [0,1], ARRAY [-1,1], \n         '  X', '  X', 'X X', '   '),\n    ('ll', 3, ARRAY [0,0], ARRAY [-1,0], ARRAY [0,1], ARRAY [0,2], \n         'X    ', 'X X X', '     ', '     '),\n    ('ll', 4, ARRAY [0,0], ARRAY [-1,0], ARRAY [-1,1], ARRAY [1,0], \n         'X X', 'X  ', 'X  ', '   ');   \nEach row in the table describes a specific piece (given by the name column) in a specific orientation (given by the orient column), with information about the relative positions of the four blocks (columns b1, b2, b3. and b4) and the text strings needed to properly illustrate the pieces (columns prev1, prev2, prev3, and prev4, to be discussed more later). The block positions are each provided as a two-element integer array, with the first integer giving its relative height and the second giving its relative width. These values are taken relative to the block assigned [0, 0], which is always in the leftmost position (although at varying heights). Because of the way the board is configured, a smaller height value actually indicates a piece that is further up the playfield (i.e. closer to the top from the perspective of the player), with pieces appearing initially at a height of 1 and then falling into place at some larger value (maximum of 20)."
  },
  {
    "objectID": "projects/tetris/tetris-sql/tetris-sql.html#starting-a-game",
    "href": "projects/tetris/tetris-sql/tetris-sql.html#starting-a-game",
    "title": "PostgreTETRIS: Tetris in SQL",
    "section": "Starting a game",
    "text": "Starting a game\nTo start a new game of Tetris, the move list and line counts must be reset, and all pieces from the previous game must be cleared from the playfield. This is done using the reset procedure (CALL reset();), which is defined below:\nCREATE OR REPLACE PROCEDURE reset()\nLANGUAGE plpgsql\nAS $$\n    DECLARE\n        col_index INT;\n        row_index INT;\n    BEGIN\n        TRUNCATE TABLE moves;\n        TRUNCATE TABLE board;\n        TRUNCATE TABLE lines;\n        INSERT INTO lines(num_lines, num_cleared) \n            VALUES (1, 0), (2, 0), (3, 0), (4, 0);\n        INSERT INTO board (height, width) \n            SELECT * \n            FROM generate_series(1, 20) t1 \n                CROSS JOIN generate_series(1, 10) t2;\n        PERFORM prepare_next()\n        COMMIT;\n    END;\n$$;\nThe procedure begins by truncating the moves, board, and lines tables, and then inserting the appropriate starting values for the latter two tables. With tables now in a fresh state, a final function prepare_next is called which draws a random first piece and prepares the “graphical” interface for the player to use. The code for this function is given below:\nCREATE OR REPLACE FUNCTION prepare_next()\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        piece_txt TEXT;\n    BEGIN\n        PERFORM print_board();\n        PERFORM print_clears();\n        RAISE NOTICE ' ';\n        piece_txt = get_piece();\n        PERFORM print_piece(piece_txt);\n        UPDATE piece_log SET piece_name = piece_txt;\n    END;\n$$;\nWe can see that prepare_next first calls a pair of functions that print the current state of the playfield (empty at this point) and the number of line clears (all zero). The code for these functions is given below:\nCREATE OR REPLACE FUNCTION print_board()\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        row_itr RECORD;\n    BEGIN\n        FOR row_itr IN \n            SELECT * FROM readable\n        LOOP\n            RAISE NOTICE '| % | % | % | % | % | % | % | % | % | % |', \n                row_itr.c1, row_itr.c2, row_itr.c3, row_itr.c4, row_itr.c5,\n                row_itr.c6, row_itr.c7, row_itr.c8, row_itr.c9, row_itr.c10;\n        END LOOP;\n        RAISE NOTICE '  1   2   3   4   5   6   7   8   9   10'; \n    END;\n$$;\n\nCREATE OR REPLACE FUNCTION print_clears()\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        lines INT[];\n    BEGIN\n        lines = array(SELECT num_cleared FROM lines ORDER BY num_lines);\n        RAISE NOTICE 'Single: %  Double: %  Triple: %  Tetris: %',\n            lines[1], lines[2], lines[3], lines[4];\n    END;\n$$;\nAs can be seen, the graphical display is produced by raising notices with appropriately-formatted strings. Since the board table is not structured to be especially readable, we instead employ a view called readable that constructs a pivot table whose columns are the columns of the playfield:\nCREATE EXTENSION IF NOT EXISTS tablefunc;\n\nCREATE OR REPLACE VIEW readable AS\n    SELECT * FROM crosstab(\n        'SELECT height, width, CASE WHEN state THEN ''X'' ELSE '' '' END AS val \n            FROM board ORDER BY 1,2') \n        AS t (height INT, c1 TEXT, c2 TEXT, c3 TEXT, c4 TEXT, c5 TEXT, \n              c6 TEXT, c7 TEXT, c8 TEXT, c9 TEXT, c10 TEXT);\nOnce the board table is repackaged in this more intuitive format, it can be easily displayed to the player by simply raising a notice for each row. Since the crosstab function is not available by default, we must import the tablefunc extension.\nLooking back at the second half of the prepare_next function, we can see that it next calls the get_piece function, which returns a random piece name that will serve as the next piece to be placed. The code for this function is given below:\nCREATE OR REPLACE FUNCTION get_piece()\n    RETURNS TEXT\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        piece TEXT;\n    BEGIN\n        SELECT CASE\n            WHEN val BETWEEN 0 AND 1 THEN 'sq'\n            WHEN val BETWEEN 1 AND 2 THEN 'i'\n            WHEN val BETWEEN 2 AND 3 THEN 't'\n            WHEN val BETWEEN 3 AND 4 THEN 'zl'\n            WHEN val BETWEEN 4 AND 5 THEN 'zr'\n            WHEN val BETWEEN 5 AND 6 THEN 'll'\n            ELSE 'lr' END\n        INTO piece\n        FROM (VALUES (random() * 7)) AS t (val);\n        RETURN piece;\n    END;\n$$;\nWhile a bit verbose, this function operates in a simple manner by first sampling a random number uniformly between 0 and 7, and then returning a piece name based on which two integers it lies most tightly between. Once the piece has been selected, prepare_next stores its name in the piece_log table (which is the table’s only purpose) and then displays its shape to the player by calling the print_piece function. The code for this function is given below:\nCREATE OR REPLACE FUNCTION print_piece(piece_name TEXT)\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        piece_text1 RECORD;\n        piece_text2 RECORD;\n        piece_text3 RECORD;\n        piece_text4 RECORD;\n    BEGIN\n        SELECT prev1, prev2, prev3, prev4 INTO piece_text1 FROM pieces \n            WHERE name = piece_name AND orient = 1;\n        SELECT prev1, prev2, prev3, prev4 INTO piece_text2 FROM pieces \n            WHERE name = piece_name AND orient = 2;\n        SELECT prev1, prev2, prev3, prev4 INTO piece_text3 FROM pieces \n            WHERE name = piece_name AND orient = 3;\n        SELECT prev1, prev2, prev3, prev4 INTO piece_text4 FROM pieces \n            WHERE name = piece_name AND orient = 4;\n        RAISE NOTICE 'Next piece:  %  |  %  |  %  |  %', \n            piece_text1.prev1, \n            COALESCE(piece_text2.prev1, ''), \n            COALESCE(piece_text3.prev1, ''), \n            COALESCE(piece_text4.prev1, '');\n        RAISE NOTICE '             %  |  %  |  %  |  %',\n            piece_text1.prev2, \n            COALESCE(piece_text2.prev2, ''), \n            COALESCE(piece_text3.prev2, ''), \n            COALESCE(piece_text4.prev2, '');\n        RAISE NOTICE '             %  |  %  |  %  |  %',\n            piece_text1.prev3, \n            COALESCE(piece_text2.prev3, ''), \n            COALESCE(piece_text3.prev3, ''), \n            COALESCE(piece_text4.prev3, '');\n        RAISE NOTICE '             %  |  %  |  %  |  %',\n            piece_text1.prev4, \n            COALESCE(piece_text2.prev4, ''), \n            COALESCE(piece_text3.prev4, ''), \n            COALESCE(piece_text4.prev4, '');\n    END;\n$$;\nWhile the function is fairly long, it is really just repeating the same basic step. First, the prev1, prev2, prev3, and prev4 strings for the desired piece are retrieved from the pieces table at a given orientation. The “prev” + n naming scheme simply indicates that the string serves as the nth row in the display graphic. Once this information has been retrieved for all orientations, the piece illustrations can be printed to the player. For pieces which don’t have all orientations, any NULL values are replaced with an empty string before printing."
  },
  {
    "objectID": "projects/tetris/tetris-sql/tetris-sql.html#placing-a-piece",
    "href": "projects/tetris/tetris-sql/tetris-sql.html#placing-a-piece",
    "title": "PostgreTETRIS: Tetris in SQL",
    "section": "Placing a piece",
    "text": "Placing a piece\nOnce a new game has been started, the player can place a piece by performing an insertion into the moves table. This can be done manually using INSERT INTO moves (pos, orient) VALUES (int1, int2);, or more conveniently by calling the place stored procedure with arguments int1 and int2, i.e. CALL place(int1, int2);, which executes the same insertion statement. The value of int1, which must be between 1 and 10, denotes the leftmost column that the piece will occupy. The value of int2 specifies which orientation to place the piece. This value must be greater than zero but no larger than the maximum number of orientations for the piece, which can be determined by simply looking at the number of different illustrations that are displayed. Once the orientation and horizontal position have been chosen, the piece will be dropped vertically onto the stack of previous pieces.\nInternally, the process described above is carried out using a trigger on the moves table that is called before each row insertion. This trigger executes the place_piece function, which is given below:\nCREATE OR REPLACE FUNCTION place_piece()\n    RETURNS TRIGGER\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        pos_block BOOL;\n        row_itr INT;\n        row0 Int;\n        col0 INT;\n        collision BOOL;\n        piece RECORD;\n    BEGIN\n        SELECT * INTO piece FROM pieces WHERE orient = NEW.orient AND \n            pieces.name = (SELECT piece_log.piece_name FROM piece_log);\n        IF piece IS NULL THEN\n            PERFORM print_board();\n            RAISE NOTICE 'Piece does not have orientation %.', NEW.orient;\n            PERFORM print_piece((SELECT piece_log.piece_name FROM piece_log));\n            RETURN NULL;\n        END IF;\n        col0 = NEW.pos;\n        FOR row_itr IN 1..21 LOOP\n            collision = check_piece_collision(row_itr, col0, piece.b1, piece.b2, \n                                              piece.b3, piece.b4);\n            row0 = row_itr - 1;\n            EXIT WHEN collision;\n        END LOOP;\n        IF row0 = 0 THEN\n            PERFORM print_board();\n            RAISE NOTICE 'Piece cannot be placed.';\n            PERFORM print_piece(piece.name);\n            RETURN NULL;\n        ELSE\n            PERFORM add_piece(row0, col0, piece.b1, piece.b2, piece.b3, piece.b4);\n            PERFORM clear_lines();\n        END IF;\n        PERFORM prepare_next();\n        RETURN NEW;\n    END;\n$$;\n\nCREATE OR REPLACE TRIGGER piece_placed BEFORE INSERT ON moves FOR EACH ROW\n    EXECUTE PROCEDURE place();\nThe function begins by retrieving the necessary piece of information and checking that the orientation requested by the player is valid. Next, it loops through the playfield rows starting from the top, and checks if the piece will collide with the existing piece stack at the given height. This collision checking is done using the check_piece_collision and check_block_collision functions, which are given below:\nCREATE OR REPLACE FUNCTION check_piece_collision(\n    row0 INT, col0 INT, b1 INT[], b2 INT[], b3 INT[], b4 INT[])\n    RETURNS BOOL\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        row1 INT;\n        col1 INT;\n        collision BOOL = 'false';\n    BEGIN\n        collision = collision OR check_block_collision(row0 + b1[1], col0 + b1[2]);\n        collision = collision OR check_block_collision(row0 + b2[1], col0 + b2[2]);\n        collision = collision OR check_block_collision(row0 + b3[1], col0 + b3[2]);\n        collision = collision OR check_block_collision(row0 + b4[1], col0 + b4[2]);\n        RETURN collision;\n    END;\n$$;\n\nCREATE OR REPLACE FUNCTION check_block_collision(row0 INT, col0 INT)\n    RETURNS BOOL\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        collision BOOL = 'true';\n    BEGIN\n        IF (col0 BETWEEN 1 AND 10) AND row0 &lt;= 20 THEN\n            IF row0 &gt; 0 THEN\n                SELECT state INTO collision \n                FROM board WHERE height = row0 AND width = col0;\n            ELSE\n                collision = 'false';\n            END IF;\n        END IF;\n        RETURN collision;\n    END;\n$$; \nThe first function to be called is check_piece_collision, which takes as arguments the row and column of the playfield to be checked and the relative block positions of the piece that were retrieved from pieces. It computes the absolute positions of the four piece blocks by adding the specified row and column to the first and second elements respectively of each integer array. The rows and columns for these positions are then passed to check_block_collision, which determines whether the specified block is in-bounds and not currently occupied by another piece.\nGoing back to the loop in function place, we can see that it terminates once check_block_collision indicates that a collision is detected at the specified height. After subtracting one from this height to get the largest non-colliding height, the function then calls add_piece, which is defined below:\nCREATE OR REPLACE FUNCTION add_piece(\n    row0 INT, col0 INT, b1 INT[], b2 INT[], b3 INT[], b4 INT[])\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    BEGIN\n        UPDATE board SET state = 'true' WHERE \n            (height = row0 + b1[1] AND width = col0 + b1[2]) OR\n            (height = row0 + b2[1] AND width = col0 + b2[2]) OR\n            (height = row0 + b3[1] AND width = col0 + b3[2]) OR\n            (height = row0 + b4[1] AND width = col0 + b4[2]);\n    END;\n$$;\nThis function simply updates the values in board which correspond to the final position of the piece. Once the state of those tiles is changed to true, the place function clears any filled lines by calling the clear_lines function, which is given below:\nCREATE OR REPLACE FUNCTION clear_lines()\n    RETURNS VOID\n    LANGUAGE plpgsql\nAS $$\n    DECLARE\n        row_itr INT;\n        filled BOOL;\n        cleared_count INT = 0;\n    BEGIN\n        FOR row_itr IN \n            SELECT height FROM board GROUP BY height HAVING BOOL_AND(state) ORDER BY height\n        LOOP\n            DELETE FROM board WHERE height = row_itr;\n            UPDATE board SET height = height + 1 WHERE height &lt; row_itr;\n            cleared_count = cleared_count + 1;\n        END LOOP;\n        INSERT INTO board(height, width) \n            SELECT * FROM generate_series(1, cleared_count) t1 CROSS JOIN generate_series(1, 10) t2;\n        UPDATE lines SET num_cleared = num_cleared + 1 WHERE num_lines = cleared_count;\n    END;\n$$;\nWhen clearing a line, the blocks in the target line must be deleted, and all lines that are above it in the playfield must be dropped down by one row. This rearrangement can be carried out for any number of simultaneous line clears by starting from the top of the playfield (i.e. at a height of 1) and iterating down the rows. When a row is determined to be full, it is deleted from board and all rows above it have their heights incremented by 1. By repeating this for heights 1 through 20, all line clears can be correctly implemented in a single pass. Finally, clear_lines updates the lines table based on how many lines were cleared, ranging from 0 (in which case there is no update) to 4.\nAfter performing any line clears, the place function finishes by calling prepare_next, which prints the updated playfield and selects the next piece for the player. This process repeats for each new piece until no valid moves remain, at which point the player must call reset to begin a new game (this can be used to end a game at any point)."
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html",
    "href": "projects/tetris/tetris-vba/tetris-vba.html",
    "title": "Tetris in VBA",
    "section": "",
    "text": "GitHub Repository"
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html#overview",
    "href": "projects/tetris/tetris-vba/tetris-vba.html#overview",
    "title": "Tetris in VBA",
    "section": "Overview",
    "text": "Overview\nThis project implements a simplified version of Tetris within a Microsoft Excel spreadsheet using Visual Basic for Applications (VBA) Visual Basic for Applications (VBA). To view this application, you can either download and open the Tetris.xlsm file (with macros enabled), or import the VBA code from the Tetris.bas file. Both files can be found in the project’s GitHub repository. Note that the scrollButtons_SpinDown and scrollButtons_SpinUp macros must placed in the worksheet code module.\n\n\n\nA game of Tetris played within Excel, showing the simple graphical interface.\n\n\nTo start a game, simply hit the “Reset” button to clear the board and generate a new piece. The orientation of the piece can be set by pressing “Rotate”, while its horizontal alignment can be shifted using the left-right arrow buttons. The “Drop” button allows the piece to fall vertically downward until it collides with either the bottom of the board or a previously-placed piece.\nThe text below offers a comprehensive description of the program’s code. For a more informal discussion of the project, see the associated post(s)."
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html#worksheet-structure",
    "href": "projects/tetris/tetris-vba/tetris-vba.html#worksheet-structure",
    "title": "Tetris in VBA",
    "section": "Worksheet Structure",
    "text": "Worksheet Structure\nThe Tetris.xlsm worksheet can be broadly divided into two relevant areas: the Tetris playfield on the left (columns A through L), and the user interface on the right (columns M through R). The playfield is itself further subdivided into a set of four named ranges, specifying the in-bounds area plus the left, right, and bottom walls. The interface area consists of four buttons and a table that holds the number of different line clears that have occurred throughout the game.\nThe player controls the placement of each piece using the buttons provided in the interface. At the start of a game and after each piece drop, a new piece is positioned at the top of the game board. The horizontal alignment of the piece can be shifted by the player using the left-right arrow buttons, which are implemented using a horizontal ActiveX scroll button control. This widget triggers the following two macros, which are activated by pressing the left and right arrows respectively:\n\n'Moves piece to the left after button press'\nPrivate Sub scrollButtons_SpinDown()\n    Application.ScreenUpdating = False\n    ShiftPiece -1\nEnd Sub\n\n'Moves piece to the right after button press'\nPrivate Sub scrollButtons_SpinUp()\n    Application.ScreenUpdating = False\n    ShiftPiece 1\nEnd Sub\nThe player can cycle through different piece orientations by clicking the “Rotate” button repeatedly, and then finally drop the piece by pressing the “Drop” button. The “Reset” button is used to start a new game by clearing the playfield and zeroing the line count table."
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html#starting-a-game",
    "href": "projects/tetris/tetris-vba/tetris-vba.html#starting-a-game",
    "title": "Tetris in VBA",
    "section": "Starting a Game",
    "text": "Starting a Game\nWhenever the “Reset” button is pressed, it triggers the following macro:\n\nSub Reset()\n    Application.ScreenUpdating = False\n    startHeight = 3\n    CreatePieceDict\n    ClearRange Range(\"board\")\n    Range(\"lines\") = 0\n    NextPiece\nEnd Sub\nIn order to prepare a new game of Tetris, the program must ensure that the following steps have been taken:\n\nThe seven different piece types have been properly represented.\nThe playfield and line counts have been cleared.\nA new, randomly-selected piece is placed at the top of the playfield.\n\nThe Reset procedure shown above accomplishes each of these tasks in turn by calling a respective subroutine. While this preparatory work is being undertaken, the screen update flag is set to false in order to improve performance and avoid visual artifacts.\nThe most complicated procedure called by Reset is CreatePieceDict, which defines the seven “tetromino” pieces used in standard Tetris. A portion of the code for this procedure, used to generate the “T-piece”, is reproduced below:\n\nDim tCoords(3, 3, 1) As Long\n\ntCoords(0, 0, 0) = 0: tCoords(0, 0, 1) = 0\ntCoords(0, 1, 0) = 0: tCoords(0, 1, 1) = 1\ntCoords(0, 2, 0) = 1: tCoords(0, 2, 1) = 1\ntCoords(0, 3, 0) = 0: tCoords(0, 3, 1) = 2\n\ntCoords(1, 0, 0) = 0: tCoords(1, 0, 1) = 0\ntCoords(1, 1, 0) = 0: tCoords(1, 1, 1) = 1\ntCoords(1, 2, 0) = 1: tCoords(1, 2, 1) = 1\ntCoords(1, 3, 0) = -1: tCoords(1, 3, 1) = 1\n\ntCoords(2, 0, 0) = 0: tCoords(2, 0, 1) = 0\ntCoords(2, 1, 0) = 0: tCoords(2, 1, 1) = 1\ntCoords(2, 2, 0) = -1: tCoords(2, 2, 1) = 1\ntCoords(2, 3, 0) = 0: tCoords(2, 3, 1) = 2\n\ntCoords(3, 0, 0) = 0: tCoords(3, 0, 1) = 0\ntCoords(3, 1, 0) = 0: tCoords(3, 1, 1) = 1\ntCoords(3, 2, 0) = -1: tCoords(3, 2, 1) = 0\ntCoords(3, 3, 0) = 1: tCoords(3, 3, 1) = 0\n\nSet Pieces = CreateObject(\"Scripting.Dictionary\")\nPieces.Add \"t\", tCoords\nThe piece descriptions, which consist of (x, y) coordinates for each of the four blocks, are stored in three-dimensional integer arrays with shape 4 x 4 x 2. The first dimension denotes the orientation of the piece (there are always four orientations given, even if some of them are identical), while the second dimension identifies the specific piece block. Given a specific orientation and block, the array reduces to a two-dimensional vector, which holds the desired (x, y) coordinates.\nOnce the pieces are properly defined, a new piece can be selected and added to the top of the playfield by calling the NextPiece procedure:\n\nPrivate Sub NextPiece()\n    pieceLocation = 4\n    pieceOrient = 0\n    Select Case Rnd() * 7\n        Case 0 To 1\n            pieceName = \"sq\"\n        Case 1 To 2\n            pieceName = \"i\"\n        Case 2 To 3\n            pieceName = \"t\"\n        Case 3 To 4\n            pieceName = \"zl\"\n        Case 4 To 5\n            pieceName = \"zr\"\n        Case 5 To 6\n            pieceName = \"ll\"\n        Case Else\n            pieceName = \"lr\"\n    End Select\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient\nEnd Sub\nHere, a new piece is first selected randomly using Excel’s built-in random number generator, and then mapped (arbitrarily) to the abbreviated name of a piece. That string is then passed to the PlacePiece procedure, along with the initial piece position and orientation, which displays the new piece on top of the playfield."
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html#positioning-a-piece",
    "href": "projects/tetris/tetris-vba/tetris-vba.html#positioning-a-piece",
    "title": "Tetris in VBA",
    "section": "Positioning a Piece",
    "text": "Positioning a Piece\nAfter a new piece is placed on the board, the player is free to decide its orientation and horizontal position at their own pace. As shown previously, the left-right arrow buttons will ultimately call the ShiftPiece procedure with an argument of either -1 (move left) or +1 (move right). Pressing the “Rotate” button triggers the RotatePiece macro, which cycles through different piece orientations. The code for ShiftPiece and RotatePiece is given below:\n\n'Moves piece to the left or right at the top of the board'\nSub ShiftPiece(direct As Long)\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient, True\n    If Not PieceCollision(pieceName, startHeight, pieceLocation + direct, pieceOrient) Then\n        pieceLocation = pieceLocation + direct\n    End If\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient\nEnd Sub\n\n'Rotates piece in place (roughly) at the top of the board'\nSub RotatePiece()\n    Dim newOrient As Long\n    Application.ScreenUpdating = False\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient, True\n    If pieceOrient = 3 Then\n        newOrient = 0\n    Else\n        newOrient = pieceOrient + 1\n    End If\n    If Not PieceCollision(pieceName, startHeight, pieceLocation, newOrient) Then\n        pieceOrient = newOrient\n    End If\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient\nEnd Sub\nBoth procedures have the same logical structure. They begin by using the PlacePiece procedure to remove the current image of the piece (which is equivalent to “placing” a transparent piece in that same location), and then they perform the desired modification of the piece’s coordinates. After checking that the new coordinates do not collide with the boundaries of the playfield or with another piece, the procedure finishes by placing the repositioned piece back on the board.\nThe code for the PlacePiece procedure, along with its two helper functions AddBlocks and ClearRange, is given below:\n\nPrivate Sub PlacePiece(piece As String, x0 As Long, y0 As Long, orient As Long, _ \n                       Optional blank As Boolean = False)\n    Dim coords As Variant\n    Dim block As Long, x As Long, y As Long\n    Dim cell As Range\n    If Pieces Is Nothing Then Reset\n    coords = Pieces.Item(piece)\n    For block = 0 To 3\n        x = x0 + coords(orient, block, 0)\n        y = y0 + coords(orient, block, 1)\n        If (x &gt; 0) And (y &gt; 0) Then\n            Set cell = Range(\"board\")(x, y)\n            If blank Then\n                ClearRange cell\n            Else\n                AddBlocks cell, piece\n            End If\n        End If\n    Next block\nEnd Sub\n\nPrivate Sub AddBlocks(cells As Range, piece As String)\n    Dim color As Long\n    color = PieceColors.Item(piece)\n    cells.Interior.ColorIndex = color\n    cells.Font.ColorIndex = color\n    cells.Value = 1\n    cells.BorderAround xlContinuous, xlThin, xlAutomatic\nEnd Sub\n\nPrivate Sub ClearRange(cells As Range)\n    cells.Clear\n    cells.Interior.ColorIndex = xlNone\nEnd Sub\nThe core logic is contained in the for-loop, which iterates through the piece blocks and computes their coordinates on the playfield. It does this by taking the relative coordinates given in CreatePieceDict and adding them to the passed arguments x0 and y0, which denote the desired absolute position of the upper-left-most piece block. When the optional boolean argument is set to false, the AddBlocks procedure is called to paint the piece block into the target cell. When the argument is set to true, the cell is cleared of all formatting.\nTo determine if a candidate piece position leads to collisions, and therefore must be rejected, the PieceCollision and CheckCollision functions are used:\n\nPrivate Function PieceCollision(piece As String, x0 As Long, y0 As Long, _ \n                                orient As Long) As Boolean\n    Dim coords As Variant\n    Dim block As Long, x As Long, y As Long\n    coords = Pieces.Item(piece)\n    PieceCollision = False\n    For block = 0 To 3\n        x = x0 + coords(orient, block, 0)\n        y = y0 + coords(orient, block, 1)\n        PieceCollision = PieceCollision Or CheckCollision(x, y)\n    Next block\nEnd Function\n\nPrivate Function CheckCollision(x0 As Long, y0 As Long) As Boolean\n    'Check left boundary collision'\n    CheckCollision = Not (Intersect(Range(\"board\")(x0, y0), Range(\"left\")) Is Nothing)\n    'Check right boundary collision'\n    CheckCollision = CheckCollision Or Not _ \n                        (Intersect(Range(\"board\")(x0, y0), Range(\"right\")) Is Nothing)\n    'Check bottom boundary condition'\n    CheckCollision = CheckCollision Or Not _\n                        (Intersect(Range(\"board\")(x0, y0), Range(\"bottom\")) Is Nothing)\n    'Check piece collision'\n    CheckCollision = CheckCollision Or (Range(\"board\")(x0, y0) = 1)\nEnd Function\nThe PieceCollision iterates through the piece blocks and calls CheckCollision at each coordinate. The latter function checks to see if the block cell overlaps with any of the cells corresponding to the left, right, or bottom boundaries of the playfield, or if it overlaps with an already occupied cell on the board. If any of these intersections occur, PieceCollision will return true and the proposed piece position will be rejected."
  },
  {
    "objectID": "projects/tetris/tetris-vba/tetris-vba.html#dropping-a-piece",
    "href": "projects/tetris/tetris-vba/tetris-vba.html#dropping-a-piece",
    "title": "Tetris in VBA",
    "section": "Dropping a Piece",
    "text": "Dropping a Piece\nOnce the player has positioned a piece to their satisfaction, they can drop it into place by pressing the “Drop” button. This triggers the DropPiece procedure, which determines how the piece should ultimately land in the playfield:\n\nSub DropPiece()\n    Dim height As Long\n    Application.ScreenUpdating = False\n    PlacePiece pieceName, startHeight, pieceLocation, pieceOrient, True\n    For height = startHeight + 1 To 24\n    If PieceCollision(pieceName, height, pieceLocation, pieceOrient) Then\n        height = height - 1\n        Exit For\n    End If\n    Next height\n    PlacePiece pieceName, height, pieceLocation, pieceOrient\n    ClearLines\n    NextPiece\nEnd Sub\nThe procedure works by incrementally lowering the height of the piece and checking for collisions. When a collision is detected, either with another piece or at the bottom of the playfield, the procedure calls PlacePiece at the height just before the collision was detected.\nOnce the piece is placed in its final position, the application must determine whether any rows of the playfield have been filled, and then update the playfield appropriately. This is done using the ClearLines and UpdateScore procedures:\n\nPrivate Sub ClearLines()\n    Dim height As Long\n    Dim board As Range: Set board = Range(\"board\")\n    Dim subrange As Range\n    Dim lineCount As Long: lineCount = 0\n    For height = 1 To 22\n        If WorksheetFunction.Sum(Range(board.cells(height, 1), board.cells(height, 10))) = 10 Then\n            lineCount = lineCount + 1\n            Range(board.cells(1, 1), board.cells(height - 1, 10)).Copy\n            Range(board.cells(2, 1), board.cells(height, 10)).PasteSpecial xlPasteAll\n            Range(\"A1\").Select\n        End If\n    Next height\n    UpdateScore lineCount\nEnd Sub\n\nPrivate Sub UpdateScore(lineClears As Long)\n    If lineClears &gt; 0 Then\n        Range(\"lines\")(1, lineClears) = Range(\"lines\")(1, lineClears) + 1\n    End If\nEnd Sub\nThe ClearLines procedure exploits a hidden feature of the playfield, in which occupied cells are given a value of 1 using a font color identical to the background cell color. As a result, filled rows can be found by simply adding the values of all cells in each row and checking if the sum equals 10. When a row is found to be filled, it is removed by copying the portion of the playfield above the row and pasting it one row lower. The total number of lines cleared in a single call to ClearLines is used to update the table of line counts via the UpdateScore procedure."
  }
]